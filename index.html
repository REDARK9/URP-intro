<html><head><style>body {
   color: black;
}
</style></head><body><p>⟶ E-BOOK</p>
<p><img src="_page_0_Picture_1.jpeg" alt=""></p>
<p>Introduction to the</p>
<h1 id="-universal-render-pipeline-for-advanced-unity-creators-"><strong>Universal Render Pipeline for advanced Unity creators</strong></h1>
<p><img src="_page_0_Picture_4.jpeg" alt=""></p>
<p><img src="_page_0_Picture_5.jpeg" alt=""></p>
<h2 id="-contents-"><strong>Contents</strong></h2>
<table>
<thead>
<tr>
<th>Introduction 7</th>
</tr>
</thead>
<tbody>
<tr>
<td>Author and contributors 9</td>
</tr>
<tr>
<td>URP: The successor to the Built-In Render Pipeline 10</td>
</tr>
<tr>
<td>The solution: Scriptable Render Pipelines 10</td>
</tr>
<tr>
<td>Why choose URP 11</td>
</tr>
<tr>
<td>Around 90% of Unity games on PC/console<br>are using SRPs 13</td>
</tr>
<tr>
<td>How to open a new URP project 13</td>
</tr>
<tr>
<td>How to add URP to an existing Built-In<br>Render Pipeline project 16</td>
</tr>
<tr>
<td>Converting the scenes of an existing project 20</td>
</tr>
<tr>
<td>Converting custom shaders 21</td>
</tr>
<tr>
<td>Comparing Quality options between the Built-In<br>Render Pipeline and URP 22</td>
</tr>
<tr>
<td>Built-In Render Pipeline to URP: Low settings 23</td>
</tr>
<tr>
<td>Built-In Render Pipeline to URP: High settings 25</td>
</tr>
<tr>
<td>Anti-aliasing 27</td>
</tr>
<tr>
<td>How to work with Quality settings 27</td>
</tr>
<tr>
<td>Quality settings when using URP 28</td>
</tr>
<tr>
<td>Modifying a URP Asset 30</td>
</tr>
<tr>
<td>GPU Resident Drawer and GPU occlusion culling 31</td>
</tr>
<tr>
<td>Lighting in URP 33</td>
</tr>
<tr>
<td>Choose your renderer 33</td>
</tr>
<tr>
<td>Light settings 36</td>
</tr>
<tr>
<td>URP shaders for lit scenes 37</td>
</tr>
<tr>
<td>Lit or Simple Lit? 38</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Lighting overview 39</th>
</tr>
</thead>
<tbody>
<tr>
<td>Light Inspector 39</td>
</tr>
<tr>
<td>Lighting a new scene 40</td>
</tr>
<tr>
<td>Ambient or Environment lighting 41</td>
</tr>
<tr>
<td>Shadows 42</td>
</tr>
<tr>
<td>Main Light shadow resolution 42</td>
</tr>
<tr>
<td>Main Light: Shadow Max Distance 44</td>
</tr>
<tr>
<td>Shadow Cascades 45</td>
</tr>
<tr>
<td>Additional Light Shadows 46</td>
</tr>
<tr>
<td>Light modes 48</td>
</tr>
<tr>
<td>Rendering Layers 55</td>
</tr>
<tr>
<td>Light probes 58</td>
</tr>
<tr>
<td>Light probes 58</td>
</tr>
<tr>
<td>Adaptive Probe Volumes 62</td>
</tr>
<tr>
<td>Lighting Scenario asset 65</td>
</tr>
<tr>
<td>Fixing issues with Adaptive Probe Volumes 68</td>
</tr>
<tr>
<td>Light leaks 70</td>
</tr>
<tr>
<td>Rendering Layers 71</td>
</tr>
<tr>
<td>Streaming APVs 74</td>
</tr>
<tr>
<td>Sky occlusion 75</td>
</tr>
<tr>
<td>Light probes vs APVs 78</td>
</tr>
<tr>
<td>Reflection probes 79</td>
</tr>
<tr>
<td>Reflection probe blending 81</td>
</tr>
<tr>
<td>Box Projection 81</td>
</tr>
<tr>
<td>Lens flares 82</td>
</tr>
<tr>
<td>Screen space lens flare 84</td>
</tr>
<tr>
<td>Light halos 87</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th></th>
<th>Screen Space Ambient Occlusion 88</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Decals 90</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shaders 93</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Comparing URP and Built-In Render Pipeline shaders . 94</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Custom shaders 94</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Unlit 95</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Unlit Color 97</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Unlit Textured 98</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lit Simple 100</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shadows 102</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Pipeline callbacks 105</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Render Objects 106</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>The render graph system 109</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Main principles 109</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Resource management 109</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Render graph execution overview 110</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Renderer Feature 111</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Post-processing 122</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Using the URP post-processing framework 124</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Adding a Local Volume component 126</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Motion Blur 129</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Using Motion Blur 130</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Troubleshooting performance issues 130</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Controlling post-processing with code 131</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Camera Stacking 132</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Controlling a stack with code 134</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>The SubmitRenderRequest API 135</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Coding a screengrab 135</td>
<td></td>
</tr>
<tr>
<td>Additional tools compatible with URP 138</td>
<td></td>
</tr>
<tr>
<td>Shader Graph 138</td>
<td></td>
</tr>
<tr>
<td>Fullscreen Shader Graph 145</td>
<td></td>
</tr>
<tr>
<td>Six Way Shader Graph 147</td>
<td></td>
</tr>
<tr>
<td>VFX Graph 148</td>
<td></td>
</tr>
<tr>
<td>2D Renderer and 2D lights 150</td>
<td></td>
</tr>
<tr>
<td>2D game development resources from Unity 153</td>
<td></td>
</tr>
<tr>
<td>2D sample projects from Unity 153</td>
<td></td>
</tr>
<tr>
<td>More Unity 6 features for URP 156</td>
<td></td>
</tr>
<tr>
<td>Spatial-Temporal Post-Processing (STP) 156</td>
<td></td>
</tr>
<tr>
<td>High Dynamic Range display output<br>for PC and consoles 158</td>
<td></td>
</tr>
<tr>
<td>Using a Pipeline State Object 159</td>
<td></td>
</tr>
<tr>
<td>PSO creation and caching 159</td>
<td></td>
</tr>
<tr>
<td>Tracing a new PSO collection 161</td>
<td></td>
</tr>
<tr>
<td>Precooking a PSO collection 161</td>
<td></td>
</tr>
<tr>
<td>Platform support 162</td>
<td></td>
</tr>
<tr>
<td>Performance 163</td>
<td></td>
</tr>
<tr>
<td>Optimizing lighting and rendering in URP 165</td>
<td></td>
</tr>
<tr>
<td>Light probes 167</td>
<td></td>
</tr>
<tr>
<td>Reflection probes 167</td>
<td></td>
</tr>
<tr>
<td>Camera settings 168</td>
<td></td>
</tr>
<tr>
<td>Occlusion culling 168</td>
<td></td>
</tr>
<tr>
<td>Pipeline settings 170</td>
<td></td>
</tr>
<tr>
<td>Frame Debugger 171</td>
<td></td>
</tr>
<tr>
<td>Unity Profiler 172</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>The URP 3D Sample 175</th>
</tr>
</thead>
<tbody>
<tr>
<td>The garden 176</td>
</tr>
<tr>
<td>The oasis 176</td>
</tr>
<tr>
<td>The cockpit 177</td>
</tr>
<tr>
<td>The terminal 177</td>
</tr>
<tr>
<td>Moving between the scenes 178</td>
</tr>
<tr>
<td>Scalability 182</td>
</tr>
<tr>
<td>Running the sample project on a mobile device 185</td>
</tr>
<tr>
<td>Conclusion 188</td>
</tr>
</tbody>
</table>
<h2 id="-span-id-page-6-0-span-introduction"><span id="page-6-0"></span>Introduction</h2>
<p>This guide can help experienced Unity developers and technical artists develop as efficiently as possible with the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/index.html">Universal Render Pipeline</a> (URP) in Unity 6.</p>
<p>URP and the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@17.0/manual/index.html">High Definition Render Pipeline (HDRP)</a> are two rendering solutions provided by Unity that are built on top of the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/srp-custom.html?">Scriptable Render Pipeline</a> (SRP) framework. These SRPs enable you to customize the culling of objects, their drawing, and the post-processing of the frame without having to use low-level programming languages like C++. You can also create your own fully customized SRP.</p>
<p>URP is Unity&#39;s default renderer for 2D and 3D games for mobile, XR, and untethered hardware. It&#39;s the successor to our Built-In Render Pipeline, designed to be efficient for you to learn, customize, and scale to all Unity-supported platforms. In Unity 6 it offers the same functionality as the Built-In Render Pipeline, and in a number of areas, exceeds its quality levels and performance.</p>
<p>Some of the areas this e-book provides expert guidance and best practices for include how to:</p>
<ul>
<li>Set up URP for a new project, or convert an existing Built-In Render Pipeline-based project to URP.</li>
<li>Work with URP Quality settings.</li>
<li>Use all lighting tools available in URP including new features like Adaptive Probe Volumes (APVs) for real-time global illumination and lighting scenarios that blend between day and night lighting.</li>
</ul>
<p><img src="_page_7_Picture_0.jpeg" alt=""></p>
<ul>
<li>Use URP shaders for lit scenes and understand the differences between URP and Built-In Render Pipeline shaders.</li>
<li>Use custom shaders, includes and HLSL includes.</li>
<li>Use the URP post-processing framework, including adding a Local Volume and controlling post-processing with code.</li>
<li>Use Rendering layers.</li>
<li>Apply many kinds of performance optimizations with tools in URP, including the newlyreleased GPU Resident Drawer, GPU occlusion culling, and more.</li>
<li>Customize the render pipeline using Renderer Features and the render graph system.</li>
</ul>
<p>Multiplatform deployment is a key factor in the success of many games. Players often play the same game on different devices, such as console and mobile, meaning Unity developers require rendering options that scale up and down for numerous devices, with as few steps and complexity as possible.</p>
<p>With scalability, customizability, and a rich feature set, URP offers you creative freedom in any type of project, from stylized visuals to physically based rendering.</p>
<p><img src="_page_7_Picture_10.jpeg" alt=""></p>
<p>A scene made with URP</p>
<p><span id="page-8-0"></span><img src="_page_8_Picture_0.jpeg" alt=""></p>
<h2 id="author-and-contributors">Author and contributors</h2>
<p><strong>Nik Lever</strong>, the author of this e-book, has been creating real-time 3D content since the midnineties and using Unity since 2006. For over 30 years he led the small development company, Catalyst Pictures, and has provided courses since 2018 with the aim of helping game developers expand their knowledge in a rapidly evolving industry.</p>
<h4 id="-unity-contributors-"><strong>Unity contributors</strong></h4>
<p><strong>Steven Cannavan</strong> is a senior development consultant on the <a href="https://unity.com/solutions/accelerate-solutions-games">Accelerate</a> <a href="https://unity.com/solutions/accelerate-solutions-games">Solutions Games</a> team, specializing in the Scriptable Rendering Pipelines. He has over 16 years of experience in the game development industry.</p>
<p><strong>Maxime Grange</strong> is a senior technical artist with eight years of experience, starting in VR indie games and advancing to become a light technical artist in Unity. Passionate about rendering techniques, shaders, and developing artist tools, Maxime focuses on achieving stunning visuals while maintaining optimal runtime performance.</p>
<p><strong>Felipe Lira</strong> has over 14 years of experience as a software engineer in the games industry, and specializes in graphics programming and multiplatform game development.</p>
<p><strong>Ali Mohebali</strong> has 21 years of experience working in the games industry, and has contributed to hit titles such as <em>Fruit Ninja</em> and <em>Jetpack Joyride</em>, both by Halfbrick Studios.</p>
<p><strong>Adrien Moulin</strong> is a senior graphics developer in Unity&#39;s render pipeline team. He has over eight years of experience in the simulation and real-time software industry. He is currently focused on delivering the best possible foundations and APIs to the Scriptable Render Pipeline users.</p>
<p><strong>Mathieu Muller</strong> is the lead product manager for Graphics at Unity. He leads the Graphics product management team and oversees the Graphics roadmap and product vision.</p>
<p><strong>Damian Nachman</strong> is a senior technical product manager in Unity&#39;s graphics team, specializing in low-level graphics development and optimization. He has 10 years of experience with working on real-time graphics engines and benchmarking across multiple industries.</p>
<p><strong>Oliver Schnabel</strong> is a senior technical product manager in Unity&#39;s graphics team, where he integrates customer insights and works with global studios to prioritize the development of a more performant, unified, and scalable rendering stack. He brings extensive experience in computer graphics and real-time development.</p>
<p><span id="page-9-0"></span><img src="_page_9_Picture_0.jpeg" alt=""></p>
<h2 id="urp-the-successor-to-the-built-in-render-pipeline">URP: The successor to the Built-In Render Pipeline</h2>
<p>One of Unity&#39;s biggest strengths is its platform reach. The ideal for all game studios is to create once and efficiently deploy their game to their desired range of platforms, from highend PCs to low-end mobile.</p>
<p>The Built-In Render Pipeline was developed to be a turnkey solution for all platforms supported by Unity. It supports a mix of graphics features and is convenient to use with Forward and Deferred pipelines.</p>
<p>However, as Unity continues to add support for more platforms, the shortcomings of the Built-In Render Pipeline have become more pronounced:</p>
<ul>
<li>The bulk of the code is written in C++ and can&#39;t be modified by developers, making it a blackbox system.</li>
<li>The render flow and render passes are prestructured.</li>
<li>The rendering algorithm is hardcoded.</li>
<li>Unconstrained customization makes achieving good performance on all platforms difficult.</li>
<li>It exposes callbacks in the rendering code that trigger sync points in the pipeline. Those callbacks prevent multithreaded rendering optimizations, enabling changes for injection of state at any point in the frame dynamically by calling to C#.</li>
<li>Caching data to manage the persistence state for user injection is difficult.</li>
</ul>
<h4 id="-the-solution-scriptable-render-pipelines-"><strong>The solution: Scriptable Render Pipelines</strong></h4>
<p>The SRPs were developed to support an efficient multiplatform workflow by providing:</p>
<ul>
<li>Intelligent and reliable scaling for the maximum number of hardware platforms, from high- to low-end devices.</li>
<li>The ability to customize rendering processes using C#, not C++. Using C# means a new executable does not need to be compiled for every change.</li>
<li>Flexibility to support architecture evolution.</li>
<li>Flexibility to create sharp graphics that are performant across many platforms.</li>
</ul>
<p><span id="page-10-0"></span>The image below illustrates how SRPs work. With SRPs, you can use C# to control and customize render passes and rendering control, as well as HLSL shaders that can be created using artist-friendly tools such as <a href="#page-137-0">Shader Graph.</a> Shaders give you access to even the lowerlevel API and engine-layer abstractions.</p>
<p><img src="_page_10_Figure_2.jpeg" alt=""></p>
<p>The graphics programmable model for the Scriptable Render Pipelines</p>
<p>An advanced user can create a new SRP from scratch or modify the HDRP or URP. The graphics stack is open source and available for use on <a href="https://github.com/Unity-Technologies/Graphics">GitHub</a>.</p>
<h2 id="why-choose-urp">Why choose URP</h2>
<ul>
<li><strong>Accessible to a wide range of users:</strong> URP is configurable by artists and technical artists alike, providing more flexibility for prototyping and refining rendering techniques for full game production.</li>
<li><strong>Extendable and customizable:</strong> URP allows users to modify existing capabilities and extend the pipeline with new ones, making it a solid choice for advanced users, including Asset Store and third-party package creators, experienced studios, and advanced teams.</li>
</ul>
<p>While the low-level rendering API is written in C++ for performance purposes, a URP developer can write a simple C# script to be called during the render pipeline, enabling high-level customization without sacrificing performance.</p>
<p>— <strong>Multiple rendering options:</strong> URP provides a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/urp-universal-renderer.html?">Universal Renderer</a> that supports Forward, <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/rendering/forward-plus-rendering-path.html">Forward+</a> and <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/rendering/deferred-rendering-path.html?">Deferred</a> rendering paths, as well as a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/2d-index.html?">2D Renderer</a>.</p>
<p>These renderers can be extended with additional features and Scriptable Render Passes. The <a href="#page-105-0">Render Objects</a> feature can be used to render objects from a given Layer Mask at</p>
<p>different events in the rendering pipeline. It also allows you to override material and other render states when rendering those objects, making it possible to customize the rendering without code. URP can be extended with custom renderers to suit specific needs.</p>
<p>The <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/render-graph-introduction.html">render graph system</a> enables you to access and manipulate the various buffers used to render a frame; using the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/urp-renderer-feature.html">Renderer Features</a> workflow means this can be injected at any stage in the render pipeline.</p>
<ul>
<li><strong>Excellent performance</strong>: URP provides robust performance and provides many tools for you to adapt the balance between fidelity and frame rate on a wide range of devices. In particular:<ul>
<li>URP evaluates real-time lighting very efficiently. In Forward rendering it evaluates all lighting in a single pass. Forward+ improves upon standard Forward rendering by culling lights spatially rather than per object. This increases the overall number of lights that can be utilized in rendering a frame. In Deferred rendering it supports the Native RenderPass API, allowing G-buffer and lighting passes to be combined into a single render pass.</li>
<li>There are CPU and GPU improvements when drawing meshes. The <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/SRPBatcher.html?">SRP Batcher</a> helps ensure fewer draw calls and improves on how depth is handled, while <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/gpu-resident-drawer.html">GPU</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/gpu-resident-drawer.html">Resident Drawer</a> and occlusion culling can significantly reduce the draw calls for some scenes.</li>
<li>URP makes more efficient use of tile memory on mobile devices, leading to less power consumption, a longer battery life, and therefore, the possibility of longer play sessions.</li>
<li>URP comes with an integrated <a href="#page-121-1">post-processing</a> stack that allows for better performance compared to the Built-In Render Pipeline. Using the <a href="#page-123-1">Volume</a> framework, you can create post-processing effects that are dependent on the Camera position without writing any code.</li>
</ul>
</li>
<li><strong>Compatible with the other key tools:</strong> URP supports artist- and technical artist-friendly tools like <a href="https://docs.unity3d.com/Packages/com.unity.shadergraph@17.0/manual/index.html?">Shader Graph,</a> <a href="https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@17.0/manual/index.html">VFX</a> <a href="https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@17.0/manual/index.html">Graph,</a> and the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/features/rendering-debugger.html?">Rendering Debugger.</a></li>
<li><strong>2D rendering:</strong> URP supports advanced 2D lighting, shadows, and post-processing effects, enhancing the visual quality of 2D games without compromising on performance.</li>
</ul>
<p><span id="page-12-0"></span><img src="_page_12_Picture_0.jpeg" alt=""></p>
<h4 id="-around-90-of-unity-games-on-pc-console-are-using-srps-"><strong>Around 90% of Unity games on PC/console are using SRPs</strong></h4>
<p>The latest data available to Unity shows that URP is the most popular choice for games using Unity released on PC and console in 2023. The graph below shows that the Built-In Render Pipeline is now only used by a small fraction of development teams.</p>
<p><img src="_page_12_Picture_3.jpeg" alt=""></p>
<p>Proportion of games released using the different pipelines available from Unity</p>
<p>However, while most Unity projects are now being built on URP or HDRP, the Built-In Render Pipeline will remain an available option in Unity 6.</p>
<h2 id="how-to-open-a-new-urp-project">How to open a new URP project</h2>
<p>Open a new project using URP via the Unity Hub. Click on <strong>New</strong> and verify that the Unity version selected at the top of the window is Unity 6 or newer. Choose a name and location for the project, select the <strong>Universal 2D</strong> or <strong>Universal 3D</strong> templates then click <strong>Create</strong>.</p>
<table>
<thead>
<tr>
<th></th>
<th>New project<br>Editor Version: 6000.0.1f1 C</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>100<br>All templates</td>
<td>Q Search all templates</td>
<td></td>
</tr>
<tr>
<td>ල<br>Core<br><br>Sample</td>
<td>Universal 2D<br>589<br>Core</td>
<td>SRP</td>
</tr>
<tr>
<td>4<br>Learning</td>
<td>Universal 3D<br>Core</td>
<td></td>
</tr>
<tr>
<td></td>
<td>High Definition 3D<br>୍ରରତ<br>Core</td>
<td>Universal 3D<br>This template includes the settings and<br>assets you need to start creating with the<br>Universal Render Pipeline (URP).</td>
</tr>
<tr>
<td></td>
<td>Universal 3D sample<br>్రాల<br>Sample</td>
<td>Read more<br>PROJECT SETTINGS</td>
</tr>
<tr>
<td></td>
<td>3D Mobile<br>D<br>0<br>Core</td>
<td>Project name<br>My project</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Cancel<br>Create project</td>
</tr>
</tbody>
</table>
<p>When you create a new project with the URP template, you might have to download the template for the first time.</p>
<p><img src="_page_13_Picture_0.jpeg" alt=""></p>
<p><strong>Note:</strong> The template ensures that your project is set to use a linear color space, which is required for calculating lighting correctly.</p>
<p><img src="_page_13_Picture_2.jpeg" alt=""></p>
<p>The <a href="https://unity.com/demos/urp-3d-sample">URP 3D sample scene,</a> which is covered at the end of this book, is available as a downloadable template.</p>
<p>You can create new scenes via <strong>File &gt; New Scene</strong>, with essential GameObjects such as Camera and Directional light, and even create your own scene template with prepopulated objects. Read more in the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/scene-templates.html">URP Scene Templates documentation</a>.</p>
<p><img src="_page_13_Figure_5.jpeg" alt=""></p>
<p>The New Scene dialog displaying Scene Templates</p>
<p>Go to <strong>Edit &gt; Project Settings</strong> and open the <strong>Graphics</strong> panel. To use URP in-Editor, you must select a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/universalrp-asset.html?">URP Asset</a> from the <strong>Scriptable Render Pipeline Settings</strong>. The URP Asset controls the global rendering and Quality settings of a project and creates the rendering pipeline instance. Meanwhile, the rendering pipeline instance contains intermediate resources and the render pipeline implementation.</p>
<p><strong>PC_RPAsset</strong> is the default URP Asset selected on a desktop, but you can switch to <strong>Mobile_ RPAsset</strong>.</p>
<table>
<thead>
<tr>
<th>00</th>
<th>Project Settings</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Project Settings</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>a</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Adaptive Performance<br>Audio</td>
<td>Graphics</td>
<td></td>
<td>0 2</td>
<td></td>
</tr>
<tr>
<td>Burst AOT Settings</td>
<td>Scriptable Render Pipeline Settings</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Editor</td>
<td>9 UniversalRP (Universal Render Pipeline Asset)</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Graphics</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>URP Global Settings<br>Input Manager</td>
<td>A Seriptable Render Pipeline is in use, some settings will not be used and are hidden</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Memory Settings</td>
<td>Built-in Shader Settings</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Package Manager<br>Physics</td>
<td>Video</td>
<td>Always include</td>
<td>P</td>
<td></td>
</tr>
<tr>
<td>Physics 2D</td>
<td>Always Included Shaders</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Player</td>
<td>Size</td>
<td>6</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Preset Manager</td>
<td>Element O</td>
<td>Legacy Shaders/Diffuse</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Quality</td>
<td>Element 1</td>
<td>Hidden/CubeBlur</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Scene Template<br>Script Execution Order</td>
<td>Element 2</td>
<td>Hidden/CubeCopy</td>
<td>(2)</td>
<td></td>
</tr>
<tr>
<td>V Services</td>
<td>Element 3</td>
<td>Hidden/CubeBlend</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Ads</td>
<td>Element 4</td>
<td>Sprites/Default</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Analytics<br>Cloud Build</td>
<td>Element 5</td>
<td>Ul/Default</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Cloud Diagnostics</td>
<td>Shader Stripping</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Collaborate</td>
<td>Lightmap Modes</td>
<td>Automatic</td>
<td>4</td>
<td></td>
</tr>
<tr>
<td>In-App Purchasing</td>
<td>Fog Modes</td>
<td>Automatic</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ShaderGraph<br>Tags and Layers</td>
<td>Instancing Variants</td>
<td>Strip Unused</td>
<td></td>
<td></td>
</tr>
<tr>
<td>TextMesh Pro</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Time</td>
<td>Shader Loading</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Timeline</td>
<td>Log Shader Compilation</td>
<td>D</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ul Builder</td>
<td>Preloaded Shaders</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Version Control</td>
<td>Size</td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Visual Scripting<br>XR Plugin Management</td>
<td>Preload shaders after showing first scene</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Currently tracked: 79 shaders 112 total variants</td>
<td></td>
<td>-</td>
</tr>
</tbody>
</table>
<p>The Graphics panel in Project Settings</p>
<p>A <a href="#page-29-0">later section</a> of this guide details how to adjust the settings of a URP Asset.</p>
<h2 id="-span-id-page-15-0-span-how-to-add-urp-to-an-existing-built-in-render-pipeline-project"><span id="page-15-0"></span>How to add URP to an existing Built-In Render Pipeline project</h2>
<p><strong>Important:</strong> Be sure to backup your project using source control before following the steps in this section. This process will convert assets, and Unity does not provide an undo option. If you use source control, you will be able to revert to previous versions of the assets if necessary.</p>
<p>If you upgrade an existing Built-In Render Pipeline project, you&#39;ll need to add the <strong>URP package</strong> to your project as it was not included in Unity before Unity 6.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>Package Manager</th>
</tr>
</thead>
<tbody>
<tr>
<td>Package Manager<br>+ ▼ Packages: In Project ▼<br>Sort: Name ↓ ▼</td>
<td></td>
<td><br>0<br>a</td>
</tr>
<tr>
<td>Pac<br>Unity Registry<br>V In Project<br>Je<br>Te<br>4<br>My Assels<br>Te<br>A<br>Built-in<br>&gt; Tillemia</td>
<td>3.0.7 V<br>1.1.29 V<br>3.0.6 V<br>1.6.2 V</td>
<td>JetBrains Rider Editor<br>Release<br>Unity Technologies<br>Version 3.0.7 - May 21, 2021<br>Registry Unity<br>View documentation View changelog View licenses</td>
</tr>
<tr>
<td>&gt; Unity UI<br>Version Control<br>Visual Scripting<br>Visual Studio Code Editor<br>Visual Studio Editor</td>
<td>1.0.0 V<br>1.9.0 V<br>0<br>1.7.2<br>1.2.4 V<br>2.0.11 V</td>
<td>The JetBrains Rider Editor package provides an integration for using the<br>JetBrains Rider IDE as a code editor for Unity. It adds support for generating<br>.csproj files for code completion and auto-discovery of installations.</td>
</tr>
<tr>
<td>Last update Oct 11, 11:51</td>
<td>C .</td>
<td>Remove</td>
</tr>
</tbody>
</table>
<p>The Package Manager displaying the Unity Registry packages</p>
<p>Go to <strong>Window &gt; Package Manager</strong> and click the <strong>Packages</strong> drop-down to add URP to your project. Make sure to select the <strong>Unity Registry</strong>, followed by <strong>Universal RP</strong>. Click <strong>Download</strong>  in the lower-right corner of the window if the URP package is not yet installed on your development computer. Then click <strong>Install</strong> once it&#39;s downloaded.</p>
<table>
<thead>
<tr>
<th>Package Manager</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>+ . Sort: Name (asc) . Filters . Clear Filters</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>In Project<br>O Updates<br>Unity Registry<br>My Assets</td>
<td>Q univer<br>· Packages<br>Universal RP</td>
<td>X<br>17.0.3 G</td>
<td>Universal RP<br>17.0.3 · May 21, 2024   Release<br>From Unity Registry by Unity Technologies Inc.<br>com.unity.render-pipelines.universal<br>Documentation: Changelog Licenses<br>Description Version History Dependencies Samples<br>The Universal Render Pipeline (URP) is a prebuilt Scriptable Render Pipeline, made by<br>Unity. URP provides artist-friendly workflows that let you quickly and easily create<br>optimized graphics across a range of platforms, from mobile to high-end consoles and<br>PCs.</td>
<td>Remove</td>
</tr>
<tr>
<td>Built-in<br>Services</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Installing URP via the Package Manager</p>
<p><img src="_page_16_Picture_0.jpeg" alt=""></p>
<p>To create a URP Asset, right-click in the <strong>Project</strong> window and choose <strong>Create &gt; Rendering &gt; URP Asset (with Universal Renderer)</strong>. Name the asset.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>Audio Mixer</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Rendering</td>
<td>A</td>
<td>URP Asset (with 2D Renderer)</td>
<td></td>
</tr>
<tr>
<td>Create</td>
<td></td>
<td>Material</td>
<td></td>
<td>URP Asset (with Universal Renderer)</td>
<td></td>
</tr>
<tr>
<td>Reveal in Finder<br>Open<br>Delete<br>Rename<br>Copy Path</td>
<td>C 36 C</td>
<td>Lens Flare<br>Lens Flare (SRP)<br>Render Texture<br>Lightmap Parameters<br>Lighting Settings<br>Custom Render Texture</td>
<td></td>
<td>URP Renderer Feature<br>URP 2D Renderer<br>URP Universal Renderer<br>URP Global Settings Asset</td>
<td>IT 15 (</td>
</tr>
<tr>
<td>Open Scene Additive</td>
<td></td>
<td>Animator Controller</td>
<td></td>
<td>URP Post-process Data<br>URP XR System Data</td>
<td></td>
</tr>
<tr>
<td>View in Package Manager</td>
<td></td>
<td>Animation</td>
<td></td>
<td>Environment Library (Look Dev)</td>
<td></td>
</tr>
<tr>
<td>Import New Asset</td>
<td></td>
<td>Animator Override Controller</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Creating a URP Asset</p>
<p><strong>Remember:</strong> If you create a new project using the Universal Render Pipeline or 3D (URP) templates, these URP Assets are already available in the project.</p>
<p>Rather than creating a single URP Asset, URP uses two files, each with an Asset extension.</p>
<p><img src="_page_16_Picture_7.jpeg" alt=""></p>
<p>Two assets in URP, one for URP settings and the other for Renderer Data</p>
<p>One is called <strong>UniversalRP_Renderer</strong>, a <strong>Renderer Data Asset</strong> that you can use to filter the layers the renderer works on, and intercept the rendering pipeline to customize how the scene is rendered. This way, you can facilitate the creation of high-quality effects. See the section on <a href="#page-104-0">Pipeline callbacks</a> for more information.</p>
<p>Additionally, the UniversalRP_Renderer controls high-level rendering logic and passes for URP. It supports Forward and Deferred paths, and a 2D Renderer that enables features such as <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/Lights-2D-intro.html?">2D</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/Lights-2D-intro.html?">Lights,</a> <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/2DShadows.html?">2D Shadows</a>, and <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/LightBlendStyles.html?">Light Blend Styles</a>. You can even extend URP to create your own renderers.</p>
<table>
<thead>
<tr>
<th></th>
<th>O Inspector</th>
<th></th>
<th>a :</th>
</tr>
</thead>
<tbody>
<tr>
<td>20<br>14</td>
<td></td>
<td>New Universal Render Pipeline Asset_Renderer (Universal Renderer Data)</td>
<td>@</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>Open</td>
</tr>
<tr>
<td></td>
<td>Filtering</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Opaque Layer Mask</td>
<td>Everything</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Transparent Layer Mask</td>
<td>Everything</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Rendering</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Rendering Path</td>
<td>Forward</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Depth Priming Mode</td>
<td>Disabled</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Depth Texture Mode</td>
<td>After Transparents</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Depth Attachment Format</td>
<td>Default</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Depth Texture Format</td>
<td>Default</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Transparent Receive Shadows</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Post-processing</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Enabled</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Data</td>
<td>PostProcessData (Post Process Data)</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td>Overrides</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Stencil</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Compatibility</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Intermediate Texture</td>
<td>Always</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Renderer Features</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>No Renderer Features added</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Add Renderer Feature</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The Inspector for UniversalRP_Renderer Data Asset</p>
<p>The other URP Asset provides options for controlling the Quality, Lighting, Shadows and Post-processing settings.. You can use different URP Assets to control the Quality settings, a process <a href="#page-29-1">outlined further down</a> in this section. This Settings Asset is linked to the Renderer Data Asset via the Renderer List. When you create a new URP Asset, the Settings Asset will have a Renderer List containing a single item – the Renderer Data Asset created at the same time, set as the default. You can add alternative Renderer Data Assets to this list.</p>
<p><img src="_page_18_Picture_1.jpeg" alt=""></p>
<p>The default renderer is used for all Cameras, including the Scene view. A Camera can override the default renderer by selecting another one from the Renderer List. This can be done through the use of a script, as needed.</p>
<p>A URP Asset in the Inspector</p>
<p>Despite following these steps to create a URP Asset, an open scene in the Scene or Game view will still use the Built-In Render Pipeline. You must complete one last step to make the switch to URP: Go to <strong>Edit &gt; Project Settings</strong> and open the <strong>Graphics</strong> panel. Click the small dot next to <strong>None (Render Pipeline Asset)</strong>. In the open panel, select <strong>UniversalRP</strong>.</p>
<table>
<thead>
<tr>
<th>● @</th>
<th></th>
<th>Project Settings</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Project Settings</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Adaptive Performance<br>Audio</td>
<td>Graphics</td>
<td></td>
<td></td>
<td>9 花</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Burst AOT Settings</td>
<td>Scriptable Render Pipeline Settings</td>
<td></td>
<td>Select RenderPip</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Editor</td>
<td>None (Render Pipeline Asset)</td>
<td></td>
<td></td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Graphics</td>
<td>Camera Settings</td>
<td></td>
<td>ದ್</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>URP Global Settings</td>
<td>Transparency Sort Mode</td>
<td>Default</td>
<td>Assets<br>0</td>
<td>9/16</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Input Manager<br>Memory Settings</td>
<td></td>
<td>× 0</td>
<td>None<br>Y</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Package Manager</td>
<td>Transparency Sort Axis</td>
<td></td>
<td>UniversalRP</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Physics</td>
<td>T Tier Settings</td>
<td></td>
<td></td>
<td>I Or</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Physics 2D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Player</td>
<td>F</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Preset Manager</td>
<td>Low (Tier 1)</td>
<td></td>
<td></td>
<td>V<br>18</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Quality<br>Scene Template</td>
<td>Standard Shader Quality</td>
<td></td>
<td>Hi</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Script Execution Order</td>
<td>Reflection Probes Box Projection</td>
<td></td>
<td>V</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Services</td>
<td>Reflection Probes Blending</td>
<td></td>
<td>V</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ads</td>
<td>Detail Normal Map</td>
<td></td>
<td>V</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Analytics</td>
<td>Enable Semitransparent Shadows</td>
<td></td>
<td></td>
<td>S</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cloud Build</td>
<td>Enable Light Probe Proxy Volume</td>
<td></td>
<td></td>
<td>&gt;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cloud Diagnostics<br>Collaborate</td>
<td>Cascaded Shadows</td>
<td></td>
<td>V</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>In-App Purchasing</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ShaderGraph</td>
<td>Preter 32-bit shadow maps.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Tags and Layers</td>
<td>Use HDR</td>
<td></td>
<td>&gt;<br>UniversalRP</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TextMesh Pro</td>
<td>HDR Mode</td>
<td></td>
<td>EP<br>Jniversal Render Pipeline Asset</td>
<td>P</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Time<br>Timeline</td>
<td>Rendering Path</td>
<td></td>
<td>isets/Settings/UniversalRP.ass<br>For</td>
<td>A</td>
<td></td>
<td></td>
</tr>
<tr>
<td>UI Builder</td>
<td>Realtime Global Illumination CPU Usage</td>
<td></td>
<td>LOV</td>
<td>P</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Version Control</td>
<td>Medium (Tier 2)</td>
<td></td>
<td></td>
<td>Use Defaults V</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Visual Scripting</td>
<td>Standard Shader Quality</td>
<td></td>
<td></td>
<td>High</td>
<td></td>
<td></td>
</tr>
<tr>
<td>XR Plugin Management</td>
<td>Reflection Probes Box Projection</td>
<td></td>
<td>1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>D</td>
<td></td>
</tr>
</tbody>
</table>
<p>Selecting a Scriptable Render Pipeline Asset</p>
<p><span id="page-19-0"></span><img src="_page_19_Picture_0.jpeg" alt=""></p>
<p>A warning message will pop up regarding the switch, but just press <strong>Continue</strong>.</p>
<p>As there is no content in your project yet, changing the render pipeline will be almost instantaneous. You&#39;re now ready to use URP.</p>
<h2 id="converting-the-scenes-of-an-existing-project">Converting the scenes of an existing project</h2>
<p>After you complete the above steps, you&#39;ll find that your beautiful scenes are suddenly colored magenta. This is because the shaders used by the materials in a Built-In Render Pipeline project are not supported in URP. Fortunately, there is a method for restoring your scenes to their original quality.</p>
<p><img src="_page_19_Picture_5.jpeg" alt=""></p>
<p>Materials in a scene appear in magenta because their Built-In Render Pipeline-based shaders must be converted for use in URP.</p>
<p>Go to <strong>Window &gt; Rendering &gt; Render Pipeline Converter</strong>. Choose <strong>Convert Built-In to 2D (URP)</strong> for a 2D project, or <strong>Built-In to URP</strong> for a 3D project. Assuming that your project is 3D, you&#39;ll need to select the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/features/rp-converter.html">appropriate</a> <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/features/rp-converter.html">converters:</a></p>
<ul>
<li><strong>Rendering Settings:</strong> Select this to create multiple Render Pipeline setting assets that will match Built-In Render Pipeline Quality settings as closely as possible. This lets you test different Quality Levels more efficiently. See <a href="#page-21-0">the section</a> on comparing Built-In Render Pipeline and URP Quality options for more details.</li>
<li><strong>Material Upgrade</strong>: Use this to convert materials from the Built-In Render Pipeline to URP.</li>
<li><strong>Animation Clip Converter:</strong> This converts animation clips. It runs once the Material Upgrade converter finishes.</li>
<li><strong>Read-only Material Converter:</strong> This converts the prebuilt, read-only Materials included in a Unity project. It indexes the project and creates the temporary .index file. Note that it can take significant time.</li>
</ul>
<h2 id="-span-id-page-20-0-span-converting-custom-shaders"><span id="page-20-0"></span>Converting custom shaders</h2>
<p>Custom shaders are not converted using the Material Upgrade converter. The <a href="#page-92-0">Shaders</a> and <a href="#page-137-0">Shader Graph s</a>ections outline the steps for converting custom Built-In Render Pipeline shaders to URP. Using <a href="https://docs.unity3d.com/Packages/com.unity.shadergraph@17.0/manual/index.html?">Shader Graph</a> is often the quickest way to update a custom shader to URP.</p>
<p>There are several different URP shaders including:</p>
<ul>
<li><strong>Universal Render Pipeline/Lit</strong>: This physically based render (PBR) shader, similar to the Built-In Standard Shader, can be used to represent most real-life materials. It supports all the Standard Shader features with both metallic and specular workflows.</li>
<li><strong>Universal Render Pipeline/Simple Lit</strong>: This uses a Blinn-Phong model, and is suitable for low-end mobile devices or games that don&#39;t use PBR workflows.</li>
<li><strong>Universal Render Pipeline/Baked Lit</strong>: Use this shader for stylised games or apps that only require <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightMode-Baked.html">baked lighting</a> via <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/Lightmapping.html">lightmaps</a>, <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightProbes.html">light probes</a> and <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-concept.html">Adaptive</a> <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-concept.html">Probe</a> <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-concept.html">Volumes</a> (APVs). This shader is not <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/shading-model.html#physically-based-shading">Physically Based</a> and has no real-time lighting, so all real-time relevant shader keywords and variants are <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/shader-stripping.html">stripped</a> from the shader code, making it faster to calculate.</li>
<li><strong>Universal Render Pipeline/Complex Lit</strong>: The Complex Lit shader contains all the functionality of the Lit shader and adds advanced material features. Some features in this shader might be more resource-intensive and require <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/SL-ShaderCompileTargets.html">Unity Shader Model 4.5</a> hardware.</li>
<li><strong>Universal Render Pipeline/Unlit</strong>: This is a GPU performant shader that doesn&#39;t use lighting equations.</li>
<li><strong>Universal Render Pipeline/Terrain/Lit:</strong> This is suitable to use with the Terrain Tools package.</li>
<li><strong>Universal Render Pipeline/Particles/Lit:</strong> This particle shader uses a PBR lighting model.</li>
<li><strong>Universal Render Pipeline/Particles/Unlit:</strong> This unlit particle shader is light on the GPU.</li>
</ul>
<p>Although Simple Lit replaces many legacy/mobile shaders, the performance is not the same. Legacy/mobile shaders only partially evaluate lighting, whereas Simple Lit considers all lights as defined by the URP Asset.</p>
<p>Refer to <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/upgrading-your-shaders.html?">this table</a> in our URP documentation to see how each URP shader maps to its Built-In Render Pipeline equivalent.</p>
<p><span id="page-21-0"></span><img src="_page_21_Picture_0.jpeg" alt=""></p>
<p>Once you select one or more of the above converters, either click <strong>Initialize Converters</strong> or <strong>Initialize And Convert</strong>. Whichever option you choose, the project will be scanned and those assets that need converting will be added to each of the converter panels. If you choose <strong>Initialize Converters</strong> you can limit the conversions by deselecting the items using the checkbox provided for each one. At this stage, click <strong>Convert Assets</strong> to start the conversion process. If you choose <strong>Initialize And Convert</strong>, the conversion starts automatically after the converters are initialized. Once it&#39;s complete you might be asked to reopen the scene that is active in the Editor.</p>
<table>
<thead>
<tr>
<th></th>
<th>Render Pipeline Converter</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Render Pipeline Converter</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Built-in to URP</td>
<td>The Render Pipeline Converter performs the following tasks:<br>· Converts project clements from the Built-in Render Pipeline to URP.<br>* Upgrades assets from earlier URP versions to the current URP version.</td>
<td></td>
</tr>
<tr>
<td></td>
<td>This process makes irreversible changes to the project. Back up your project before proceeding,</td>
<td></td>
</tr>
<tr>
<td>Built-in to URP</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Material Upgrade<br>S</td>
<td></td>
<td>31 items</td>
</tr>
<tr>
<td>This will upgrade your materials.</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>10<br>-31 A 0 80</td>
</tr>
<tr>
<td>V<br>Dacal</td>
<td>Packages/com.unity.render-pipelines.universal/Ri</td>
<td></td>
</tr>
<tr>
<td>PolygonWestern_Material_02_A</td>
<td>Assets/PolygonWestern/Materials/PolygonWeste</td>
<td>- 9</td>
</tr>
<tr>
<td>&lt; PolygonWestern_Material_01_B</td>
<td>Assets/PolygonWestern/Materials/PolygonWeste</td>
<td>- 9</td>
</tr>
<tr>
<td>65819<br>&gt;</td>
<td>Assets/PolygonWestern/Materials/Glass.mat</td>
<td>- 12</td>
</tr>
<tr>
<td>V BackgroundCard_01</td>
<td>Assets/PolygonWestern/Materials/Misc/Backgrou</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Initialize Converters</td>
<td></td>
<td>Convert Assets</td>
</tr>
</tbody>
</table>
<p>The Render Pipeline Converter</p>
<h3 id="comparing-quality-options-between-the-built-in-render-pipeline-and-urp">Comparing Quality options between the Built-In Render Pipeline and URP</h3>
<p>There are several default Quality options available in the Built-In Render Pipeline, from Very low to Ultra. The Quality settings impact the fidelity of the scene, including Texture resolution, lighting, shadow rendering, and so on.</p>
<p><span id="page-22-0"></span>Go to <strong>Edit &gt; Project Settings</strong> and select the <strong>Quality</strong> panel. Here, you can switch between these Quality options by picking the current quality. This will change the render settings used by the Scene and Game views. You can also edit each of the Quality options from this panel.</p>
<p>If you select the <strong>Rendering Settings</strong> option while using the Render Pipeline Converter and switching from the Built-In Render Pipeline to URP, a set of URP Assets that attempt to match the Built-In Render Pipeline Quality options will be created. The first table below shows how the Built-In Render Pipeline maps to URP for Low settings, while the second table displays a comparison for High settings. In both the Built-In Render Pipeline and URP, settings are chosen via the Quality panel. The URP Asset settings are available via the Inspector when selecting a URP Asset. Refer to the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/universalrp-asset.html?">URP documentation</a> for more details.</p>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Built-in Render<br>Pipeline</th>
<th>URP</th>
<th>URP Asset settings</th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Pixel Light Count</td>
<td>0</td>
<td>Not applicable<br>(NA) *</td>
<td>NA</td>
</tr>
<tr>
<td>Anti-aliasing</td>
<td>Disabled</td>
<td>NA</td>
<td>Disabled</td>
</tr>
<tr>
<td>Render Scale</td>
<td>NA</td>
<td>NA</td>
<td>1</td>
</tr>
<tr>
<td>Real-time Reflection Probes</td>
<td>No</td>
<td>No</td>
<td>NA</td>
</tr>
<tr>
<td>Resolution Scaling Fixed DPI<br>Factor</td>
<td>1</td>
<td>1</td>
<td>NA</td>
</tr>
<tr>
<td>VSync Count</td>
<td>Don&#39;t sync</td>
<td>Don&#39;t sync</td>
<td>NA</td>
</tr>
<tr>
<td>Depth Texture</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
<tr>
<td>Opaque Texture</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
<tr>
<td>Opaque Downsampling</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Terrain Holes</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>HDR</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>Textures</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Texture Quality</td>
<td>Half res</td>
<td>Half res</td>
<td>NA</td>
</tr>
<tr>
<td>Anisotropic Textures</td>
<td>Disabled</td>
<td>Disabled</td>
<td>NA</td>
</tr>
<tr>
<td>Texture Streaming</td>
<td>No</td>
<td>No</td>
<td>NA</td>
</tr>
<tr>
<td>Particles</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Soft Particles</td>
<td>No</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Particle Raycast Budget</td>
<td>16</td>
<td>16</td>
<td>NA</td>
</tr>
<tr>
<td>Terrain</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Billboards Face Camera<br>Position</td>
<td>No</td>
<td>No</td>
<td>NA</td>
</tr>
</tbody>
</table>
<h4 id="-built-in-render-pipeline-to-urp-low-settings-"><strong>Built-In Render Pipeline to URP: Low settings</strong></h4>
<p><img src="_page_23_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Shadows</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Shadowmask Mode</td>
<td>Shadowmask</td>
<td>Shadowmask</td>
<td>NA</td>
</tr>
<tr>
<td>Shadows</td>
<td>Disabled</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>Low resolution</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Projection</td>
<td>Stable fit</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Distance</td>
<td>20</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Near Plane Offset</td>
<td>3</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Cascades</td>
<td>No Cascades</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Cascade splits</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Working unit</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Depth Bias</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Normal Bias</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Soft Shadows</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Async Asset Upload</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Time Slice</td>
<td>2</td>
<td>2</td>
<td>NA</td>
</tr>
<tr>
<td>Buffer Size</td>
<td>16</td>
<td>16</td>
<td>NA</td>
</tr>
<tr>
<td>Persistent Buffer</td>
<td>Yes</td>
<td>Yes</td>
<td>NA</td>
</tr>
<tr>
<td>Level of Detail</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LOD Bias</td>
<td>0.4</td>
<td>0.4</td>
<td>NA</td>
</tr>
<tr>
<td>Maximum LOD level</td>
<td>0</td>
<td>0</td>
<td>NA</td>
</tr>
<tr>
<td>Meshes</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Skin Weights</td>
<td>4 bones</td>
<td>4 bones</td>
<td>NA</td>
</tr>
<tr>
<td>Lighting</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Main Light:</td>
<td>NA</td>
<td>NA</td>
<td>Per pixel</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Additional Lights:</td>
<td>NA</td>
<td>NA</td>
<td>Disabled</td>
</tr>
<tr>
<td>Per Object Limit</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Atlas Resolution</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Resolutiontiers</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Cookie AtlasResolution</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Cookie AtlasFormat</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Reflection probes:</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
</tbody>
</table>
<p><span id="page-24-0"></span><img src="_page_24_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Probe Blending</th>
<th>NA</th>
<th>NA</th>
<th>No</th>
</tr>
</thead>
<tbody>
<tr>
<td>Box Projection</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
<tr>
<td>Post-processing</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Grading Mode</td>
<td>NA</td>
<td>NA</td>
<td>Low Dynamic Range</td>
</tr>
<tr>
<td></td>
<td>NA</td>
<td>NA</td>
<td>16</td>
</tr>
<tr>
<td>Fast sRGB/Linear conversion</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
</tbody>
</table>
<p>* In URP, Pixel Light Count is handled using <strong>Additional Lights &gt; (Per pixel ) &gt; Per Object Limit</strong>.</p>
<h4 id="-built-in-render-pipeline-to-urp-high-settings-"><strong>Built-In Render Pipeline to URP: High settings</strong></h4>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Built-In Render<br>Pipeline</th>
<th>URP</th>
<th>URP Asset settings</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Pixel Light Count</td>
<td>2</td>
<td>Not applicable<br>(NA)</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Anti-aliasing</td>
<td>Disabled</td>
<td>NA</td>
<td>2x</td>
<td></td>
</tr>
<tr>
<td>Render Scale</td>
<td>NA</td>
<td>NA</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Real-time Reflection<br>Probes</td>
<td>Yes</td>
<td>Yes</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Resolution Scaling Fixed<br>DPI Factor</td>
<td>1</td>
<td>1</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>VSync Count</td>
<td>Every V Blank</td>
<td>Every V Blank</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Depth Texture</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
<td></td>
</tr>
<tr>
<td>Opaque Texture</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
<td></td>
</tr>
<tr>
<td>Opaque Downsampling</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Terrain Holes</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>HDR</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>Textures</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Texture Quality</td>
<td>Full res</td>
<td>Full res</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Anisotropic Textures</td>
<td>Disabled</td>
<td>Disabled</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Texture Streaming</td>
<td>No</td>
<td>No</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Particles</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Soft Particles</td>
<td>No</td>
<td>NA</td>
<td>NA</td>
<td></td>
</tr>
<tr>
<td>Particle Raycast Budget</td>
<td>256</td>
<td>256</td>
<td>NA</td>
</tr>
</tbody>
</table>
<p><img src="_page_25_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Terrain</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Billboards Face Camera<br>Position</td>
<td>Yes</td>
<td>Yes</td>
<td>NA</td>
</tr>
<tr>
<td>Shadows</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadowmask Mode</td>
<td>Distance<br>Shadowmask</td>
<td>Distance<br>Shadowmask</td>
<td>NA</td>
</tr>
<tr>
<td>Shadows</td>
<td>Hard and Soft<br>Shadows</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>Medium resolution</td>
<td>NA</td>
<td>2048</td>
</tr>
<tr>
<td>Shadow Projection</td>
<td>Stable fit</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Distance</td>
<td>40</td>
<td>NA</td>
<td>50</td>
</tr>
<tr>
<td>Shadow Near Plane Offset</td>
<td>3</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Shadow Cascades</td>
<td>2 Cascades</td>
<td>NA</td>
<td>2</td>
</tr>
<tr>
<td>Cascade splits</td>
<td>33/67</td>
<td>NA</td>
<td>12.5/33.8/3.8</td>
</tr>
<tr>
<td>Working unit</td>
<td>Percent</td>
<td>Percent</td>
<td>Metric</td>
</tr>
<tr>
<td>Depth Bias</td>
<td>NA</td>
<td>NA</td>
<td>1</td>
</tr>
<tr>
<td>Normal Bias</td>
<td>NA</td>
<td>NA</td>
<td>1</td>
</tr>
<tr>
<td>Soft Shadows</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>Async Asset Upload</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Time Slice</td>
<td>2</td>
<td>2</td>
<td>NA</td>
</tr>
<tr>
<td>Buffer Size</td>
<td>16</td>
<td>16</td>
<td>NA</td>
</tr>
<tr>
<td>Persistent Buffer</td>
<td>Yes</td>
<td>Yes</td>
<td>NA</td>
</tr>
<tr>
<td>Level of Detail</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LOD Bias</td>
<td>1</td>
<td>1</td>
<td>NA</td>
</tr>
<tr>
<td>Maximum LOD level</td>
<td>0</td>
<td>0</td>
<td>NA</td>
</tr>
<tr>
<td>Meshes</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Skin Weights</td>
<td>Unlimited</td>
<td>Unlimited</td>
<td>NA</td>
</tr>
<tr>
<td>Lighting</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Main Light:</td>
<td>NA</td>
<td>NA</td>
<td>Per pixel</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Additional Lights:</td>
<td>NA</td>
<td>NA</td>
<td>Per pixel</td>
</tr>
<tr>
<td>Per Object Limit</td>
<td>NA</td>
<td>NA</td>
<td>4</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>Shadow Atlas Resolution</td>
<td>NA</td>
<td>NA</td>
<td>2048</td>
</tr>
<tr>
<td>Shadow Resolution tiers</td>
<td>NA</td>
<td>NA</td>
<td>512/1024/2048</td>
</tr>
<tr>
<td>Cookie AtlasResolution</td>
<td>NA</td>
<td>NA</td>
<td>2048</td>
</tr>
</tbody>
</table>
<p><span id="page-26-0"></span></p>
<table>
<thead>
<tr>
<th>Cookie AtlasFormat</th>
<th>NA</th>
<th>NA</th>
<th>Color high</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reflection probes:</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>Probe Blending</td>
<td>NA</td>
<td>NA</td>
<td>Yes</td>
</tr>
<tr>
<td>Box Projection</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
<tr>
<td>Post-processing</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Grading Mode</td>
<td>NA</td>
<td>NA</td>
<td>Low Dynamic Range</td>
</tr>
<tr>
<td>LUT size</td>
<td>NA</td>
<td>NA</td>
<td>32</td>
</tr>
<tr>
<td>Fast sRGB/Linear<br>conversion</td>
<td>NA</td>
<td>NA</td>
<td>No</td>
</tr>
</tbody>
</table>
<h4 id="-anti-aliasing-"><strong>Anti-aliasing</strong></h4>
<p>In URP in Unity 6 you can select Temporal Anti-aliasing (TAA) as an anti-aliasing option for the Camera, via <strong>Camera &gt; Rendering &gt; Anti-aliasing</strong>.</p>
<table>
<thead>
<tr>
<th>Rendering</th>
<th></th>
<th>?)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Renderer</td>
<td>Default Renderer (Haunted Mansio ·</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Post Processing</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Anti-aliasing</td>
<td>Temporal Anti-aliasing (TAA)</td>
<td></td>
<td>D</td>
</tr>
<tr>
<td>Quality</td>
<td>High</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Contrast Adaptive ! ●</td>
<td></td>
<td>0</td>
</tr>
</tbody>
</table>
<p>TAA selected</p>
<p>URP in Unity 6 improves the overall quality of TAA without impacting performance. It provides better edge anti-aliasing (removing odd edge artifacts seen with the previous implementation) and better retention of texture quality. The output quality is now comparable to the low and medium SMAA presets but with better performance.</p>
<h3 id="how-to-work-with-quality-settings">How to work with Quality settings</h3>
<p>When using URP, quality settings are divided between the Quality panel and those for each URP Asset. The following table shows where each setting can be found.</p>
<h2 id="-span-id-page-27-0-span-quality-settings-when-using-urp"><span id="page-27-0"></span>Quality settings when using URP</h2>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Quality panel</th>
<th>URP Asset</th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Anti-aliasing</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Render Scale</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Resolution Scaling Fixed DPI Factor</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>VSync Count</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Depth Texture</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Opaque Texture</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Opaque Downsampling</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Terrain Holes</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>HDR</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Textures</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Texture Quality</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Anisotropic Textures</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Texture Streaming</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Particles</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Particle Raycast Budget</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Terrain</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Billboards Face Camera Position</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadowmask Mode</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Shadow Distance</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Shadow Cascades</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Cascade splits</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Working unit</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Depth Bias</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Normal Bias</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Soft Shadows</td>
<td></td>
<td>✅</td>
</tr>
</tbody>
</table>
<p><img src="_page_28_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Async Asset Upload</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Time Slice</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Buffer Size</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Persistent Buffer</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Level of Detail</td>
<td></td>
<td></td>
</tr>
<tr>
<td>LOD Bias</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Maximum LOD level</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Meshes</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Skin Weights</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>Lighting</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Main Light:</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Cast Shadows</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Shadow Resolution</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Additional Lights:</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Per Object Limit</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Cast Shadows</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Shadow Atlas Resolution</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Shadow Resolutiontiers</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Cookie AtlasResolution</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Cookie AtlasFormat</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Reflection probes:</td>
<td>✅</td>
<td></td>
</tr>
<tr>
<td>—<br>Probe Blending</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>—<br>Box Projection</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Post-processing</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Grading Mode</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>LUT size</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td>Fast sRGB/Linear conversion</td>
<td></td>
<td>✅</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>If you switch between Quality options, choose a <strong>Quality Level</strong> for the Render Pipeline Asset in the <strong>Quality</strong> panel via <strong>Project Settings</strong>. Note that if the Quality Level is not set, the Render Pipeline Asset will default to the one set as the Scriptable Render Pipeline Asset in the Graphics panel. This can cause some confusion as you attempt to adjust the Quality settings of a URP Asset. For instance, you might accidentally assume that the Quality Level set in the URP Asset is the one currently used by the Scene and Game views.</p>
<p><span id="page-29-0"></span><img src="_page_29_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Current Active Quality Level</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>Low</td>
<td></td>
</tr>
<tr>
<td></td>
<td>A Scriptable Render Pipeline is in use, some settings will not be used and are hidden</td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Render Pipeline Asset</td>
<td>(SUniversalRP-LowQuality (Universal Render Pipeline Asset)</td>
<td>0</td>
</tr>
<tr>
<td>Realtime Reflection Probes</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Resolution Scaling Fixed DPI Factor</td>
<td></td>
<td></td>
</tr>
<tr>
<td>VSync Count</td>
<td>Don&#39;t Sync</td>
</tr>
</tbody>
</table>
<p>Setting the Quality Level for the Render Pipeline Asset</p>
<h2 id="-span-id-page-29-1-span-modifying-a-urp-asset"><span id="page-29-1"></span>Modifying a URP Asset</h2>
<p>This image shows a URP Asset in the Inspector with all its available settings. See the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/universalrp-asset.html#rendering?">URP</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/universalrp-asset.html#rendering?">documentation</a> to learn more about each setting.</p>
<p><strong>Note:</strong> If you have the URP 2D Renderer enabled, some of the options related to 3D rendering in the URP Asset will not impact your final app or game. The 2D Renderer Asset is available under <strong>Scriptable Render Pipeline Settings</strong> via <strong>Edit &gt; Project Settings &gt; Graphics</strong>.</p>
<table>
<thead>
<tr>
<th>PC.High (Universal Render Pigeline Asset)</th>
<th>01<br>Oper</th>
</tr>
</thead>
<tbody>
<tr>
<td>* Rendering</td>
<td>1</td>
</tr>
<tr>
<td>Renderer List</td>
<td></td>
</tr>
<tr>
<td>D PC, High Renderer (Universal Renderer Data)</td>
<td>0<br>Defit</td>
</tr>
<tr>
<td></td>
<td>Set Default<br>0</td>
</tr>
<tr>
<td>PC, High ScreenRendener (Universal Renderer Data)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>+ =</td>
</tr>
<tr>
<td>Depth Texture</td>
<td>1</td>
</tr>
<tr>
<td>Opaque Texture<br>Opaque Downsampling</td>
<td>2 . Diffridae</td>
</tr>
<tr>
<td>Terrain Holes</td>
<td>1</td>
</tr>
<tr>
<td>OPU Resident Drawer</td>
<td>Instanced Drawing</td>
</tr>
<tr>
<td>Small-Miesh Screen-Percentage</td>
<td>0</td>
</tr>
<tr>
<td>GPU Declusion Culling</td>
<td>1</td>
</tr>
<tr>
<td>GRP Batcher</td>
<td>1</td>
</tr>
<tr>
<td>Dynamic Batching</td>
<td></td>
</tr>
<tr>
<td>Deport Frees</td>
<td>Disabled</td>
</tr>
<tr>
<td>Store Actions</td>
<td>Auto</td>
</tr>
<tr>
<td>T Quality</td>
<td></td>
</tr>
<tr>
<td>HOR</td>
<td>1</td>
</tr>
<tr>
<td>HOR Precision</td>
<td>32 Bits</td>
</tr>
<tr>
<td>Anti Allasing (MSAA)</td>
<td>Disabled</td>
</tr>
<tr>
<td>Render Scale</td>
<td></td>
</tr>
<tr>
<td>Upscaling Filter</td>
<td>Automotive</td>
</tr>
<tr>
<td>LOD Cress Face</td>
<td></td>
</tr>
<tr>
<td>LOO Cross Fade Dithering Type</td>
<td>Bloo Nolok</td>
</tr>
<tr>
<td>T Lighting</td>
<td>188</td>
</tr>
<tr>
<td>Main Light</td>
<td>Pat Pical<br>4</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>&gt;<br>2048</td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td></td>
</tr>
<tr>
<td>Light Probe System</td>
<td>Light Probe Groups</td>
</tr>
<tr>
<td>Additional Lights</td>
<td>Par Point</td>
</tr>
<tr>
<td>Per Object Limit</td>
<td></td>
</tr>
<tr>
<td>Cast Shadows<br>Shadow Atlas Resolution</td>
<td>V<br>2048</td>
</tr>
<tr>
<td>Shadow Resolution Thirs</td>
<td>Medium 552<br>Low 250<br>High 1024</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>Cookie Atlas Resolution</td>
<td>2048<br>Color High</td>
</tr>
<tr>
<td>Cookie Atus Format</td>
<td></td>
</tr>
<tr>
<td>Reflection Probes</td>
<td></td>
</tr>
<tr>
<td>Probe Biending</td>
<td>4</td>
</tr>
<tr>
<td>Box Projection</td>
<td>1</td>
</tr>
<tr>
<td>Mieed Lighting</td>
<td>&gt;</td>
</tr>
<tr>
<td>Use Rendering Layers</td>
<td>1<br>1</td>
</tr>
<tr>
<td>Light Cookies<br>SH Exaluation Mode</td>
<td>Acres</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadows</td>
<td>100</td>
</tr>
<tr>
<td>Max Distance<br>Working Unit</td>
<td>50<br>Metriq</td>
</tr>
<tr>
<td>Cascode Count</td>
<td>. 4</td>
</tr>
<tr>
<td>Spet 1</td>
<td>6.15<br>0</td>
</tr>
<tr>
<td>Spet 2</td>
<td>14.63</td>
</tr>
<tr>
<td>Special</td>
<td>26.8</td>
</tr>
<tr>
<td>Last Border</td>
<td>2.5</td>
</tr>
</tbody>
</table>
<p>The Quality panel for a URP Asset allows you to set the HDR format to 64-bit for better fidelity. However, be aware that this results in a performance hit and requires additional memory, so avoid this setting on low-end hardware.</p>
<p>Another feature of the Quality panel is the option to enable LOD Cross Fade. LOD is a technique to reduce the GPU cost needed to render distant meshes. As the Camera moves, different LODs will be swapped to provide the right level of quality. LOD Cross Fade allows for smoother transitions of different LOD geometries and avoids the harsh snapping and popping that occurs during a swap.</p>
<p>A URP Asset in the Inspector</p>
<h4 id="-span-id-page-30-0-span-gpu-resident-drawer-and-gpu-occlusion-culling-"><span id="page-30-0"></span><strong>GPU Resident Drawer and GPU occlusion culling</strong></h4>
<p><strong><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/urp/gpu-resident-drawer.html">GPU Resident Drawer</a></strong> is a new feature in Unity 6 that&#39;s available via the <strong>Rendering</strong> section of the URP Asset<strong>.</strong></p>
<p><img src="_page_30_Picture_3.jpeg" alt=""></p>
<p>The GPU Resident Drawer and GPU Occlusion Culling options available via the URP Asset in Unity 6</p>
<p>Notice from the screengrabs above that the batches necessary to render the garden environment from the URP 3D Sample scene in Editor mode is 3569. When GPU Resident Drawer is set to <strong>Instanced Drawing</strong> this drops to just 506.</p>
<p>The GPU Resident Drawer is a GPU-driven rendering system that&#39;s designed to optimize CPU time. It enables GameObjects to take advantage of the BatchRenderGroup API, so they can benefit from its faster batching and improved CPU performance.</p>
<p>With GPU Resident Drawer, you can author your game using GameObjects, and when processed, they will be ingested and rendered via a special fast path that handles better instancing. When you enable this feature, games that are CPU-bound due to a high number of draw calls will see a reduction in this bottleneck as the amount of draw calls is reduced.</p>
<p>The improvements you will see are dependent on the scale of your scenes and the amount of instancing you utilize. The more instanceable objects you render, the bigger the benefits gain.</p>
<p><img src="_page_31_Picture_0.jpeg" alt=""></p>
<p>GPU Resident Drawer is targeted for MeshRenderers. It will not handle Skinned Mesh Renderers, VFX Graphs, particle systems, or similar effects renderers. No changes to your existing content are required to take advantage of it.</p>
<p><strong>Note:</strong> GPU Resident Drawer requires the Forward+ renderer, and <strong>Project Settings &gt; Graphics &gt; BatchRendererGroup Variants</strong> needs to be set to <strong>Keep All</strong>.</p>
<table>
<thead>
<tr>
<th>Graphics</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Set Default Render Pipeline Asset</td>
<td>Sot the Default Render Pipeline Assot that Unity uses when you don&#39;t have assigned Rondor Pipeline Associative Lovel.</td>
<td></td>
</tr>
<tr>
<td>Default Render Pipeline</td>
<td>PC_RPAsset - Dither (Universal Render Pipeline Asset)</td>
<td>0</td>
</tr>
<tr>
<td>Shader Stripping</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lightmap Modes</td>
<td>Automatic</td>
<td></td>
</tr>
<tr>
<td>Fog Modes</td>
<td>Automatic</td>
<td></td>
</tr>
<tr>
<td>Instancing Variants</td>
<td>Strip Unused</td>
<td></td>
</tr>
<tr>
<td>BatchRendererGroup Variants</td>
<td>Keep All</td>
<td></td>
</tr>
<tr>
<td>Shader Loading<br>Log Shader Compilation</td>
<td>Strip if no Entities Graphics package<br>Strip All<br>V Keep All</td>
</tr>
</tbody>
</table>
<p>When you enable GPU Resident Drawer, <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/urp/gpu-culling.html">GPU occlusion culling</a> also becomes available as an option. This uses a GPU-driven approach to ensure you don&#39;t render things you can&#39;t see on the screen; depending on your content, it can reduce CPU work dramatically.</p>
<p><img src="_page_31_Figure_5.jpeg" alt=""></p>
<p>Viewing the Occlusion Test using the Rendering Debugger</p>
<p>To see if GPU occlusion culling is effective for your scene go to <strong>Window &gt; Analysis &gt; Rendering Debugger</strong>, and select <strong>GPU Resident Drawer &gt; Occlusion Test Overlay</strong>. This displays a heatmap of culled instances. The heatmap displays blue if there are few culled instances, through to red if there are many culled instances. If you enable this setting, culling might be slower.</p>
<h2 id="-span-id-page-32-0-span-lighting-in-urp"><span id="page-32-0"></span>Lighting in URP</h2>
<p>This section shows how lighting in URP in Unity 6 works, including covering techniques you can use to achieve balance between graphic fidelity and performance.</p>
<p>Start with these resources if you are new to lighting in Unity:</p>
<ul>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightingInUnity.html?">Lighting documentation</a></li>
<li><a href="https://cgcookie.com/posts/art-of-lighting-game-environments">The art of lighting game environments</a></li>
<li><a href="https://www.youtube.com/watch?v=wwm98VdzD8s">Real-time lighting in Unity</a></li>
<li><a href="https://youtu.be/hMnetI4-dNY">Harnessing light with the URP and the GPU Lightmapper</a></li>
</ul>
<h4 id="-choose-your-renderer-"><strong>Choose your renderer</strong></h4>
<p>URP offers different rendering techniques, each with its own strengths and weaknesses. The choice of rendering technique depends on the specific requirements and constraints of your project. Let&#39;s delve into the differences between Forward, Forward+, and Deferred rendering in (URP).</p>
<p><img src="_page_33_Picture_0.jpeg" alt=""></p>
<h4 id="-forward-rendering-"><strong>Forward rendering</strong></h4>
<table>
<thead>
<tr>
<th>How it works<br>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>Forward rendering is a traditional<br>rendering technique where each<br>object in the scene is rendered<br>individually and each pixel<br>computed separately. This means<br>that for every pixel on the screen,<br>Unity calculates the lighting and<br>shading for each object in the<br>scene that contributes to that<br>pixel&#39;s final color.</td>
<td>The workflow is relatively<br>It can be inefficient for<br>straight-forward to<br>rendering scenes with a<br>understand. It works well<br>large number of lights or<br>in scenes with a small<br>complex materials. This<br>number of lights and<br>is because it requires<br>simple materials.<br>multiple passes over<br>the scene for each light,<br>leading to increased<br>rendering overhead.</td>
</tr>
</tbody>
</table>
<h4 id="-forward-rendering-"><strong>Forward+ rendering</strong></h4>
<table>
<thead>
<tr>
<th>How it works</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>Forward+ rendering is an<br>enhancement that addresses<br>some of the limitations of Forward<br>rendering, particularly when<br>dealing with a large number of<br>lights. In Forward+ rendering,<br>lights are grouped into clusters,<br>and only objects within each<br>cluster are considered when<br>calculating lighting, rather than<br>processing every object in the<br>scene for each light.</td>
<td>It improves performance<br>compared to Forward<br>rendering, especially in<br>scenes with many lights.<br>It allows for more efficient<br>utilization of hardware<br>resources by reducing the<br>number of objects that<br>need to be considered for<br>each light.</td>
<td>It can still struggle<br>with extremely large<br>numbers of lights or<br>very complex scenes.<br>Additionally, implementing<br>Forward+ rendering may<br>require more effort and<br>optimization compared to<br>Forward rendering.</td>
</tr>
</tbody>
</table>
<h4 id="-urp-deferred-rendering-"><strong>URP Deferred rendering</strong></h4>
<table>
<thead>
<tr>
<th>How it works</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deferred rendering decouples the<br>lighting and shading calculations<br>from the geometry rendering<br>process. Geometry is first<br>rendered to a set of buffers (e.g.,<br>G-buffer) that store information</td>
<td>It&#39;s highly efficient for<br>scenes with a large<br>number of lights or<br>complex materials because<br>lighting calculations are<br>performed per-pixel rather</td>
<td>Deferred rendering has<br>its own set of challenges,<br>including increased<br>memory usage due to the<br>need to store additional<br>buffers, limitations with</td>
</tr>
<tr>
<td>about each pixel&#39;s position,<br>normals, and material properties.<br>Then, lighting calculations are<br>performed per-pixel based on<br>the information stored in these<br>buffers.</td>
<td>than per-object. This<br>allows for a large number<br>of lights to be rendered<br>with minimal performance<br>impact.</td>
<td>transparent objects, and<br>difficulty in handling<br>certain types of<br>lighting effects such as<br>volumetric lighting.</td>
</tr>
</tbody>
</table>
<p><img src="_page_34_Picture_0.jpeg" alt=""></p>
<p>The table below provides more detail about these three rendering options:</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Forward</th>
<th>Forward+</th>
<th>Deferred</th>
</tr>
</thead>
<tbody>
<tr>
<td>Maximum number of<br>real-time lights per<br>object</td>
<td>9</td>
<td>Unlimited;<br>per-Camera<br>limit applies</td>
<td>Unlimited</td>
</tr>
<tr>
<td>Per pixel normal<br>encoding</td>
<td>No<br>encoding<br>(accurate<br>normal<br>values)</td>
<td>No<br>encoding<br>(accurate<br>normal<br>values)</td>
<td>Two options:<br>—<br>Quantization of normals<br>in G-buffer (loss of<br>accuracy, better<br>performance)<br>—<br>Octahedron encoding<br>(accurate normals,<br>might have significant<br>performance impact on<br>mobile GPUs)<br>For more information, see<br>Encoding of normals in<br>G-buffer.</td>
</tr>
<tr>
<td>MSAA</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>GPU Resident Drawer</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Vertex lighting</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Camera stacking</td>
<td>Yes</td>
<td>Yes</td>
<td>Supported with a limitation:<br>Unity renders only the base<br>Camera using the Deferred<br>path; Unity renders all<br>overlay Cameras using the<br>Forward Rendering path</td>
</tr>
</tbody>
</table>
<p><span id="page-35-0"></span><img src="_page_35_Picture_0.jpeg" alt=""></p>
<p>Use the Universal Renderer Data Asset to switch between the rendering paths.</p>
<p><img src="_page_35_Figure_3.jpeg" alt=""></p>
<p>Choosing a rendering path.</p>
<p>When using Forward+, a number of URP Asset Lighting settings are overridden:</p>
<ul>
<li><strong>Main light</strong>: The value of this property is <strong>Per Pixel</strong>, regardless of the value you select.</li>
<li><strong>Additional lights</strong>: The value of this property is <strong>Per Pixel</strong>, regardless of the value you select.</li>
<li><strong>Additional Lights &gt; Per Object Limit</strong>: Unity ignores this property.</li>
<li><strong>Reflection Probes &gt; Probe Blending</strong>: Reflection probe blending is always on.</li>
</ul>
<h4 id="-light-settings-"><strong>Light settings</strong></h4>
<p>You set light properties in the three places listed here:</p>
<ul>
<li><strong>1. Window &gt; Rendering &gt; Lighting:</strong> This panel allows you to set lightmapping and environment settings, and view real-time and baked lightmaps. It is unchanged from the Built-In Render Pipeline to URP.</li>
<li><strong>2. Light Inspector:</strong> There are significant differences between the Built-In Render Pipeline and URP Inspectors. See th<a href="#page-38-0">e Light Inspector section</a> for details.</li>
<li><strong>3. URP Asset Inspector:</strong> This is the principal place where you will set shadows. Lighting in URP relies heavily on the settings chosen in this panel.</li>
</ul>
<p>Quality settings are handled via <strong>Edit &gt; Project Settings &gt; Quality</strong> in the Built-In Render Pipeline. In URP, this depends on the URP Asset settings which can be swapped using the</p>
<p><span id="page-36-0"></span><img src="_page_36_Picture_0.jpeg" alt=""></p>
<h4 id="-quality-panel-see-the-quality-settings-section-page-26-0-"><strong>Quality</strong> panel (see the <a href="#page-26-0">Quality settings section)</a>.</h4>
<p>As the focus here is on lighting, the methods apply to materials that use the shaders in the following table.</p>
<table>
<thead>
<tr>
<th>Shader</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Complex Lit</td>
<td>This shader has all the features of the Lit Shader. Select it when using<br>the Clear Coat option to give a metallic sheen to a car, for example. The<br>specular reflection is calculated twice – once for the base layer, and again<br>to simulate a transparent thin layer on top of the base layer.</td>
</tr>
<tr>
<td>Lit</td>
<td>The Lit Shader lets you render real-world surfaces, such as stone, wood,<br>glass, plastic, and metals with photorealistic quality. The light levels and<br>reflections look lifelike and react across various lighting conditions, from<br>bright sunlight to a dark cave.</td>
</tr>
<tr>
<td></td>
<td>This is the default choice for most materials that use lighting. It supports<br>baked, mixed, and real-time lighting, and works with Forward or Deferred<br>rendering.</td>
</tr>
<tr>
<td></td>
<td>It is a physically based shading (PBS) model. Due to the complexity of the<br>shading calculations, it&#39;s best to avoid using this shader on low-end mobile<br>hardware.</td>
</tr>
<tr>
<td>Simple Lit</td>
<td>This shader is not physically based. It uses a non-energy conserving Blinn<br>Phong shading model and gives a less photorealistic result. Nonetheless, it<br>can provide an excellent visual appearance. It is more suited to use on non<br>physically based projects when targeting low-end mobile devices.</td>
</tr>
<tr>
<td>Baked Lit</td>
<td>This shader provides a performance boost for objects that don&#39;t need to<br>support real-time lighting, including distant static objects that will never be<br>affected by dynamic objects, real-time lights, or dynamic shadows.</td>
</tr>
</tbody>
</table>
<h4 id="-urp-shaders-for-lit-scenes-"><strong>URP shaders for lit scenes</strong></h4>
<p><span id="page-37-0"></span><img src="_page_37_Picture_0.jpeg" alt=""></p>
<h4 id="-lit-or-simple-lit-"><strong>Lit or Simple Lit?</strong></h4>
<p>The choice between a Lit Shader and Simple Lit Shader is largely an artistic decision. It is easier for artists to get a realistic render using the Lit Shader, but if a more stylized render is desired, Simple Lit provides stellar results.</p>
<p><img src="_page_37_Picture_4.jpeg" alt=""></p>
<p><img src="_page_37_Picture_5.jpeg" alt=""></p>
<p>Comparing scenes rendered using different shaders: The top-left image uses the Lit Shader, the top-right, the Simple Lit Shader, and the bottom image, the Baked Lit Shader.</p>
<p>It&#39;s possible to implement your own custom lighting model by writing a custom shader or using Shader Graph (see the <a href="#page-137-0">Additional tools chapter)</a>.</p>
<p><span id="page-38-0"></span><img src="_page_38_Picture_0.jpeg" alt=""></p>
<h2 id="lighting-overview">Lighting overview</h2>
<p>Lights are divided into Main <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/universalrp-asset.html#lighting">Light and Additional Lights</a> in URP. The settings for the Main Light property affect the Directional Light. This is either the brightest light or the one set via <strong>Window &gt; Rendering &gt; Lighting &gt; Environment &gt; Sun Source</strong>.</p>
<table>
<thead>
<tr>
<th>Inspector</th>
<th>Navigation</th>
<th></th>
<th>· Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Scene Environment Realtime Lightmaps Baked Lightmaps</td>
<td></td>
</tr>
<tr>
<td>Environment</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Skybox Material</td>
<td></td>
<td>C Default-Skybox</td>
<td></td>
<td>O</td>
</tr>
<tr>
<td>Sun Source</td>
<td></td>
<td></td>
<td>Directional Light (Light)</td>
<td></td>
<td>O</td>
</tr>
<tr>
<td></td>
<td>Realtime Shadow Color</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Environment Lighting</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td></td>
<td>Skybox</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Intensity Multiplier</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Setting the Sun Source</p>
<p>Later in the guide, you&#39;ll learn how to use the URP Asset settings to set the number of dynamic lights that affect an object via the Object Per Light limit, which is capped at eight for the URP Forward Renderer, but Unlimited for Forward+ and Deferred. The number of dynamic lights that can be used per Camera is also limited by different hardware:</p>
<ul>
<li><strong>Desktop and console platforms</strong>: 1 main light, and 256 additional lights</li>
<li><strong>Mobile platforms</strong>: 1 main light, and 32 additional lights</li>
<li><strong>OpenGL ES 3.0 and earlier</strong>: 1 main light, and 16 additional lights</li>
</ul>
<h4 id="-light-inspector-"><strong>Light Inspector</strong></h4>
<p>The Light Inspector is one of three places where you can set up lighting.</p>
<p>The available properties for lights in URP are Directional, Spot, Point, and Area, though area lights only work in Baked Indirect Mode. See the <a href="#page-47-0">Light Mode</a> section for more details.</p>
<p><span id="page-39-0"></span></p>
<table>
<thead>
<tr>
<th>▼ &lt; Light</th>
<th></th>
<th>0<br>14</th>
</tr>
</thead>
<tbody>
<tr>
<td>T General</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Type</td>
<td>Directional</td>
<td></td>
</tr>
<tr>
<td>Mode</td>
<td>Realtime</td>
<td></td>
</tr>
<tr>
<td>V Emission</td>
<td></td>
<td>@</td>
</tr>
<tr>
<td>Light Appearance</td>
<td>Filter and Temperature</td>
<td></td>
</tr>
<tr>
<td>Filter</td>
<td></td>
<td>P</td>
</tr>
<tr>
<td>Temperature</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>5000</td>
<td>Kelvin</td>
</tr>
<tr>
<td>Intensity</td>
<td>2</td>
<td></td>
</tr>
<tr>
<td>Indirect Multiplier</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Cookie</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Render Mode</td>
<td>Auto</td>
<td></td>
</tr>
<tr>
<td>Rendering Layers</td>
<td>Default</td>
<td></td>
</tr>
<tr>
<td>Culling Mask</td>
<td>Everything</td>
<td>D</td>
</tr>
<tr>
<td>T Shadows</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Shadow Type</td>
<td>Soft Shadows</td>
<td>D</td>
</tr>
<tr>
<td>Realtime Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Strength</td>
<td></td>
<td>@ 1</td>
</tr>
<tr>
<td>Blas</td>
<td>Use settings from Render Pipeline Asset</td>
<td></td>
</tr>
<tr>
<td>Near Plane</td>
<td></td>
<td>0.2</td>
</tr>
<tr>
<td>Soft Shadows Quality</td>
<td>Low</td>
<td></td>
</tr>
<tr>
<td>Custom Shadow Layers</td>
<td></td>
</tr>
</tbody>
</table>
<p>The Light Inspector panel in URP</p>
<p>The image above shows how light properties are presented in the Light Inspector. The URP version has four groupings of controls, based on whether the light is Directional or Point, and an additional Shape grouping for Spot and Area lights.</p>
<h4 id="-lighting-a-new-scene-"><strong>Lighting a new scene</strong></h4>
<table>
<thead>
<tr>
<th>1 Inspector</th>
<th></th>
<th>@ Lighting</th>
<th>Project Settings</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Scene   Adaptive Probe Volumes   Environment   Realtime Lightmaps   Baked Lightmaps</td>
<td></td>
<td></td>
<td>8 *</td>
</tr>
<tr>
<td></td>
<td>Lighting Settings</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Lighting Settings Asset</td>
<td></td>
<td>% New Lighting Settings</td>
<td></td>
<td></td>
<td>O New</td>
<td>Clone</td>
</tr>
</tbody>
</table>
<p>Creating a Lighting Settings Asset</p>
<p>The first step to lighting a new scene for URP is to create a new Lighting Settings Asset (see image above). Open <strong>Window &gt; Rendering &gt; Lighting</strong>, and once you&#39;re on the <strong>Scene</strong> tab, click <strong>New Lighting Settings</strong>, and give the new asset a name. The settings that you apply in Lighting panels are now saved to it. Switch between settings by switching the Lighting Settings Asset.</p>
<p><span id="page-40-0"></span><img src="_page_40_Picture_0.jpeg" alt=""></p>
<h4 id="-ambient-or-environment-lighting-"><strong>Ambient or Environment lighting</strong></h4>
<p>The main ambient light is calculated from the panel accessible via <strong>Window &gt; Rendering &gt; Lighting &gt; Environment</strong>.</p>
<table>
<thead>
<tr>
<th>@ Inspector</th>
<th></th>
<th>. Lighting</th>
<th>Project Settings</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Scene</td>
<td></td>
<td></td>
<td></td>
<td>Adaptive Probe Volumes Environment Realtime Lightmaps</td>
<td>Baked Lightmaps</td>
<td></td>
<td>00</td>
</tr>
<tr>
<td>V Environment</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Skybox Material</td>
<td></td>
<td></td>
<td>@ Default-Skybox</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Sun Source</td>
<td></td>
<td></td>
<td></td>
<td>None (Light)</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Realtime Shadow Color</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>A</td>
</tr>
<tr>
<td></td>
<td>Environment Lighting</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td></td>
<td></td>
<td></td>
<td>Skybox</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Intensity Multiplier</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Environment Reflections</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td></td>
<td></td>
<td></td>
<td>Skybox</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Resolution</td>
<td></td>
<td></td>
<td>128</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Compression</td>
<td></td>
<td></td>
<td>Auto</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Intensity Multiplier</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Bounces</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>V Other Settings</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Fog</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Halo Texture</td>
<td></td>
<td></td>
<td></td>
<td>None (Texture 2D)</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
</tr>
<tr>
<td></td>
<td>Halo Strength</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Flare Fade Speed</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Flare Strength</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>● 1</td>
<td></td>
</tr>
<tr>
<td>Spot Cookie</td>
<td></td>
<td></td>
<td></td>
<td>C Soft</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
</tr>
</tbody>
</table>
<p>The available settings for lighting in the Environment panel</p>
<p>You can set Environment Lighting to use the scene&#39;s Skybox, with an option to adjust the Intensity, Gradient, or Color. Only the Gradient and Color modes update in real-time. The Skybox mode requires an on-demand bake to compute the ambient probe from the sky.</p>
<table>
<thead>
<tr>
<th>Environment Lighting<br>Source<br>Intensity Multiplier</th>
<th>Skybox</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Environment Lighting</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td>Gradient</td>
<td>œ</td>
</tr>
<tr>
<td>Sky Color</td>
<td></td>
<td>8</td>
</tr>
<tr>
<td>Equator Color</td>
<td>HDS</td>
<td>20</td>
</tr>
<tr>
<td>Ground Color</td>
<td>HDR</td>
<td></td>
</tr>
<tr>
<td>Environment Lighting</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td>Color</td>
<td>V</td>
</tr>
<tr>
<td>Ambient Color</td>
<td></td>
</tr>
</tbody>
</table>
<p>Environment Lighting options</p>
<p><span id="page-41-0"></span><img src="_page_41_Picture_0.jpeg" alt=""></p>
<h2 id="shadows">Shadows</h2>
<p>As discussed earlier, you need a Renderer Data object and a Render Pipeline Asset when using URP. The section on <a href="#page-12-0">setting up a project for URP</a> covers how to view your scene via Render Pipeline Asset, which you can use to define the fidelity of your shadows.</p>
<p><img src="_page_41_Figure_3.jpeg" alt=""></p>
<p>The URP Asset</p>
<h4 id="-main-light-shadow-resolution-"><strong>Main Light shadow resolution</strong></h4>
<p>The Lighting and Shadow groups in the URP Asset are key to setting up shadows in your scene. First, set the <strong>Main Light Shadow</strong> to <strong>Disabled</strong> or <strong>Per Pixel</strong>, then go to the checkbox to enable <strong>Cast Shadows</strong>. The last setting is the resolution of the shadow map.</p>
<p>If you&#39;ve worked with shadows in Unity before, you know that real-time shadows require rendering a shadow map that contains the depth of objects from the perspective of the light. The higher the resolution of this shadow map, the higher the visual fidelity – though both more processing power and increased memory are required. Factors that increase shadow processing include:</p>
<ul>
<li><ol>
<li>The number of Shadow Casters rendered in the shadow map this number for the Main Light depends on the Shadow Distance (far plane of shadow frustum)</li>
</ol>
</li>
<li><ol>
<li>Shadow Receivers that are visible (you have to encompass them all)</li>
</ol>
</li>
<li><ol>
<li>Shadow Cascades splits</li>
</ol>
</li>
<li><ol>
<li>Shadow filtering (soft shadows)</li>
</ol>
</li>
</ul>
<p>The highest resolution isn&#39;t always ideal. For example, the <strong>Soft Shadows</strong> option has the effect of blurring the map. In the following image of a cartoon-like haunted room, you can see that the chair in the foreground casts a shadow on the desk drawers, which appears too crisp when the resolution is greater than 1024.</p>
<p><img src="_page_42_Picture_1.jpeg" alt=""></p>
<p><img src="_page_42_Picture_2.jpeg" alt=""></p>
<p>Setting the shadow resolution for the Main Light: The resolution is set to 256 in the top-left image, 512 in the top-right image, 1024 in the middle-left image, 2048 in the middle-right image, and 4096 in the bottom image.</p>
<p><span id="page-43-0"></span><img src="_page_43_Picture_0.jpeg" alt=""></p>
<h4 id="-main-light-shadow-max-distance-"><strong>Main Light: Shadow Max Distance</strong></h4>
<p><img src="_page_43_Picture_3.jpeg" alt=""></p>
<p>Varying Max Distance for the Main Light Shadow: Top-left image – 10, top-right image – 30, bottom-left image – 60, bottom-right image – 400</p>
<p>Another important setting for the Main Light Shadow is Max Distance. This is set in scene units. In the image above, the poles are 10 units apart. The Max Distance varies from 10 to 400 units. Notice that only the first pole casts a shadow, and this is cut short at 10 units from the Camera location. At 60 units (bottom-left image), all shadows are in view – the shadow fidelity is adequate. When the Max Distance is much greater than the visible assets, the shadow map is being spread over too large an area. This means that the region in-shot has a much lower resolution than required.</p>
<p>The Max Distance property needs to relate directly to what the user can see, as well as the units used in the scene. Aim for the minimum distance that gives acceptable shadows (see note below). If the player only sees shadows from dynamic objects 60 units from the Camera, then set Max Distance to 60. When the Lighting Mode for Mixed Lights is set to <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightMode-Mixed-Shadowmask.html">Shadowmask</a>, the shadows of objects beyond Shadow Distance are baked. If this was a static scene then you would see shadows on all objects, but only dynamic shadows would be drawn up to the Shadow Distance.</p>
<p><span id="page-44-0"></span><img src="_page_44_Picture_0.jpeg" alt=""></p>
<h4 id="-shadow-cascades-"><strong>Shadow Cascades</strong></h4>
<p>As assets disappear into the distance due to perspective, it is convenient to decrease Shadow Resolution, thereby devoting more of the shadow map to shadows closer to the Camera. <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/shadow-cascades.html?">Shadow Cascades</a> can help with this.</p>
<p>The images below show the shadow map of the scene with the chair and desk in the haunted room. The cascade count is 1 in the image to the left. The map takes up the whole area. In the image to the right, the cascade count is 4. Notice that the map includes four different maps, with each area receiving a lower resolution map.</p>
<p>A cascade count of 1 is likely to give the best result for small scenes like this. But if your Max Distance is a large value, then a cascade count of 2 or 3 will give better shadows for foreground objects, as these receive a larger proportion of the shadow map. Notice that the chair in the left image is much bigger, resulting in a sharper shadow.</p>
<p><img src="_page_44_Picture_6.jpeg" alt=""></p>
<p>Shadow map when cascade count is set to 1 (left image) and 4 (right image)</p>
<p>You can adjust the start and end ranges for each section of the cascade using the draggable pointers, or by setting the units in the relevant fields (see following image). Always adjust Max Distance to a value that is a close fit for your scene and choose the slider positions carefully. If you use metric as the working unit, always choose the last cascade to be, at most, the distance of the last Shadow Caster. Adjusting the range of a Shadow Cascade</p>
<table>
<thead>
<tr>
<th>Shadows<br>40</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Max Distance</td>
<td>30.9</td>
<td></td>
</tr>
<tr>
<td>Working Unit</td>
<td>Metric</td>
<td>P</td>
</tr>
<tr>
<td>Cascade Count</td>
<td></td>
<td>4<br>0</td>
</tr>
<tr>
<td>Split 1</td>
<td></td>
<td>1,91344</td>
</tr>
<tr>
<td>Split 2</td>
<td></td>
<td>6.18</td>
</tr>
<tr>
<td>Split 3</td>
<td></td>
<td>9.09728</td>
</tr>
<tr>
<td>Last Border</td>
<td></td>
<td>13,3931</td>
</tr>
<tr>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0<br>2<br>1<br>1,900<br>4,3m<br>2.9m</td>
<td>3<br>B. Am</td>
<td>3-&gt;Falback<br>13 4m</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><span id="page-45-0"></span><img src="_page_45_Picture_0.jpeg" alt=""></p>
<h4 id="-additional-light-shadows-"><strong>Additional Light Shadows</strong></h4>
<table>
<thead>
<tr>
<th>3<br>Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Main Light</td>
<td>Per Pixel</td>
<td></td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>Disabled</td>
<td></td>
</tr>
<tr>
<td>Additional Lights<br>Per Object Limit<br>Cast Shadows</td>
<td>Per Vertex<br>V Per Pixel</td>
<td></td>
</tr>
<tr>
<td></td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Shadow Atlas Resoluti  1024</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution TicLow 128</td>
<td>Medium 256 High 512</td>
</tr>
</tbody>
</table>
<p>Settings available for Additional Lights in URP Asset</p>
<p>Having sorted the shadows for the Main Light, it&#39;s time to move on to <strong>Additional Lights Mode</strong>. Enable additional lights to cast shadows by setting the Additional Lights Mode for the URP Asset to <strong>Per Pixel</strong>. While the mode can be set to Disabled, Per Vertex, or Per Pixel (see above image), only the latter works with shadows.</p>
<p><strong>Note:</strong> URP does not support shadows for additional directional lights. Remember, the Main light is always the brightest Directional light. For additional lights with shadows, use a Point or Spot light.</p>
<p>Check the <strong>Cast Shadows</strong> box. Then, select the resolution of the <strong>Shadow Atlas</strong>. This is the map that will be used to combine all the maps for every light casting shadows. Bear in mind that a Point light casts six shadow maps, creating a cubemap, since it casts light in all directions. This makes a Point light the most demanding performance-wise. The individual resolution of an additional light shadow map is set using a combination of the three Shadow Resolution tiers, plus the resolution chosen via the Light Inspector when selecting the light in the Hierarchy window.</p>
<table>
<thead>
<tr>
<th>Shadows</th>
<th></th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Shadow Type</td>
<td>Soft Shadows</td>
<td></td>
</tr>
<tr>
<td>Baked Shadow Angle</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Realtime Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Strength</td>
<td></td>
<td>0.843</td>
</tr>
<tr>
<td>Bias</td>
<td>Use settings from Render Pipeline Asset</td>
<td></td>
</tr>
<tr>
<td>Near Plane</td>
<td></td>
<td>0.1</td>
</tr>
<tr>
<td>Soft Shadows Quality</td>
<td>Medium</td>
<td>&gt;</td>
</tr>
</tbody>
</table>
<p>Shadows group in the Light Inspector</p>
<p>Setting <strong>Shadow Type</strong> to <strong>Soft Shadows</strong> enables the <strong>Baked Shadow Angle</strong> slider. This property adds some artificial softening to the edges of shadows and gives them a more natural look. A new option in Unity 6 is available to switch the <strong>Soft Shadows Quality</strong> between Low, Medium, and High.</p>
<p>In the haunted room, there is a Spot light over the mirror and a Point light over the desk. There are also seven maps. To fit these seven maps onto a 1024px square map, the size of each map needs to be 256px or smaller. If you exceed this size, the resolution of shadow maps will shrink to fit the atlas, resulting in a warning message in the console.</p>
<table>
<thead>
<tr>
<th>Number of maps</th>
<th>Atlas tiling</th>
<th>Atlas size (multiply shadow tier size by)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1x1</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>2–4</td>
<td>2x2</td>
<td>2</td>
<td></td>
</tr>
<tr>
<td>5–16</td>
<td>4x4</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>Setting the Shadow Atlas size based on the number of Additional Lights shadow maps and the tier size chosen per map</p>
<p><img src="_page_46_Picture_4.jpeg" alt=""></p>
<p>Shadow Atlas for Additional Lights</p>
<p>The image above shows the six maps used by the Point light where the resolution is set to medium and the tier value to 256px. The Spot light has a resolution set to high, with a tier value of 512px.</p>
<p><span id="page-47-0"></span><img src="_page_47_Picture_1.jpeg" alt=""></p>
<p>This is a low-polygon version of the haunted room, lit with a Main Directional light, a Point light over the desk, and a Spot light over the mirror. All lights are real-time and casting shadows.</p>
<h2 id="light-modes">Light modes</h2>
<p>Environments have predominantly static geometry, so that if a light is static, you don&#39;t need to calculate the lighting and shadows for it repeatedly. You can calculate this once at design time, and then use that data when rendering the geometry. This is called lightmapping or baking.</p>
<p>Let&#39;s go through the steps for lightmapping using an FPS Sample project by Unity. The following screenshots are from this project, which you can download <a href="https://github.com/NikLever/Unity6E-book">here</a>. The scene via <strong>Inspection &gt; Scenes &gt; Small Indirect</strong> demonstrates how to use real-time and baked lighting in URP.</p>
<p><img src="_page_48_Picture_1.jpeg" alt=""></p>
<p>The Inspection &gt; Scenes &gt; Small Indirect scene from the Unity 6 URP e-book repository on GitHub.</p>
<ol>
<li>The scene from the FPS Sample project contains largely static geometry. To include the geometry in lightmapping, click the <strong>Static</strong> box to the right side of the Inspector.</li>
</ol>
<p><img src="_page_48_Picture_4.jpeg" alt=""></p>
<ol>
<li>Choose the lightmapping settings via <strong>Window &gt; Rendering &gt; Lighting &gt; Scene</strong>. Keep the Lightmap Resolution low while adjusting the settings. Once you have your desired settings, increase the value when generating the final lightmaps. Choose <strong>Progressive GPU</strong> to speed up the lightmap generation, if your GPU supports it.</li>
</ol>
<table>
<thead>
<tr>
<th>Lightmapping Settings</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Lightmapper</td>
<td>Progressive GPU</td>
<td>D</td>
</tr>
<tr>
<td>Importance Samp √</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Direct Samples</td>
<td></td>
<td>32</td>
</tr>
<tr>
<td>Indirect Samples -</td>
<td></td>
<td>256</td>
</tr>
<tr>
<td>Environment San-</td>
<td></td>
<td>256</td>
</tr>
<tr>
<td>Light Probe Sam  3</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Max Bounces</td>
<td>2</td>
<td></td>
</tr>
<tr>
<td>Filtering</td>
<td>Auto</td>
<td>D</td>
</tr>
<tr>
<td>Lightmap Resolution 30</td>
<td></td>
<td>texels per unit</td>
</tr>
<tr>
<td>Lightmap Padding 2</td>
<td></td>
<td>texels</td>
</tr>
<tr>
<td>Max Lightmap Size 2048</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Fixed Lightmap Size</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Use Mipmap Limits ✔</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lightmap Compres: Normal Quality</td>
<td></td>
<td>D</td>
</tr>
<tr>
<td>Ambient Occlusion V</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Max Distance</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Indirect Contribu-</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Direct Contributio</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>Directional Mode Directional</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Albedo Boost</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Indirect Intensity</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lightmap Paramete Default-Medium O New   Clone</td>
</tr>
</tbody>
</table>
<ol>
<li>Filtering blurs the map to minimize noise. This can result in gaps in a shadow where one object meets another. Use <strong>A-Trous</strong> filtering to minimize this artifact. See <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/progressive-lightmapper.html?">Progressive</a>  <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/progressive-lightmapper.html?">Lightmapping documentation</a> for more details on the settings available for lightmapping.</li>
</ol>
<p><img src="_page_49_Picture_3.jpeg" alt=""></p>
<p>How filtering affects the shadow between objects</p>
<p><img src="_page_50_Picture_0.jpeg" alt=""></p>
<ol>
<li>Make sure all static geometry has no overlapping UV values, or is generating lighting <strong>UVs</strong> on import.</li>
</ol>
<p><img src="_page_50_Picture_3.jpeg" alt=""></p>
<ol>
<li>Set <strong>Light Mode</strong> to <strong>Baked</strong> or <strong>Mixed</strong>. Select the light in the <strong>Hierarchy</strong> window and use the <strong>Inspector</strong>. Mixed lights will illuminate dynamic objects as well as static ones.</li>
</ol>
<table>
<thead>
<tr>
<th>&lt; &gt; Light</th>
<th></th>
<th>0 = :</th>
</tr>
</thead>
<tbody>
<tr>
<td>V General</td>
<td></td>
<td>B</td>
</tr>
<tr>
<td>Type</td>
<td>Directional</td>
<td>D</td>
</tr>
<tr>
<td>Mode</td>
<td>Mixed</td>
<td>P</td>
</tr>
<tr>
<td>Emission</td>
<td>Realtime</td>
<td></td>
</tr>
<tr>
<td>Light Appearance</td>
<td>V Mixed</td>
<td></td>
</tr>
<tr>
<td>Filter</td>
<td>Baked</td>
<td></td>
</tr>
<tr>
<td>Tammaratura</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><ol>
<li>When using mixed lights, set the <strong>Light Mode</strong> to <strong>Baked Indirect</strong>, <strong>Subtractive</strong>, or <strong>Shadowmask</strong> via <strong>Window &gt; Rendering &gt; Lighting &gt; Scene</strong>.<ul>
<li><strong>a. <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightMode-Mixed-BakedIndirect.html">Baked Indirect:</a></strong> Only the indirect light contribution will be baked into the lightmaps and light probes (the bounces of the lights only). Direct lighting and shadows will be real-time. This is an expensive option and not ideal for mobile platforms. However, it does mean that you get correct shadows and direct light for both static and dynamic geometry.</li>
</ul>
</li>
</ol>
</li>
<li><strong>b. <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightMode-Mixed-Subtractive.html">Subtractive:</a></strong> Here, you bake the direct lighting from a Directional light set to Mixed into the static geometry, and subtract the lighting from shadows cast by dynamic geometry. This results in the static geometry unable to cast a shadow on dynamic objects, unles<a href="#page-57-0">s light probes</a> or Adaptive Probe Volumes (APV) are used, which can cause unpleasant visual discontinuities. URP calculates an estimate of the contribution of the light from the Directional Light and subtracts that from the baked Global Illumination. The estimate is clamped by the Real-time Shadow Color setting in the Environment section of the Lighting window, so the color subtracted is never darker than this color. Then choose the minimum color of your subtracted value and the original baked color. While this mode is the most suitable option for low-end hardware, it cannot correctly combine baked and real-time shadows at runtime, leading to artifacts. This trade-off prioritizes performance over quality.</li>
<li><strong>c. <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightMode-Mixed-Shadowmask.html?">Shadowmask:</a></strong> Though similar to Baked Indirect Mode, Shadowmask combines both dynamic and baked shadows, rendering shadows at a distance. It does this by using an additional Shadowmask texture and storing additional information in the light probes. This provides the highest fidelity shadows, but is also the most expensive option in terms of memory use and performance. Visually, it&#39;s identical to Baked Indirect for shots up close. The difference is apparent when looking in the far distance, making it well-suited for open-world scenes. Due to the processing cost, it&#39;s recommended for mid- to high-end hardware only.</li>
</ul>
<table>
<thead>
<tr>
<th>Mixed Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Baked Global Illumination ✔</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lighting Mode</td>
<td>Baked Indirect</td>
<td></td>
</tr>
<tr>
<td>Mixed lights provide re √ Baked Indirect<br>lightmaps and light pro</td>
<td>Subtractive</td>
<td></td>
</tr>
<tr>
<td>Lightmapping Settings</td>
<td>Shadowmask</td>
</tr>
</tbody>
</table>
<p><img src="_page_52_Picture_0.jpeg" alt=""></p>
<ol>
<li>Adjust the <strong>Lightmap Scale</strong> via <strong>Asset &gt; Inspector &gt; Mesh Renderer &gt; Lightmapping &gt; Scale In Lightmap</strong>, so that distant objects take up less space on the lightmap. The following image shows the texel size of the background rock lightmap with a setting varying from 0.05 to 0.5.</li>
</ol>
<p><img src="_page_52_Picture_3.jpeg" alt=""></p>
<ol>
<li>Click <strong>Generate Lighting</strong> to bake. The baking time depends on the number of static objects, lights set to mixed or baked mode, and the settings chosen for lightmapping, particularly the Max Lightmap Size and the Lightmap Resolution. Baking time is proportional to the number of rays used in baking so Sample Count (Direct Samples, Indirect Samples and Environment Samples) also have a direct effect on baking time.</li>
</ol>
<p><img src="_page_52_Picture_5.jpeg" alt=""></p>
<p>Bake your lightmap via <strong>Window &gt; Rendering &gt; Lighting &gt; Generate Lighting</strong>.</p>
<p><span id="page-53-0"></span>9. An interactive baking feature is new in Unity 6 with Draw Modes active (1)* and Baked Lightmap selected (2). A new panel is displayed with a Preview option (3). While you are in this mode the changes made do not affect the generated data. This feature enables a technical artist to tweak the properties and see how changes could affect the rendering without destroying a previous bake that might have taken a long time to calculate.</p>
<p>*Numbers refer to the image below.</p>
<p><img src="_page_53_Picture_3.jpeg" alt=""></p>
<p>Activating interactive preview mode</p>
<p>Unity also now provides a <strong>Baking Profile</strong>. This can be found in the <strong>Lighting</strong> window when using the GPU backend in on-demand mode, and offers users a tradeoff between performance and GPU memory usage.</p>
<table>
<thead>
<tr>
<th>GPU Baking Device<br>GPU Baking Profile</th>
<th>Highest Performance<br>High Performance</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>V Automatic</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Low Memory Usage</td>
<td></td>
</tr>
<tr>
<td>Scenario Size</td>
<td>Lowest Memory Usage</td>
<td></td>
</tr>
<tr>
<td>Baking Set Size</td>
<td>11-1 MG</td>
</tr>
</tbody>
</table>
<p>GPU Baking Profile</p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p>Since the 2019 release, Unity has provided a system for automatically generating baked environment lighting in scenes that haven&#39;t been baked explicitly. This system was known as the SkyManager. However the SkyManager was causing confusion for users as the automatic behavior wasn&#39;t clear, and was only present in a few specific situations. Additionally, the system caused differences in the behavior of the Editor and built Player, sometimes leading to the environment lighting being unexpectedly missing.</p>
<p><span id="page-54-0"></span><img src="_page_54_Picture_0.jpeg" alt=""></p>
<p>In Unity 6 the SkyManager is replaced with a new default Lighting Data Asset in the Editor, which is assigned to newly created scenes. The asset contains environment lighting matching the default settings for environment lighting. If you change these settings using the Skybox Mode, you&#39;ll have to manually rebake lighting using the <strong>Generate Lighting</strong> button in the Lighting Window.</p>
<h4 id="-more-resources-"><strong>More resources:</strong></h4>
<ul>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/Lightmappers.html?">Lightmapping</a> documentation</li>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/class-LightingSettings.html?">Lighting Settings Asset</a> documentation</li>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightingExplorer.html?">Lighting Explorer</a> documentation</li>
<li><a href="https://blog.unity.com/engine-platform/5-common-lightmapping-problems-and-tips-to-help-you-fix-them">5 common lightmapping problems and tips to help you fix them</a></li>
</ul>
<h3 id="rendering-layers">Rendering Layers</h3>
<p>The <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/features/rendering-layers.html?">Rendering Layers</a> feature lets you configure certain lights to affect only specific GameObjects so you can emphasize and draw attention to them in a scene. In the image below, the syringe, a key collectable, appears in a shaded part of the scene. With a Rendering Layer, it becomes visible and helps ensure that the player doesn&#39;t miss picking it up.</p>
<p><img src="_page_54_Picture_10.jpeg" alt=""></p>
<p>Highlighting an object using Rendering Layers</p>
<p><img src="_page_55_Picture_0.jpeg" alt=""></p>
<p>Here are the steps for setting up Rendering Layers.</p>
<ol>
<li>Select the <strong>URP Asset</strong>. In the Lighting section, click the vertical ellipsis icon (⁝) and select <strong>Advanced Properties</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Main Light</td>
<td>Per Pixel</td>
<td></td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>&gt;</td>
<td>✔ Advanced Properties</td>
</tr>
<tr>
<td>Shadow Resolution 2048</td>
<td></td>
<td>&gt;</td>
</tr>
</tbody>
</table>
<ol>
<li>A new setting, <strong>Use Rendering Layers</strong>, will appear under the Lighting section.</li>
</ol>
<p><img src="_page_55_Picture_6.jpeg" alt=""></p>
<ol>
<li>Rename a Rendering Layer via <strong>Project Settings &gt; Tags and Layers &gt; Rendering Layers</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>Memory Settings<br>Package Manager</th>
<th>· Tags and Layers</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Physics<br>Settings</td>
<td>Tags</td>
<td></td>
</tr>
<tr>
<td>Physics 2D</td>
<td>Sorting Layers</td>
<td></td>
</tr>
<tr>
<td>Player<br>Preset Manager</td>
<td>Layers<br>A</td>
<td></td>
</tr>
<tr>
<td>Quality</td>
<td>V Rendering Layers</td>
<td></td>
</tr>
<tr>
<td>Scene Template</td>
<td>Layer O</td>
<td>Dafault</td>
</tr>
<tr>
<td>Script Execution Order<br>Services</td>
<td>Layer 1</td>
<td>Highlight</td>
</tr>
<tr>
<td>ShaderGraph</td>
<td>Layer 2</td>
<td>Light Layer Z</td>
</tr>
<tr>
<td>Tags and Layers</td>
<td>Layer 3</td>
<td>Light Layer 3</td>
</tr>
<tr>
<td>TextMesh Pro</td>
<td>aver A</td>
<td>I ight I aver 4</td>
</tr>
</tbody>
</table>
<ol>
<li>The <strong>Light Inspector &gt; Rendering</strong> section includes a <strong>Rendering Layers</strong> drop-down. A light can contribute to more than one layer.</li>
</ol>
<p><img src="_page_55_Figure_10.jpeg" alt=""></p>
<p><img src="_page_56_Picture_0.jpeg" alt=""></p>
<ol>
<li>With Rendering Layers enabled, create a new light and set up a custom shadow layer. The new light can cast shadows from the scene&#39;s <strong>Main Light</strong> or from its own frustum.</li>
</ol>
<table>
<thead>
<tr>
<th>Shadows</th>
<th></th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>Shadow Type</td>
<td>Soft Shadows</td>
<td></td>
</tr>
<tr>
<td>Realtime Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Strength</td>
<td></td>
<td>@ 1</td>
</tr>
<tr>
<td>Bias</td>
<td>Use settings from Render Pipeline Asse▼</td>
<td></td>
</tr>
<tr>
<td>Near Plane</td>
<td></td>
<td>0.1</td>
</tr>
<tr>
<td>Soft Shadows Qua Low</td>
<td></td>
<td>&gt;</td>
</tr>
<tr>
<td>Custom Shadow Lay ✔</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Layer</td>
<td>Default</td>
<td>D</td>
</tr>
<tr>
<td></td>
<td>Nothing</td>
<td></td>
</tr>
<tr>
<td>V Universal Additiona</td>
<td>Everything</td>
<td>(2)</td>
</tr>
<tr>
<td></td>
<td>Default<br>V</td>
<td></td>
</tr>
<tr>
<td>A</td>
<td>Highlight</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Light Layer 2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Light Layer 3</td>
</tr>
</tbody>
</table>
<ol>
<li>Lastly, select the object this applies to in the <strong>Hierarchy</strong> window and then set the <strong>Rendering Layer Mask</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>Additional Settings</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Motion Vectors</td>
<td>Per Object Motion</td>
<td></td>
</tr>
<tr>
<td>Dynamic Occlusion</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Rendering Layer Mask Default, Highlight</td>
<td></td>
</tr>
</tbody>
</table>
<p>This can also be dynamically set in code.</p>
<pre><code>Renderer renderer = GetComponent&lt;Renderer&gt;()<span class="hljs-comment">;</span>
int layerID = <span class="hljs-number">1</span><span class="hljs-comment">;</span>
int mask = <span class="hljs-number">1</span> &lt;&lt; layerID<span class="hljs-comment">;</span>
renderer.renderingLayerMask = (uint)mask<span class="hljs-comment">;</span>
</code></pre><h2 id="-span-id-page-57-0-span-light-probes"><span id="page-57-0"></span>Light probes</h2>
<p>As covered in the <a href="#page-47-0">light modes section</a>, you can combine baked and dynamic objects using Mixed Lighting Mode. When using Mixed Lighting Mode it&#39;s recommended to also add probes to your scene. With Unity 6 there are two options: light probes and the new Adaptive Probe Volumes (APV). The two options solve the same problem, namely allowing dynamic objects to move through a scene and be affected by global illumination.</p>
<p>A probe is simply a point in your scene. At design time the global illumination at this location is calculated. At run time, when rendering a frame, a URP shader that includes lighting calculations uses a blend of the nearest probes for global illumination values.</p>
<p><strong>Note:</strong> Global illumination (GI) is a system that models how light bounces off surfaces onto other surfaces, to create indirect light, rather than being limited to just the light that hits a surface directly from a direct light source.</p>
<h4 id="-light-probes-"><strong>Light probes</strong></h4>
<p><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightProbes.html">Light probe</a>s save the light data at a particular position within an environment when you bake the lighting by clicking <strong>Generate Lighting</strong> via <strong>Window &gt; Rendering &gt; Lighting</strong> panel. This ensures that the illumination of a dynamic object moving through an environment reflects the lighting levels used by the baked objects. In a dark area it will be dark, and in a lighter area it will be brighter. Sampling is per object so for large objects this can lead to lighting anomalies if an object extends from a dark to a light area. If this is a problem for your scene then consider using APVs, which are sampled per pixel (see the section on APVs later on in the guide).</p>
<p><strong>Note:</strong> You&#39;ll need to ensure that active URP Asset has <strong>Lighting &gt; Light Probe System</strong> set to <strong>Light Probe Group</strong> when using light probes:</p>
<table>
<thead>
<tr>
<th>Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Main Light</td>
<td>Per Pixel</td>
<td>P</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>2048</td>
<td></td>
</tr>
<tr>
<td>Light Probe System</td>
<td>V Light Probe Groups</td>
<td></td>
</tr>
<tr>
<td>Additional Lights</td>
<td>Adaptive Probe Volumes</td>
<td></td>
</tr>
<tr>
<td>Per Object Limit</td>
<td>D</td>
<td>4</td>
</tr>
</tbody>
</table>
<p><img src="_page_58_Picture_0.jpeg" alt=""></p>
<p>Below, you can see the robot character inside and outside of the hangar in the FPS Sample: The Inspection.</p>
<p><img src="_page_58_Picture_3.jpeg" alt=""></p>
<p>The robot inside and outside of the cave, with lighting level affected by light probes</p>
<p>To create light probes, right-click in the <strong>Hierarchy</strong> window and choose <strong>GameObject &gt; Light &gt; Light Probe Group</strong>.</p>
<table>
<thead>
<tr>
<th>Light</th>
<th>&gt;</th>
<th>Directional Light</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Video</td>
<td>&gt;</td>
<td>Point Light</td>
<td></td>
</tr>
<tr>
<td>UI Toolkit</td>
<td>&gt;</td>
<td>Spot Light</td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td>&gt;</td>
<td>Area Light</td>
<td></td>
</tr>
<tr>
<td>Spline</td>
<td>&gt;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Volume</td>
<td>&gt;</td>
<td>Reflection Probe</td>
<td></td>
</tr>
<tr>
<td>Camera</td>
<td></td>
<td>Adaptive Probe Volume</td>
<td></td>
</tr>
<tr>
<td>Cinemachine</td>
<td>A</td>
<td>Probe Adjustment Volume</td>
<td></td>
</tr>
<tr>
<td>Visual Scripting Scene Variables</td>
<td></td>
<td>Light Probe Group</td>
</tr>
</tbody>
</table>
<p>Creating a new GameObject for the Light Probe Group</p>
<p>Initially, there will be a cube of probes, eight in total. To view and edit the positioning of the probes and add additional ones, select the <strong>Light Probe Group</strong> in the <strong>Hierarchy</strong> window, and in the Scene view click <strong>Tools &gt; Edit Light Probes</strong>. Be sure to activate the light probes gizmos.</p>
<p><img src="_page_59_Figure_5.jpeg" alt=""></p>
<p>Add or remove light probes and modify their position from the Inspector.</p>
<p><img src="_page_60_Picture_0.jpeg" alt=""></p>
<p>The Scene view will now be in an editing mode where only light probes can be selected. Use the Move tool to move them around.</p>
<p><img src="_page_60_Picture_2.jpeg" alt=""></p>
<p>Moving a light probe</p>
<p>Light probes should be positioned, first, in an area where a dynamic object might move to, and second, where there is a significant change in lighting level. When calculating the lighting level for an object, the engine finds a pyramid of the nearest light probes and uses those to determine an interpolated value for the illumination level.</p>
<p><img src="_page_60_Picture_5.jpeg" alt=""></p>
<p>The nearest light probes for the selected crate</p>
<p><span id="page-61-0"></span><img src="_page_61_Picture_0.jpeg" alt=""></p>
<p>Positioning probes can be time-consuming, but a code-based approach such as <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightProbes-Placing-Scripting.html?">this one</a> can speed up your editing, especially for a large scene or for super quick placement switch to using APVs.</p>
<p>Creators often build modular content for their projects in scenes. These scenes are then repositioned at runtime in a &quot;hub&quot; scene. However, when building modular content including light probes, creators were unable to reposition these together with their Scene, because the positions of the probes were read-only. This issue is solved in Unity 6 with a <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/LightProbes.SetPositionsSelf.html">new API</a> that allows the repositioning of light probes at runtime.</p>
<p>Further details on how a Mesh Renderer works with light probes and how to adjust the configuration can be found in <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LightProbes-MeshRenderer.html">this documentation.</a></p>
<h2 id="adaptive-probe-volumes">Adaptive Probe Volumes</h2>
<p>Any technical artist who has carefully positioned light probes for a scene only to find the scene layout has changed will immediately see the benefits of Adaptive Probe Volumes (APVs). For many scenes you can now place all the probes in a matter of seconds. Let&#39;s look at a practical example using the <a href="https://github.com/NikLever/Unity6E-book">FPS Sample: The Inspection</a> again. This example is found via <strong>The Inspection &gt; Scenes &gt; APV-Example</strong></p>
<ol>
<li>First make sure the active URP Asset has the <strong>Light Probe System</strong> option set to <strong>Adaptive Probe Volumes</strong>.</li>
</ol>
<p><img src="_page_61_Figure_8.jpeg" alt=""></p>
<ol>
<li>In the Hierarchy window right-click and select <strong>GameObject &gt; Light &gt; Adaptive Probe Volume</strong> (APV).</li>
</ol>
<table>
<thead>
<tr>
<th>Light</th>
<th>&gt;</th>
<th>Directional Light</th>
</tr>
</thead>
<tbody>
<tr>
<td>Video</td>
<td>&gt;</td>
<td>Point Light</td>
</tr>
<tr>
<td>Ul Toolkit</td>
<td>&gt;</td>
<td>Spot Light</td>
</tr>
<tr>
<td>Rendering</td>
<td>&gt;</td>
<td>Area Light</td>
</tr>
<tr>
<td>Spline</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Volume</td>
<td>&gt;</td>
<td>Reflection Probe</td>
</tr>
<tr>
<td>Camera</td>
<td></td>
<td>Adaptive Probe Volume</td>
</tr>
<tr>
<td>Cinemachine</td>
<td>&gt;</td>
<td>Probe Adjustment Volume</td>
</tr>
<tr>
<td>Visual Scripting Scene Variables</td>
<td></td>
<td>Light Probe Group</td>
</tr>
</tbody>
</table>
<p><img src="_page_62_Picture_0.jpeg" alt=""></p>
<ol>
<li>Set the Mode to <strong>Global</strong> and accept the default settings – Subdivisions of 1, 3, 9 and 27 meters.</li>
</ol>
<p><img src="_page_62_Picture_2.jpeg" alt=""></p>
<ol>
<li>Bake the volume by pressing <strong>Bake Probe Volumes</strong>. The current scene is scanned and the probes are placed based on the geometry in the scene. Probes are at their densest where there is the most geometry.</li>
</ol>
<p><img src="_page_62_Figure_4.jpeg" alt=""></p>
<ol>
<li>To view the result of the bake open <strong>Analysis &gt; Rendering Debugger</strong>. Select <strong>Probe Volumes</strong>  and select <strong>Display Probes</strong>. To view the different resolutions choose <strong>Display Bricks</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>C Console<br>Project</th>
<th>Render Graph Viewer</th>
<th>Rendering Debugger</th>
<th>Project Settings</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Rese</td>
</tr>
<tr>
<td>Frequently Used</td>
<td>Subdivision Visualization</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Volumes</td>
<td>Display Cells</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Display Bricks</td>
<td></td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td>Debug Draw Distance</td>
<td></td>
<td>500</td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td>Subdivision Preview</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Live Updates</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lighting</td>
<td>Probe Visualization</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPU Resident Drawer</td>
<td>Display Probes</td>
<td></td>
<td>A</td>
<td></td>
</tr>
<tr>
<td>Render Graph</td>
<td>Probe Shading Mode</td>
<td></td>
<td>SH</td>
<td></td>
</tr>
<tr>
<td>Volume</td>
<td>Debug Size</td>
<td></td>
<td></td>
<td>0.73</td>
</tr>
<tr>
<td></td>
<td>Exposure Compensation</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Max Subdivisions Displayed</td>
<td></td>
<td></td>
<td>3</td>
</tr>
<tr>
<td></td>
<td>Min Subdivisions Displayed</td>
<td></td>
<td></td>
<td>0</td>
</tr>
</tbody>
</table>
<p>For many scenes that would complete the job, and you can head off for a coffee break. But APVs provide much more fidelity. You can add multiple volumes with different subdivisions to have precise control over the placement and density of probes.</p>
<p>Take the oasis environment in the URP 3D Sample as an example. Imagine most of the action in the scene is around the tent and therefore, you want to place most of the probes around it. To achieve this you would:</p>
<ol>
<li>Open <strong>Rendering &gt; Lighting &gt; Adaptive Probe Volumes</strong> and change <strong>Max Probe Spacing</strong> to 81m.</li>
</ol>
<p><img src="_page_63_Picture_4.jpeg" alt=""></p>
<ol>
<li>Add an <strong>Adaptive Probe Volume</strong> set as <strong>Global</strong> and set the <strong>Override Probe Spacing</strong> to 27m&gt;81m.</li>
</ol>
<p><img src="_page_63_Figure_6.jpeg" alt=""></p>
<ol>
<li>Add an Adaptive Probe Volume set as <strong>Local</strong> and set the <strong>Override Probe Spacing</strong> to 1m&gt;9m. Set the Volume to be a bit bigger than the tent.</li>
</ol>
<p><img src="_page_63_Picture_8.jpeg" alt=""></p>
<p><span id="page-64-0"></span><img src="_page_64_Picture_0.jpeg" alt=""></p>
<h4 id="4-bake-the-probe-volumes-">4. Bake the Probe Volumes.</h4>
<p>As you can see from the image below, most probes are around the tent.</p>
<p><img src="_page_64_Picture_4.jpeg" alt=""></p>
<p>Probe placement</p>
<h4 id="-lighting-scenario-asset-"><strong>Lighting Scenario asset</strong></h4>
<p>Another feature of Adaptive Probe Volumes is the ability to switch between indirect lighting data. A <strong>Lighting Scenario</strong> asset contains the baked lighting data for a scene or <strong><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-usebakingsets.html">Baking Set</a></strong>. You can bake different lighting setups into different Lighting Scenarios, and change which one URP uses at runtime or at design time using the Rendering Debugger.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th>Console</th>
<th>Rendering Debugger</th>
<th></th>
<th>0 1</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Reset</td>
</tr>
<tr>
<td>Frequently Used</td>
<td></td>
<td>Display Probes</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Volumes</td>
<td></td>
<td>Debug Probe Sampling<br>Virtual Offset Debug</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td></td>
<td>Debug Draw Distance</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td></td>
<td>Probe Adjustment Volumes</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Auto Display Probes</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Lighting</td>
<td></td>
<td>Isolate Affected</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td></td>
<td>GPU Resident Drawer</td>
<td>Scenario Blending</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Number Of Cells Blencied Per Frame</td>
<td>10000</td>
<td></td>
</tr>
<tr>
<td>Render Graph</td>
<td></td>
<td>Turnover Rate</td>
<td>œ</td>
<td>0.1</td>
</tr>
<tr>
<td>Volume</td>
<td></td>
<td>Scenario Blend Target</td>
<td>Night</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Seanario Blandino Factor</td>
<td></td>
</tr>
</tbody>
</table>
<p>Scenario Blending using the Rendering Debugger</p>
<p><img src="_page_65_Picture_0.jpeg" alt=""></p>
<p><img src="_page_65_Picture_1.jpeg" alt=""></p>
<p><img src="_page_65_Picture_2.jpeg" alt=""></p>
<p>For example, you can create one Lighting Scenario for day, and another one for night. At runtime, you can switch or blend between the two.</p>
<p>Day/night Lighting Scenarios</p>
<ol>
<li>To use a Lighting Scenario asset, go to the active URP Asset and enable <strong>Lighting &gt; Light Probe Lighting &gt; Lighting Scenarios</strong>.</li>
</ol>
<p><img src="_page_65_Picture_6.jpeg" alt=""></p>
<p><img src="_page_66_Picture_0.jpeg" alt=""></p>
<ul>
<li><ol>
<li>To create a new Lighting Scenario asset so you can store baking results inside, do the following:<ul>
<li>a. Open the <strong>Adaptive Probe Volumes</strong> panel in the <strong>Lighting</strong> window.</li>
<li>b. In the <strong>Lighting Scenarios</strong> section, select the <strong>Add</strong> (+) button to add a Lighting Scenario asset.</li>
</ul>
</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>V Lighting Scenarios</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Scenario</td>
<td>Active</td>
<td>Status</td>
</tr>
<tr>
<td>Day</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Night</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>+</td>
</tr>
</tbody>
</table>
<ol>
<li>In the <strong>Lighting</strong> window, under the <strong>Adaptive Probe Volume</strong> tab, make sure the <strong>Probe Positions</strong> are set to <strong>Don&#39;t Recalculate</strong>. This ensures that Unity will only rebake lighting without changing the probe positions, which could otherwise invalidate previously baked scenarios.</li>
</ol>
<table>
<thead>
<tr>
<th>@ Inspector</th>
<th></th>
<th>@ Lighting</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Scene Adaptive Probe Volumes Environment</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Realtime Lightmaps Baked Lightmaps</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Baking</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Placement<br>Recalculate</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Positions<br>V Don&#39;t Recalculate<br>Probe Offset</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Min Probe Spacing 0.4</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><ol>
<li>To bake into a Lighting Scenario, follow these steps:<ul>
<li>a. In the Lighting Scenarios section, select a Lighting Scenario to make it active.</li>
<li>b. Select <strong>Generate Lighting</strong>. URP stores the baking results in the active Lighting Scenario.</li>
<li>c. Use the dropdown button next to <strong>Generate Lighting</strong> to only focus on the probes if you&#39;re not using lightmaps.</li>
</ul>
</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>GPU Baking Profile</th>
<th>Automatic</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Generate Lighting</td>
<td>Bake Probe Volumes</td>
</tr>
<tr>
<td>Scenario Size</td>
<td>7.3 MB</td>
<td>Bake Reflection Probes</td>
</tr>
<tr>
<td>Baking Set Size</td>
<td>18.6 MB</td>
<td>Clear Baked Data</td>
</tr>
</tbody>
</table>
<p><span id="page-67-0"></span><img src="_page_67_Picture_0.jpeg" alt=""></p>
<p>You can set which Lighting Scenario URP uses at runtime using the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-bakedifferentlightingsetups.html">ProbeReferenceVolume</a> API.</p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p>If you change the active Lighting Scenarios at runtime, URP changes only the indirect lighting data in the light probes. You might still need to use scripts to move geometry, modify lights or change direct lighting.</p>
<h4 id="-fixing-issues-with-adaptive-probe-volumes-"><strong>Fixing issues with Adaptive Probe Volumes</strong></h4>
<p><img src="_page_67_Figure_6.jpeg" alt=""></p>
<p>Debug Probe Sampling</p>
<p>To fix issues such as APV artifacts, use <strong>Window &gt; Analysis &gt; Rendering Debugger &gt; Probe Volumes &gt; Debug Probe Sampling</strong> to inspect probes and how they are sampled for a given pixel.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th>Console<br>Rendering Debugger</th>
<th></th>
<th>0 :</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td>Reset</td>
</tr>
<tr>
<td>Frequently Used</td>
<td>Subdivision Visualization</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Volumes</td>
<td>Display Cells<br>Display Bricks</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td>Debug Draw Distance</td>
<td>500</td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td>Probe Visualization</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lighting</td>
<td>Display Probes</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Debug Probe Sampling</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>GPU Resident Drawe</td>
<td>Debug Size</td>
<td></td>
<td>0.3</td>
</tr>
</tbody>
</table>
<p>Visualizing Probe Sampling per pixel</p>
<p>Since light probes are added in a grid, placement can sometimes cause rendering errors such as dark areas where it should be light and vice versa. The Editor provides several tools to let a technical artist quickly fix these issues.</p>
<p>Light probes inside geometry are called invalid probes. URP marks a probe as invalid when it fires sampling rays to capture surrounding light data, but the rays hit the unlit backfaces inside geometry. The APV system has several tools to fix these issues.</p>
<p><img src="_page_68_Figure_3.jpeg" alt=""></p>
<p>The Probe Invalidity Settings available in the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-lighting-panel-reference.html">Adaptive Probe Volumes panel</a></p>
<p><strong>Virtual Offset</strong> tries to make invalid light probes valid, by moving their capture points so they&#39;re outside any colliders. And <strong>Dilation</strong> detects light probes that remain invalid after Virtual Offset, and gives them data from valid probes nearby.</p>
<p>You can check which light probes are invalid using the <strong>Rendering Debugger.</strong></p>
<p><img src="_page_68_Picture_7.jpeg" alt=""></p>
<p>In the left-side scene in the image above, Virtual Offset isn&#39;t active and dark bands are visible. In the scene on the right side, Virtual Offset is active.</p>
<p><span id="page-69-0"></span><img src="_page_69_Picture_1.jpeg" alt=""></p>
<p>In the left-side scene in the image above, Dilation isn&#39;t active and some areas are too dark. In the scene on the right, Dilation is active.</p>
<h4 id="-light-leaks-"><strong>Light leaks</strong></h4>
<p>Light leaks are areas that are too light or dark, often in the corners of a wall or ceiling.</p>
<p><img src="_page_69_Picture_5.jpeg" alt=""></p>
<p>A light leak</p>
<p>Light leaks often occur when geometry receives light from a light probe that isn&#39;t visible to the geometry, for example due to the light probe being on the other side of a wall. APVs use regular grids of light probes, so light probes might not follow walls or be at the boundary between different lighting areas.</p>
<p>Try the following techniques to fix light leaks:</p>
<ul>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#create-thicker-walls">Create thicker walls</a><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#create-thicker-walls">.</a></li>
<li>Add an <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#add-an-adaptive-probe-volumes-options-override-to-your-scene">Adaptive Probe Volumes Options override</a> to your scene:</li>
</ul>
<p><span id="page-70-0"></span><img src="_page_70_Picture_0.jpeg" alt=""></p>
<ul>
<li>Add a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/volumes-landing-page.html">Volume,</a> then an <strong>Adaptive Probe Volumes Options</strong> override to the Volume. This adjusts the position that GameObjects use to sample the light probes.</li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#layers">Enable Rendering Layers</a>:<ul>
<li>In the Lighting window, configure the <strong>Rendering Layer Masks</strong> in the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-lighting-panel-reference.html">Adaptive</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-lighting-panel-reference.html">Probe Volumes panel</a> to allow the APV to assign a Rendering Layer Mask to each light probe.</li>
</ul>
</li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#probevolumesettings">Adjust Baking Set properties</a>:<ul>
<li>If adding a Volume doesn&#39;t work, use the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-lighting-panel-reference.html">Adaptive Probe Volumes panel</a> in the Lighting window to adjust Virtual Offset and Dilation settings.</li>
</ul>
</li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html#probevolumeadjustment">Use a Probe Adjustment Volume</a> component:<ul>
<li>Use this component to make light probes invalid in a small area. This triggers Dilation during baking, and improves the results of <strong>Leak Reduction Mode</strong> at runtime.</li>
</ul>
</li>
</ul>
<h4 id="-rendering-layers-"><strong>Rendering Layers</strong></h4>
<p>When switching the URP 3D Sample oasis environment from using light probes/lightmaps to using APV only, an issue arises with light leaks, which you can see on the bright roof and wall in the image below.</p>
<p><img src="_page_70_Picture_11.jpeg" alt=""></p>
<p>Light leaking in the tent in the oasis environment from the URP 3D Sample</p>
<p>This is because some pixels are blending between probes on the inside and outside of the tent. By using <strong>Window &gt; Analysis &gt; Rendering Debugger &gt; Probe Volumes &gt; Debug Probe Sampling</strong>, you can spot which probes are used when interpolating the value for a pixel.</p>
<p><img src="_page_71_Picture_2.jpeg" alt=""></p>
<p>Viewing the interpolated probes for a pixel</p>
<p>One option to fix this is to use a <strong>Volume</strong> to modify how APV is sampled at runtime using the <strong>Adaptive Probe Volume Options</strong> override. Use the <strong>NormalBias</strong> and <strong>ViewBias</strong> settings to adjust the sampling position:: NormalBias pushes it along the normal (away from walls), while ViewBias pushes it towards the camera (keeping it on the same side of the wall as the camera). When you change these properties in the Volume, you can see the updates in realtime in both the lighting results and the <strong>Debug Probe Sampling View</strong>, where the sampling position and weights are updated accordingly. But a better option is to use Rendering Layers.</p>
<p>APV supports <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/urp/features/rendering-layers-introduction.html">Rendering Layers</a>, allowing you to create up to four different masks and restrict sampling to those specific masks for certain objects. This can be useful to prevent interior objects from sampling exterior probes, or vice versa. Activate and add them using <strong>Window &gt; Rendering &gt; Lighting &gt; Adaptive Probe Volumes &gt; Rendering Layers</strong>.</p>
<table>
<thead>
<tr>
<th>Rendering Layers</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering Layer Masks</td>
<td>&gt;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Exterior</td>
<td></td>
<td>Default</td>
<td>&gt;</td>
</tr>
<tr>
<td>Interior</td>
<td></td>
<td>Interior</td>
<td>P</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>-</td>
</tr>
</tbody>
</table>
<p><img src="_page_72_Picture_0.jpeg" alt=""></p>
<p>You&#39;ll also need to add a layer via <strong>Project Settings &gt; Tags and Layers &gt; Rendering Layers</strong>:</p>
<table>
<thead>
<tr>
<th>Tags and Layers<br>PARK RELEAR FLATURE FRANCE</th>
<th></th>
<th>0 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>&gt; Layers</td>
<td></td>
<td></td>
</tr>
<tr>
<td>T Rendering Layers</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Layer O</td>
<td>Default</td>
<td></td>
</tr>
<tr>
<td>Layer 1</td>
<td>Screen</td>
<td></td>
</tr>
<tr>
<td>Layer 2</td>
<td>Lamps</td>
<td></td>
</tr>
<tr>
<td>Layer 3</td>
<td>Interior</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>+ =</td>
</tr>
</tbody>
</table>
<p>To implement this, edit the meshes themselves to ensure they are divided between the different areas you want to create. In this project, for example, the meshes are edited to separate the interior and exterior into multiple meshes. Once the meshes are split, assign the correct Rendering Layers to them, and specify which ones APV should use in the <strong>Adaptive Probe Volume Tab</strong>.</p>
<p>You don&#39;t need to assign layers to every object in the tent, only to those susceptible to leaking, like the walls or objects near the walls.</p>
<p>When generating lighting, the system will automatically assign layers to the probes during the bake process based on the nearby objects, eliminating the need to manually assign layers per probe. To facilitate this automatic probe assignment, you need to assign layers to larger objects. In the oasis environment tent example, the interior layer is assigned to the walls and ceiling of the tent to ensure that most of the interior probes hit them during baking and are automatically assigned to the interior mask. Probes are assigned to the layer they encounter most frequently.</p>
<p><img src="_page_72_Picture_7.jpeg" alt=""></p>
<p>Once this is done, click <strong>Generate Lighting</strong> and observe that leaking is eliminated for the tent, thanks to the separate interior and exterior masks.</p>
<p><span id="page-73-0"></span><img src="_page_73_Picture_1.jpeg" alt=""></p>
<p>Light leaks without and with rendering layers</p>
<p>Get more information <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-fixissues.html">here</a> about fixing issues with APVs.</p>
<h4 id="-streaming-apvs-"><strong>Streaming APVs</strong></h4>
<p><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-streaming.html">APV streaming</a> enables you to use APV-based lighting in large worlds. APV streaming bakes APV data that&#39;s larger than the available CPU or GPU memory, and loads it at runtime when it&#39;s needed. At runtime, as the camera moves, URP loads only APV data from cells within the camera&#39;s view frustum.</p>
<p>You can enable and disable streaming for different URP quality levels. Enable streaming with the following steps:</p>
<ul>
<li><ol>
<li>Select <strong>Edit &gt; Project Settings &gt; Quality</strong> from the main menu.</li>
</ol>
</li>
<li><ol>
<li>Select a Quality Level.</li>
</ol>
</li>
<li><ol>
<li>Double-click the Render Pipeline Asset to open it in the Inspector.</li>
</ol>
</li>
<li><ol>
<li>Expand the Lighting tab.</li>
</ol>
</li>
<li><ol>
<li>You can now enable two types of streaming:<ul>
<li>a. Enable Disk Streaming to stream from disk to CPU memory.</li>
<li>b. Enable GPU Streaming to stream from CPU memory to GPU memory. You must enable Enable Disk Streaming first.</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><span id="page-74-0"></span><img src="_page_74_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>V Lighting</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Main Light</td>
<td>Per Pixel</td>
<td>D</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>2048</td>
<td>D</td>
</tr>
<tr>
<td>Light Probe System</td>
<td>Adaptive Probe Volumes</td>
<td>œ</td>
</tr>
<tr>
<td>Memory Budget</td>
<td>Memory Budget Medium</td>
<td>P</td>
</tr>
<tr>
<td>SH Bands</td>
<td>Spherical Harmonics L1</td>
<td>D</td>
</tr>
<tr>
<td>Enable GPU Streaming</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Enable Disk Streaming</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Enable Lighting Scenanios</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Enable Lighting Scenario Blending</td>
<td></td>
</tr>
</tbody>
</table>
<p>You can configure streaming settings in the same window. Refer to the URP Asset for more information.</p>
<h4 id="-debug-streaming-"><strong>Debug streaming</strong></h4>
<p>The smallest section URP loads and uses is a cell, which is the same size as the largest brick in an APV. You can influence the size of cells in an APV by adjusting the density of light probes</p>
<p><img src="_page_74_Figure_6.jpeg" alt=""></p>
<p>Use the Rendering Debugger to view the cells in an APV or debug streaming.</p>
<p>APV Streaming</p>
<h4 id="-sky-occlusion-"><strong>Sky occlusion</strong></h4>
<p>Sky occlusion is the process whereby if a GameObject samples a color from the sky, Unity will dim the color if the light can&#39;t reach the GameObject. Sky occlusion in Unity uses the sky color from the ambient probe, which updates at runtime. This means you can dynamically light GameObjects as the sky color changes. For example, you can change the sky color from light to dark to simulate the effect of a day-night cycle.</p>
<p><img src="_page_75_Picture_0.jpeg" alt=""></p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p>If you enable sky occlusion, APVs might take longer to bake, and Unity might use more memory at runtime.</p>
<p>When you <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes-skyocclusion.html">enable sky occlusion</a>, Unity bakes an additional static sky occlusion value into each probe in an APV. The sky occlusion value is the amount of indirect light the probe receives from the sky, including light that bounced off static GamesObjects.</p>
<p>The main benefit of using sky occlusion is you can modify the sky lighting at runtime.</p>
<p><img src="_page_75_Picture_6.jpeg" alt=""></p>
<p>Let&#39;s look at the series of images to the left to illustrate this:</p>
<ul>
<li>a. The top image shows the problem that occurs when you can&#39;t bake the sky lighting because you need it to change at runtime. In this image only an ambient probe is used with no baking resulting in a poor result.</li>
<li>b. In the second to fifth images the ambient probe is used together with sky occlusion. You could also light this image with a regular APV bake, with sky occlusion disabled but then the lighting would not change at runtime.</li>
</ul>
<p>An example of the results of using sky occlusion in a scene. The images are from the Unity Asset Store package <a href="https://assetstore.unity.com/packages/tools/particles-effects/azure-sky-dynamic-skybox-36050">Azure[Sky] Dynamic Skybox</a> by 7stars.</p>
<p><img src="_page_76_Picture_0.jpeg" alt=""></p>
<p>Follow these steps to enable sky occlusion:</p>
<ul>
<li><ol>
<li>Enable the <strong>Progressive GPU Lightmapper</strong>. Unity doesn&#39;t support sky occlusion if you use Progressive CPU. Go to <strong>Window &gt; Rendering &gt; Lighting</strong>.</li>
</ol>
</li>
<li><ol>
<li>Go to the Scene panel.</li>
</ol>
</li>
<li><ol>
<li>Set Lightmapper to Progressive GPU.</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>Lightmapping Settings</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Lightmapper</td>
<td>Progressive GPU</td>
<td></td>
</tr>
<tr>
<td>Importance Sampling</td>
<td>V</td>
</tr>
</tbody>
</table>
<ul>
<li><ol>
<li>Open the Adaptive Probe Volumes panel.</li>
</ol>
</li>
<li><ol>
<li>Enable Sky Occlusion.</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>Sky Occlusion Settings</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Sky Occlusion</td>
<td>V</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Samples</td>
<td></td>
<td></td>
<td>0</td>
<td>2048</td>
</tr>
<tr>
<td>Bounces</td>
<td></td>
<td></td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>Albedo Override</td>
<td></td>
<td>0</td>
<td></td>
<td>0.6</td>
</tr>
<tr>
<td>Sky Direction</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>To update the lighting data, you must also bake the APV after you enable or disable sky occlusion. Once the sky occlusion is baked, the scene lighting will respond to the ambient probe updates. In URP, the ambient probe is updated in real-time only when using the Color or Gradient Mode, not the Skybox mode. This means you&#39;ll probably have to manually animate a color to match the animated sky visuals.</p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p>URP now supports per-vertex quality sampling for probes. This is especially useful to boost performance on lower-end devices. To set the sampling mode use the <strong>URP Asset</strong> in the Lighting section. <strong>Advanced Properties</strong> must be active to view the option; press the ellipsis at the top right of the Lighting panel to activate it. With Advanced Properties active, the <strong>SH Evaluation Mode</strong> dropdown will appear.</p>
<table>
<thead>
<tr>
<th>V Auto</th>
</tr>
</thead>
<tbody>
<tr>
<td>Per Vertex</td>
</tr>
<tr>
<td>Mixed</td>
</tr>
<tr>
<td>Per Pixel</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p><span id="page-77-0"></span><img src="_page_77_Picture_0.jpeg" alt=""></p>
<h4 id="-more-information-"><strong>More Information</strong></h4>
<ul>
<li>Adaptive Probe Volumes <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/probevolumes.html">documentation.</a></li>
<li>GDC 2023 session: <a href="https://www.youtube.com/watch?v=iU7X5xICkc8">Efficient and impactful lighting with Adaptive Probe Volumes</a></li>
</ul>
<h4 id="-light-probes-vs-apvs-"><strong>Light probes vs APVs</strong></h4>
<p><img src="_page_77_Picture_6.jpeg" alt=""></p>
<p>Light Probe Groups in use in the top image, and APVs in the bottom image; images are from the Unity Asset Store package <a href="https://assetstore.unity.com/packages/3d/environments/industrial/archvizpro-photostudio-urp-225832">ArchVizPRO</a>  <a href="https://assetstore.unity.com/packages/3d/environments/industrial/archvizpro-photostudio-urp-225832">Photostudio URP</a> by ArchVizPro</p>
<p><span id="page-78-0"></span><img src="_page_78_Picture_0.jpeg" alt=""></p>
<p>The bottom image (shown above) shows how smoothly a transition from dark to light works with APV. In the top image, the Light Probe Group results in a bright light on the car door because a single interpolated probe is used per object. This is because the door is a separate GameObject to the rest of the door and uses a different probe, resulting in a rendering error.</p>
<p>The table below compares the features of light probes and APVs.</p>
<table>
<thead>
<tr>
<th>Light Probe Groups</th>
<th>Adaptive Probe Volumes</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Time-consuming to place probes and move<br>them if geometry changes</td>
<td>Fast to place and easy to update as<br>geometry changes</td>
<td></td>
<td></td>
</tr>
<tr>
<td>A single interpolated probe is used for<br>lighting objects:<br>—<br>Objects cannot transition well from<br>darkness to light and stand out.<br>—<br>It can cause problems for big<br>objects.</td>
<td>Each pixel is individually lit:<br>—<br>This ensures smooth transitions.<br>—<br>Volumetric effects work well using<br>APV because the APV grid is easy<br>to sample at any location.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Static objects are usually lit using light<br>maps. Only dynamic objects use probes.</td>
<td>No need for lightmaps or lightmap UVs:<br>—<br>Use a single lighting solution for all<br>objects in a scene.<br>—<br>Light large worlds with a<br>constrained memory budget.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probes can be freely placed and moved at<br>runtime.</td>
<td>Probes are placed in a grid structure and<br>cannot be moved at run time.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Switch GI is not supported.</td>
<td>The Lighting Scenario asset allows for<br>switching between different lighting, e.g.,<br>from day to night, turning a light on or off,<br>and so on.</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="reflection-probes">Reflection probes</h2>
<p>A ray-tracing tool, such as Maya or Blender, can take the time to accurately calculate the values for each frame pixel of a reflective surface. This process takes far too long for a realtime renderer, which is why shortcuts are often used.</p>
<p>Reflections in a real-time renderer use environment maps (pre-rendered cubemaps). Unity supplies a default map using the SkyManager. Having a single map as the source of reflections from all locations in a scene can lead to unconvincing reflections. Take the example of the robot shown in this section. If the metal parts of this character always reflect the sky, then it will look very strange when inside the hangar where the sky is not visible. This is where reflection probes are helpful.</p>
<p><img src="_page_79_Picture_0.jpeg" alt=""></p>
<p>A <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/ReflectionProbes.html?">Reflection Probe component</a> is a pre-rendered cubemap placed at a key position in the scene. You can use several reflection probes in a single scene. As a dynamic object moves through the scene, it can select the nearest reflection probe and use that as the basis of its reflections. You can also set up the scene to blend between probes.</p>
<p>To add a Reflection Probe component, right-click the <strong>Hierarchy</strong> window and select <strong>Light &gt; Reflection Probe</strong>.</p>
<table>
<thead>
<tr>
<th>Light</th>
<th>&gt;</th>
<th>Directional Light</th>
</tr>
</thead>
<tbody>
<tr>
<td>Video</td>
<td>&gt;</td>
<td>Point Light</td>
</tr>
<tr>
<td>Ul Toolkit</td>
<td>&gt;</td>
<td>Spot Light</td>
</tr>
<tr>
<td>Rendering</td>
<td>&gt;</td>
<td>Area Light</td>
</tr>
<tr>
<td>Spline</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Volume</td>
<td></td>
<td>Reflection Probe</td>
</tr>
<tr>
<td>Camera</td>
<td></td>
<td>Adaptive Probe Volume</td>
</tr>
<tr>
<td>Cinemachine</td>
<td></td>
<td>&gt; Probe Adjustment Volume</td>
</tr>
<tr>
<td>Visual Scripting Scene Variables</td>
<td></td>
<td>Light Probe Group</td>
</tr>
</tbody>
</table>
<p>Adding a Reflection Probe component</p>
<p>Then position the probe and adjust its <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/class-ReflectionProbe.html?">settings</a>. Once the probe is placed correctly and the settings are adjusted, click <strong>Bake</strong> to generate a cubemap.</p>
<table>
<thead>
<tr>
<th>Cubemap Capture Settings</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Resolution</td>
<td>128</td>
<td></td>
</tr>
<tr>
<td>HDR</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Shadow Distance</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td>Clear Flags</td>
<td>Skybox</td>
<td></td>
</tr>
<tr>
<td>Background</td>
<td></td>
<td>00</td>
</tr>
<tr>
<td>Culling Mask</td>
<td>Everything</td>
<td>œ</td>
</tr>
<tr>
<td>Use Occlusion Culling</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Clipping Planes</td>
<td>0.3<br>Near</td>
<td></td>
</tr>
<tr>
<td></td>
<td>1000<br>Far</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Settings for the Reflection Probe component</p>
<p><span id="page-80-0"></span><img src="_page_80_Picture_0.jpeg" alt=""></p>
<p>The following image shows the two reflection probes used in FPS Sample: The Inspection, one inside the hangar and one outside.</p>
<p><img src="_page_80_Picture_2.jpeg" alt=""></p>
<p>Each reflection probe captures an image of its surroundings in a cubemap texture.</p>
<h4 id="-reflection-probe-blending-"><strong>Reflection probe blending</strong></h4>
<p><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/lighting/reflection-probes.html#reflection-probe-blending?">Blending</a> is a great feature of reflection probes. You can enable blending via the <strong>Renderer Asset Settings</strong> panel. Blending is always on when the Forward+ path is chosen, regardless of the Renderer Asset setting.</p>
<p>Blending gradually fades out one probe&#39;s cubemap, while fading in the other as the reflective object passes from one zone to the other. This gradual transition prevents a moving object from suddenly acquiring completely different reflections when crossing the boundary between two reflection probes.</p>
<h4 id="-box-projection-"><strong>Box Projection</strong></h4>
<p>Normally, the reflection cubemap is assumed to be at an infinite distance from any given object. Different angles of the cubemap will be visible as the object turns, but it&#39;s not possible for the object to move closer or further away from the reflected surroundings. While this works well for outdoor scenes, its limitations show in an indoor scene. The interior walls of a room are clearly not an infinite distance away, and the reflection of a wall should get larger as the object nears it.</p>
<p>The <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/AdvancedRefProbe.html?">Box Projection</a> option enables you to create a reflection cubemap at a finite distance from the probe, allowing objects to show reflections of different sizes according to their distance from the cubemap&#39;s walls. The size of the surrounding cubemap is determined by the probe&#39;s zone of effect, depending on its Box Size property. For example, with a probe that reflects the interior of a room, you should set the size to match the dimensions of the room.</p>
<p><span id="page-81-0"></span><img src="_page_81_Picture_0.jpeg" alt=""></p>
<h2 id="lens-flares">Lens flares</h2>
<p>If you&#39;re coming to URP from using the Built-In Render Pipeline the workflow for creating a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/shared/lens-flare/lens-flare-asset.html?">lens</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/shared/lens-flare/lens-flare-asset.html?">flare</a> has been updated for URP. The first step in configuring it is to create a Lens Flare (SRP) Data asset. Right-click in the <strong>Project</strong> window, in a suitable Assets folder, and select <strong>Create &gt; Rendering &gt; Lens Flare (SRP)</strong>.</p>
<table>
<thead>
<tr>
<th>Create<br>&gt;<br>Reveal in Finder<br>Open</th>
<th></th>
<th>Folder<br>Material<br>MonoBehaviour Script</th>
<th></th>
<th>Type<br>Runtime Settings<br>Importance<br>Intensity</th>
</tr>
</thead>
<tbody>
<tr>
<td>Delete<br>Rename<br>Copy Path</td>
<td>CHC</td>
<td>2D<br>Animation</td>
<td>&gt;<br>&gt;</td>
<td>Box Projection<br>Blend Distance</td>
</tr>
<tr>
<td>Open Scene Additive</td>
<td></td>
<td>Audio<br>Cinemachine</td>
<td>V<br>V</td>
<td>Material<br>Material Variant</td>
</tr>
<tr>
<td>View in Package Manager</td>
<td></td>
<td>Rendering<br>Scene</td>
<td>&gt;<br>&gt;</td>
<td>Lightmap Parameters<br>Lighting Settings</td>
</tr>
<tr>
<td>Import New Asset<br>Import Package<br>Export Package</td>
<td>&gt;</td>
<td>Scripting<br>Search<br>Shader</td>
<td>&gt;<br>&gt;<br>&gt;</td>
<td>Lens Flare<br>Render Texture<br>Custom Render Texture</td>
</tr>
<tr>
<td>Find References In Scene<br>Find References In Project<br>Select Dependencies</td>
<td></td>
<td>Shader Graph<br>Testing<br>Terrain<br>Text Core</td>
<td>&gt;<br>&gt;<br>&gt;<br>A</td>
<td>Legacy Cubemap<br>Volume Profile<br>Lens Flare (SRP)</td>
</tr>
<tr>
<td>Refresh</td>
<td>ਡੀ ਕਿ</td>
<td>TextMeshPro</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>Creating a Lens Flare (SRP) Data asset</p>
<p>Use this asset to configure the shape of your flare by setting <strong>Type</strong> as Circle, Polygon, or Image assets and adjusting the Tint and Intensity settings.</p>
<table>
<thead>
<tr>
<th>Elements</th>
<th></th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>&gt; &gt; Lens Flare Element</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Type</td>
<td>Circle</td>
<td></td>
</tr>
<tr>
<td>Tint</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lens Flare Element</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Type</td>
<td>Polygon</td>
<td>D</td>
</tr>
<tr>
<td>Tint</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td>0.2</td>
<td></td>
</tr>
<tr>
<td>Count</td>
<td>5</td>
<td></td>
</tr>
<tr>
<td>&gt; &gt; Lens Flare Element</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Type</td>
<td>Image</td>
<td>P</td>
</tr>
<tr>
<td>Tint</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td></td>
<td></td>
</tr>
<tr>
<td>&gt; &lt; Lens Flare Element</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Type</td>
<td>Image</td>
<td></td>
</tr>
<tr>
<td>Tint</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td>0.19</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Adding and configuring Lens Flare elements</p>
<p><img src="_page_82_Picture_0.jpeg" alt=""></p>
<p>To render a lens flare, choose the light source that will cause the flare and then select <strong>Add Component &gt; Rendering &gt; Lens Flare (SRP)</strong>.</p>
<table>
<thead>
<tr>
<th></th>
<th>Add Component</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Q</td>
<td></td>
<td></td>
</tr>
<tr>
<td>€</td>
<td>Rendering</td>
<td></td>
</tr>
<tr>
<td>2D</td>
<td></td>
<td></td>
</tr>
<tr>
<td>I Camera</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Canvas Renderer</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Flare Layer</td>
<td></td>
</tr>
<tr>
<td></td>
<td>C Lens Flare (SRP)</td>
<td></td>
</tr>
<tr>
<td>9<br>Light</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Light Anchor</td>
</tr>
</tbody>
</table>
<p>Setting up rendering for a lens flare</p>
<p>Select the Lens Flare Data Asset.</p>
<p>In the <strong>Settings</strong> panel for this component, assign the <strong>Lens Flare Data asset</strong> you created to the <strong>Lens Flare Data property</strong>.</p>
<table>
<thead>
<tr>
<th>T &amp; V Lens Flare (SRP)</th>
<th></th>
<th>2</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>General</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lens Flare Data</td>
<td>LensFlare (Lens Flare Data SRP)</td>
<td></td>
<td>O</td>
</tr>
<tr>
<td>Intensity</td>
<td>0.61</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Scale</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Attenuation By Light Shape ✔</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Attenuation Distance</td>
<td>100</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Attenuation Distance Cur</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Scale Distance</td>
<td>100</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Scale Distance Curve</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Screen Attenuation Curve</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Occlusion</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Enable</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Allow Off Screen</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Settings for the Lens Flare (SRP) component</p>
<p>If you use lens flares you&#39;ll find that the workflows for adding and adjusting them are very flexible.</p>
<p><span id="page-83-0"></span><img src="_page_83_Picture_1.jpeg" alt=""></p>
<p>An example of a lens flare</p>
<h2 id="screen-space-lens-flare">Screen space lens flare</h2>
<p>Setting up lens flares for multiple lights can be time consuming. Unity 6 introduces a new post-processing technique, the Screen Space Lens Flare override (SSLF). This technique can generate flares from any bright surface, such as a bright specular highlight or an emissive mesh. In contrast, the lens flare (SRP) effect is limited to generating flares specifically from lights. Screen space lens flare uses a post-production technique.</p>
<p>Follow these steps to use SSLF:</p>
<ol>
<li>Because SSLF is a post-processing filter you use a Volume component to apply it. Either add a Volume component to your scene or use the new Default Volume in Unity 6. Settings for the Default Volume are adjusted using <strong>Edit &gt; Project Settings &gt; Graphics</strong>.</li>
</ol>
<p><img src="_page_83_Picture_7.jpeg" alt=""></p>
<p><img src="_page_84_Picture_0.jpeg" alt=""></p>
<ol>
<li>If using the Default Volume look for the Screen Space Lens Flare override in the settings panel.</li>
</ol>
<table>
<thead>
<tr>
<th>Graphics</th>
<th></th>
<th>0</th>
<th>14</th>
</tr>
</thead>
<tbody>
<tr>
<td>Motion Blur<br>A</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>P Panini Projection</td>
<td></td>
<td>@</td>
<td></td>
</tr>
<tr>
<td>T Screen Space Lens Flare</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Tint Color</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Bloom Mip Bias</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Flares</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Regular Multiplier</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reversed Multiplier</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Warped Multiplier</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>If using a scene Volume create a Volume Profile so you can add overrides. Then add the override via <strong>Post-processing &gt; Screen Space Lens Flare</strong>.</li>
</ol>
<p><img src="_page_84_Picture_4.jpeg" alt=""></p>
<ol>
<li>Now you can experiment with the settings to achieve the desired style for your scene. Keep in mind that intensity needs to be more than 0.</li>
</ol>
<p><img src="_page_85_Figure_1.jpeg" alt=""></p>
<p>You can combine SSLF with a Lens Flare (SRP) component for more control.</p>
<p><img src="_page_85_Picture_3.jpeg" alt=""></p>
<p>Clockwise from top left: No SSLF; flares added; flares, warped flares, and streaks; flares and warped flares</p>
<h2 id="-span-id-page-86-0-span-light-halos"><span id="page-86-0"></span>Light halos</h2>
<p>The <strong>Draw Halo</strong> property is not available for lights in URP, but it&#39;s easily mimicked with a billboard. Another option is to set the alpha transparency of a sphere. The first image below shows the Shader Graph for such a shader, and the second image depicts the result. For more information on using Shader Graph to create this shader, see the <a href="#page-137-0">Additional tools chapter</a>.</p>
<p><img src="_page_86_Picture_3.jpeg" alt=""></p>
<p>Fresnel transparency using Shader Graph</p>
<p><img src="_page_86_Picture_5.jpeg" alt=""></p>
<p>A halo effect that uses a sphere with a material using the Shader Graph shader from above</p>
<h2 id="-span-id-page-87-0-span-screen-space-ambient-occlusion"><span id="page-87-0"></span>Screen Space Ambient Occlusion</h2>
<p>Since ambient light does not consider geometry by default, high levels of ambient light can lead to unconvincing renders. In the real world, a narrow gap between two objects is likely to be darker than a much wider gap. Ambient occlusion can help deal with this issue in your Unity project. To use it with URP, select the Renderer that the URP Asset is using. Go to <strong>Add Renderer Feature</strong> and choose <strong><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/post-processing-ssao.html?">Screen Space Ambient Occlusion</a></strong> (SSAO).</p>
<table>
<thead>
<tr>
<th>Renderer Features</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>No Renderer Features added</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Add Renderer Feature</td>
</tr>
<tr>
<td></td>
<td>Render Objects (Experimental)</td>
</tr>
<tr>
<td></td>
<td>Decal</td>
</tr>
<tr>
<td></td>
<td>Screen Space Ambient Occlusion</td>
</tr>
<tr>
<td></td>
<td>Screen Space Shadows</td>
</tr>
<tr>
<td></td>
<td>Blit Material Feature</td>
</tr>
<tr>
<td></td>
<td>Simple Desaturate Feature</td>
</tr>
</tbody>
</table>
<p>Choosing SSAO from the Add Renderer Feature</p>
<p>Either use the default SSAO settings or adjust as needed:</p>
<table>
<thead>
<tr>
<th>T / Screen Space Ambient Occlusion</th>
<th></th>
<th>2</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Method</td>
<td>Blue Noise</td>
<td></td>
<td>œ</td>
</tr>
<tr>
<td>Intensity</td>
<td>0.4</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Radius</td>
<td>0.3</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Falloff Distance</td>
<td>100</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Direct Lighting Strength</td>
<td></td>
<td>0.25</td>
<td></td>
</tr>
<tr>
<td>Quality</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td>Depth Normals</td>
<td></td>
<td>œ</td>
</tr>
<tr>
<td>Normal Quality</td>
<td>Medium</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>Downsample</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>After Opaque</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Blur Quality</td>
<td>High</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Samples</td>
<td>Medium</td>
<td></td>
<td>P</td>
</tr>
</tbody>
</table>
<p>The SSAO settings</p>
<p>Let&#39;s look at the SSAO properties.</p>
<ul>
<li><strong>Method</strong>: This property defines the type of noise the SSAO effect uses.</li>
<li><strong>Intensity</strong>: This property defines the intensity of the darkening effect.</li>
<li><strong>Radius</strong>: When Unity calculates the ambient occlusion value, the SSAO effect takes samples of the normal texture within this radius from the current pixel. A lower Radius value improves performance because the SSAO Renderer Feature samples pixels closer to the source pixel.</li>
</ul>
<p><img src="_page_88_Picture_0.jpeg" alt=""></p>
<ul>
<li><strong>Falloff Distance:</strong> SSAO does not apply to objects farther than this distance from the Camera. A lower value increases performance in scenes that contain many distant objects.</li>
<li><strong>Direct Lighting Strength:</strong> This property defines how visible the effect is in areas exposed to direct lighting.</li>
<li><strong>Quality</strong>: For details about these quality settings, check the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/post-processing-ssao.html?q=SSAO">documentation</a><ul>
<li>Source</li>
<li>Downsample</li>
<li>After Opaque</li>
<li>Blur Quality</li>
<li>Samples</li>
</ul>
</li>
</ul>
<p><img src="_page_88_Picture_10.jpeg" alt=""></p>
<p>A scene with only an ambient occlusion texture demonstrating a varying falloff distance</p>
<p><img src="_page_88_Picture_12.jpeg" alt=""></p>
<p>SSAO adds shading to narrow gaps. Let&#39;s look at the three images to the left:</p>
<p>The top image has no SSAO. The middle image shows the calculated SSAO, while the bottom image shows the result of SSAO. Notice that the grinder and scales have a stronger edge where they meet the desk.</p>
<p>SSAO is a post-processing technique the details of which are covered <a href="#page-86-0">later</a> in this guide.</p>
<p>The haunted room in three versions: At the top, with no SSAO, in the middle, with SSAO applied, and at the bottom, rendered with SSAO</p>
<p><span id="page-89-0"></span><img src="_page_89_Picture_0.jpeg" alt=""></p>
<h2 id="decals">Decals</h2>
<p><img src="_page_89_Picture_3.jpeg" alt=""></p>
<p>A Decal Projector</p>
<p>The Decal Projector component provides you with a great way of adding detail to a mesh. Use them for elements such as bullet holes, footsteps, signage, cracks, and more. Because they use a projection framework, they conform to an uneven or curved surface. To use a Decal Projector with URP, you need to locate your Renderer Data asset and add the <strong>Decal Renderer Feature</strong>.</p>
<table>
<thead>
<tr>
<th>Renderer Features</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>&gt; &gt; Screen Space Ambient Occlusion</td>
<td>C</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Add Renderer Feature</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>ರ</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Renderer Features</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Full Screen Pass Renderer Feature</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Render Objects (Experimental)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Decal</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Asset Labels</td>
<td>Screen Space Shadows</td>
<td></td>
</tr>
</tbody>
</table>
<p>Adding the Decal Renderer Feature</p>
<p>For most purposes, you can accept the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/renderer-feature-decal.html">default settings</a>.</p>
<p>Now your scene is ready for decals. Create a decal by right-clicking in the Hierarchy view and selecting <strong>Rendering &gt; URP Decal Projector.</strong> By default, the projector uses the material Decal, which will project a white square onto a surface. Use the usual tools to position and orientate the projector. Adjust the <strong>Width</strong>, <strong>Height</strong>, and <strong>Projection Depth</strong> in the Inspector.</p>
<p><img src="_page_90_Picture_0.jpeg" alt=""></p>
<p>To customize the decal, create a material using the <strong>Shader Graph &gt; Decal</strong> shader. Then assign it to the URP Decal Projector.</p>
<table>
<thead>
<tr>
<th>1 / URP Decal Projector</th>
<th><br>14</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>2 = 4</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Decal Scene Editing Mode:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Scale Mode</td>
<td>Scale Invariant<br>2.38</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Width</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Height</td>
<td>1.15<br>1</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Projection Depth</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Pivot</td>
<td>X<br>0</td>
<td>Y O</td>
<td>N<br>0.5</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td>GrafittiMat</td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Rendering Layers</td>
<td>TDe ault</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Tilling</td>
<td>×<br>1</td>
<td>Y<br>1</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Offset</td>
<td>×<br>0</td>
<td>Y<br>0</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Opacity</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Draw Distance</td>
<td>1000</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Start Fade</td>
<td></td>
<td></td>
<td>0.9</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Angle Fade</td>
<td></td>
<td></td>
<td>6 8</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Decal Projector component settings</p>
<p>The Inspector for a Decal Projector includes three <strong>Editing Mode</strong> buttons: Scale, Crop, and Pivot/UV, which you can read about <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/renderer-feature-decal.html">here</a>.</p>
<p>By default, the projector will affect any surface within its frustum. The Decal Renderer Feature includes the setting <strong>Use Rendering Layers</strong>. Enable this to facilitate targeting specific meshes.</p>
<table>
<thead>
<tr>
<th>V v Decal</th>
<th></th>
<th>0</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Technique</td>
<td>Automatic</td>
<td></td>
<td>&gt;</td>
</tr>
<tr>
<td>Max Draw Distance</td>
<td>1000</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Use Rendering Layers</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Decal Renderer Feature settings</p>
<p>Refer back to the <a href="#page-53-0">Rendering Layers</a> section to learn about setting up and using this rendering option. Here are the steps to set up a decal:</p>
<ul>
<li><ol>
<li>Use <strong>Edit &gt; Project Settings … &gt; Tags and Layers &gt; Rendering Layers</strong> to name a Rendering Layer.</li>
</ol>
</li>
<li><ol>
<li>Select the mesh/meshes that you want to receive the projector. In the Inspector, find <strong>Mesh Renderer &gt; Additional Settings &gt; Rendering Layer Mask</strong>, and add the named Rendering Layer to the mask.</li>
</ol>
</li>
</ul>
<p><img src="_page_91_Picture_1.jpeg" alt=""></p>
<p>Adding Rendering Layer to the Mesh Renderer Rendering Layer Mask</p>
<ol>
<li>Select the URP Decal Projector and in the Inspector, select the named Rendering Layer for the Rendering Layers property.</li>
</ol>
<p><img src="_page_91_Picture_4.jpeg" alt=""></p>
<p>The image below shows the scene with and without a decal, and with a wall projection limited by using Rendering Layers.</p>
<p><img src="_page_91_Picture_6.jpeg" alt=""></p>
<p>From left to right: No decal in the image, the decal hitting all objects, and the decal applied to the wall only using Rendering Layers</p>
<h2 id="-span-id-page-92-0-span-shaders"><span id="page-92-0"></span>Shaders</h2>
<p>This section is for users who want to convert an existing custom shader to work with URP and/or want to write a custom shader in code without using Shader Graph. It provides the information required to port both basic and advanced shaders to URP from the Built-In Render Pipeline. The tables included show helpful samples of available HLSL shader functions, macros, and so on. In each case, a link is provided to the relevant include containing many other useful functions.</p>
<p>For those who already have experience coding shaders, the includes provide you with a clear idea of what&#39;s available in HLSL to write compact and efficient shaders. After considering the information here, hopefully porting your shaders to URP won&#39;t seem so daunting.</p>
<p>Another approach is to use Shader Graph to create versions of your custom shaders. An introduction to Shader Graph is provided in the <a href="#page-137-1">Additional tools</a> section.</p>
<h2 id="-span-id-page-93-0-span-comparing-urp-and-built-in-render-pipeline-shaders"><span id="page-93-0"></span>Comparing URP and Built-In Render Pipeline shaders</h2>
<p>URP shaders use the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/SL-Reference.html?">ShaderLab</a> structure, as seen in the code snippet below. As such, Property, SubShader, Tags, and Pass will all be familiar to shader coders.</p>
<p><img src="_page_93_Figure_3.jpeg" alt=""></p>
<p>The basic structure of a SubShader block</p>
<p>The first thing to notice is that a URP shader uses the key-value pair &quot;RenderPipeline&quot; = &quot;UniversalPipeline&quot; in the SubShader tag.</p>
<p>A SubShader tag with the name RenderPipeline tells Unity which render pipelines to use this SubShader with. The value of UniversalPipeline indicates that Unity should use this SubShader with URP.</p>
<p>Looking at the render pass code, you&#39;ll see the shader code contained between the HLSLPROGRAM / ENDHLSL macros. For URP, the shader code inside those passes is written in HLSL.</p>
<p>Unity will use the first SubShader block that is supported on the GPU. If the first SubShader block doesn&#39;t have a &quot;RenderPipeline&quot; = &quot;UniversalPipeline&quot; tag, it won&#39;t run in the URP. Instead, Unity will try to run the next SubShader, if any. If none of the SubShaders are supported, Unity will render the well-known magenta error shader.</p>
<h3 id="custom-shaders">Custom shaders</h3>
<p>If you start creating a custom shader by using <strong>Create &gt; Shader &gt; Unlit Shader</strong> you&#39;ll get a template intended for the Built-In Render Pipeline. It will use code that makes it incompatible with the SRP Batcher. Why does this happen? For most purposes developers will find using <a href="https://docs.unity3d.com/Packages/com.unity.shadergraph@17.0/manual/index.html">Shader Graph</a> a more convenient route for custom shaders for the URP. However, many developers will have shaders that they have created over many years using Unity and will want to know how best to use these with the URP. This section will point you in the right direction using five examples. If you want to view the scene in the Editor it is available via <strong>Shaders &gt; Shaders</strong> in the examples <a href="https://github.com/NikLever/Unity6E-book">repo</a> mentioned earlier. For more information checkout the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/writing-custom-shaders-urp.html">documentation.</a></p>
<p><span id="page-94-0"></span><img src="_page_94_Picture_1.jpeg" alt=""></p>
<p>Shaders in URP, from the left: Unlit hard coded white; unlit using property to set color; unlit using a texture; simple Lambert lighting using the Main Light - floor; for more information on how to access and use shadows, see the &quot;Shadows&quot; section further down</p>
<h4 id="-unlit-"><strong>Unlit</strong></h4>
<p>Let&#39;s unpack the simplest of shaders, a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/writing-shaders-urp-basic-unlit-structure.html">basic unlit example:</a></p>
<ul>
<li>Every visible pixel using this shader will be set to the same color.</li>
<li><strong>Properties</strong> are empty because the color is hard set.</li>
<li>In <strong>Tags</strong> the <strong>RenderType</strong> is set to <strong>Opaque</strong> and <strong>RenderPipeline</strong> is set to <strong>UniversalPipeline</strong>. The #include to use is <strong>Core.hlsl</strong> which contains a large number of useful functions and macros.<ul>
<li>If you&#39;re familiar with Built-In shaders then this serves a similar purpose to UnityCG.cginc. The function TransformObjectToHClip is found in the Core.hlsl include. The purpose of this function is to convert Object Space to <a href="https://en.wikipedia.org/wiki/Homogeneous_coordinates">Homogenous</a> Space.</li>
</ul>
</li>
<li>The vertex shader vert simply sets the positionHCS value of the <strong>Varyings</strong> struct that is passed to the fragment shader frag.</li>
<li>HLSL uses <a href="https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-semantics">semantics</a> for all values passed between shader stages. A semantic is a string attached to a shader input or output that conveys information about the intended use of a parameter.<ul>
<li>For example, with <strong>Attributes</strong> positionOS, the semantic is POSITION. When compiling POSITION in a vertex shader is the position in Object Space for a vertex.</li>
</ul>
</li>
</ul>
<p><img src="_page_95_Picture_0.jpeg" alt=""></p>
<p>The fragment shader simply returns white resulting in the white capsule on the left in the image above.</p>
<pre><code><span class="hljs-keyword">Shader </span><span class="hljs-string">"CustomURP/Unlit"</span>
{
 Properties
 { }
 <span class="hljs-keyword">SubShader
</span> {
 Tags { <span class="hljs-string">"RenderType"</span> = <span class="hljs-string">"Opaque"</span> <span class="hljs-string">"RenderPipeline"</span> = <span class="hljs-string">"UniversalPipeline"</span> }
 Pass
 {
 HLSLPROGRAM

 <span class="hljs-comment">#pragma vertex vert</span>
 <span class="hljs-comment">#pragma fragment frag</span>
 <span class="hljs-comment">#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"</span>
 struct Attributes
 {
 float4 positionOS : POSITION<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 struct Varyings
 {
 float4 positionHCS : SV_POSITION<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 Varyings vert(Attributes IN)
 {
 Varyings OUT<span class="hljs-comment">;</span>
 OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz)<span class="hljs-comment">;</span>
 return OUT<span class="hljs-comment">;</span>
 }
 half4 frag() : SV_Target
 {
 half4 customColor = half4(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<span class="hljs-comment">;</span>
 return customColor<span class="hljs-comment">;</span>
 }

 ENDHLSL
 }
 }
}
</code></pre><p><span id="page-96-0"></span><img src="_page_96_Picture_0.jpeg" alt=""></p>
<h4 id="-unlit-color-"><strong>Unlit Color</strong></h4>
<ul>
<li>For the second shader example, unlit color, you&#39;ll need to include a <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/SL-Properties.html">property</a> to set the color.Use an attribute, [MainColor]; this is optional but helps inform Unity how to use the property. The name of the property is _BaseColor, the name in the Inspector is <strong>Base Color</strong> and the type is a Color.</li>
<li>Shader variables with URP must be compatible with SRP Batcher. In this example compatibility is achieved by declaring them inside two macros CBUFFER_ START(UnityPerMaterial) and CBUFFER_END (described as a CBUFFER block).</li>
<li>Now the fragment shader returns the value of _BaseColor.</li>
</ul>
<pre><code><span class="hljs-keyword">Shader </span><span class="hljs-string">"CustomURP/UnlitColor"</span>
{
 Properties
 { 
 [MainColor] _BaseColor(<span class="hljs-string">"Base Color"</span>, Color) = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
 }
 <span class="hljs-keyword">SubShader
</span> {
 Tags { <span class="hljs-string">"RenderType"</span> = <span class="hljs-string">"Opaque"</span> <span class="hljs-string">"RenderPipeline"</span> = <span class="hljs-string">"UniversalPipeline"</span> }
 Pass
 {
 HLSLPROGRAM
 <span class="hljs-comment">#pragma vertex vert</span>
 <span class="hljs-comment">#pragma fragment frag</span>
 <span class="hljs-comment">#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"</span>
 struct Attributes
 {
 float4 positionOS : POSITION<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 struct Varyings
 {
 float4 positionHCS : SV_POSITION<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 CBUFFER_START(UnityPerMaterial)
 half4 _BaseColor<span class="hljs-comment">;</span>
 CBUFFER_END
 Varyings vert(Attributes IN)
 {
 Varyings OUT<span class="hljs-comment">;</span>
 OUT.positionHCS = TransformObjectToHClip (IN.positionOS.xyz)<span class="hljs-comment">;</span>
 return OUT<span class="hljs-comment">;</span>
 }
</code></pre><p><span id="page-97-0"></span><img src="_page_97_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th></th>
<th>half4 frag() : SV_Target</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>{</td>
</tr>
<tr>
<td></td>
<td>return _BaseColor;</td>
</tr>
<tr>
<td></td>
<td>}</td>
</tr>
<tr>
<td></td>
<td>ENDHLSL</td>
</tr>
<tr>
<td>}</td>
<td></td>
</tr>
<tr>
<td>}</td>
<td></td>
</tr>
<tr>
<td>}</td>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>To confirm if the shader is SRP Batcher compatible, select the shader and check the Inspector which will indicate if the shader is SRP Batcher compatible.</p>
<table>
<thead>
<tr>
<th>Custom URP/Unlit (Shader)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Surface shader</td>
<td>no</td>
</tr>
<tr>
<td>Fixed function</td>
<td>no</td>
</tr>
<tr>
<td>Preprocess only</td>
<td></td>
</tr>
<tr>
<td>Compiled code</td>
<td>Compile and show code   ▼</td>
</tr>
<tr>
<td>Cast shadows</td>
<td>no</td>
</tr>
<tr>
<td>Render queue</td>
<td>2000</td>
</tr>
<tr>
<td>LOD</td>
<td>0</td>
</tr>
<tr>
<td>Ignore projector</td>
<td>no</td>
</tr>
<tr>
<td>Disable batching</td>
<td>no</td>
</tr>
<tr>
<td>Keywords</td>
<td></td>
</tr>
<tr>
<td>SRP Batcher</td>
<td>compatible</td>
</tr>
</tbody>
</table>
<p>The shader&#39;s Inspector will indicate if it&#39;s compatible with the SRP Batcher.</p>
<h4 id="-unlit-textured-"><strong>Unlit Textured</strong></h4>
<p>The third example in the image uses a texture.</p>
<ul>
<li>The shader has a property named _BaseMap, (in the Inspector it&#39;s called <strong>Base Map</strong>) that uses the attribute [MainTexture]and the type 2D.</li>
<li>To use a texture you need interpolated UV values passing from the vertex to the fragment shader. You add a float2, uv, with semantic TEXCOORD0, to both the Attributes and the Varyings structs.</li>
<li>Just before the CBUFFER block, add two macros: TEXTURE2D which takes the property _BaseMap, and SAMPLER(sampler_BaseMap).</li>
</ul>
<p><img src="_page_98_Picture_0.jpeg" alt=""></p>
<ul>
<li>For tiling and offset to work you need a float4 defining that uses the name of the 2D property with the suffix _ST. This is essential when using the macro TRANSFORM_TEX, which is used by the vertex shader. The macro takes the vertex UV value, in this example IN.uv, and a 2D property that has been declared using the TEXTURE2D macro. It ensures tiling and offsets are supported.</li>
<li>The fragment shader uses the macro SAMPLE_TEXTURE2D. This takes three parameters – a Texture2D, a sampler, and the UV value, and returns a color value. This value is returned in the frag method.</li>
</ul>
<pre><code><span class="hljs-keyword">Shader </span><span class="hljs-string">"CustomURP/UnlitTexture"</span>
{
 Properties
 { 
 [MainColor] _BaseColor(<span class="hljs-string">"Base Color"</span>, Color) = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
 [MainTexture] _BaseMap(<span class="hljs-string">"Base Map"</span>, <span class="hljs-number">2</span>D) = <span class="hljs-string">"white"</span> {}
 }
 <span class="hljs-keyword">SubShader
</span> {
 Tags { <span class="hljs-string">"RenderType"</span> = <span class="hljs-string">"Opaque"</span> <span class="hljs-string">"RenderPipeline"</span> = <span class="hljs-string">"UniversalPipeline"</span> }
 Pass
 {
 HLSLPROGRAM
 <span class="hljs-comment">#pragma vertex vert</span>
 <span class="hljs-comment">#pragma fragment frag</span>
 <span class="hljs-comment">#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"</span>
 struct Attributes
 {
 float4 positionOS : POSITION<span class="hljs-comment">;</span>
 float2 uv : TEXCOORD0<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 struct Varyings
 {
 float4 positionHCS : SV_POSITION<span class="hljs-comment">;</span>
 float2 uv : TEXCOORD0<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 TEXTURE2D(_BaseMap)<span class="hljs-comment">;</span>
 SAMPLER(sampler_BaseMap)<span class="hljs-comment">;</span>
 CBUFFER_START(UnityPerMaterial)
 half4 _BaseColor<span class="hljs-comment">;</span>
 float4 _BaseMap_ST<span class="hljs-comment">;</span>
 CBUFFER_END
 Varyings vert(Attributes IN)
 {
</code></pre><pre><code> Varyings <span class="hljs-keyword">OUT</span>;
 <span class="hljs-keyword">OUT</span>.positionHCS = TransformObjectToHClip (<span class="hljs-keyword">IN</span>.positionOS.xyz);
 <span class="hljs-keyword">OUT</span>.uv = TRANSFORM_TEX(<span class="hljs-keyword">IN</span>.uv, _BaseMap);
 <span class="hljs-keyword">return</span> <span class="hljs-keyword">OUT</span>;
 }
 half4 frag(Varyings <span class="hljs-keyword">IN</span>) : <span class="hljs-type">SV_Target</span>
 {
 half4 color = SAMPLE_TEXTURE2D(_BaseMap, sampler_Base Map, <span class="hljs-keyword">IN</span>.uv);
 <span class="hljs-keyword">return</span> color;
 }
 ENDHLSL
 }
 }
}
</code></pre><h4 id="-lit-simple-"><strong>Lit Simple</strong></h4>
<ul>
<li>To use <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/use-built-in-shader-methods-lighting.html">lighting in a URP shader</a> add the include <strong>Lighting.hlsl</strong>, which is in the same folder as <strong>Core.hlsl</strong>.</li>
<li>This example shader uses the main light the directional light with the greatest intensity. It also uses the Lambert technique, calculating at the vertex level and using the interpolated value in the fragment shader. Therefore, you need to update the Varyings struct adding a half3 lightAmount with semantic TEXCOORD2.</li>
<li>The vertex shader has a VertexNormalInputs using the function GetVertexNormalInputs. This function takes a normal in object space and converts it to world space.<ul>
<li>For a centered object you can use the object space position as a proxy to the normal. VertexNormalInputs is a struct containing a float4 value, normalWS.</li>
</ul>
</li>
<li>You get details of the main light using the function GetMainLight. This returns a Light struct containing, amongst other data, the light color and direction.</li>
<li>Finally, in the vert function, you use the function LightingLambert to return the lighting at the current vertex. The LightingLambert function takes three parameters – light color, light direction, and a world space normal. At this point you have all the necessary data to call the function. It returns a half3.</li>
<li>The fragment shader uses the macro SAMPLE_TEXTURE2D. This takes three parameters – a Texture2D, a sampler, and a float2 value, uv. You multiply this by the lightAmount after bouncing this up to a half4 by adding an additional w value set to 1.</li>
</ul>
<p><img src="_page_100_Picture_0.jpeg" alt=""></p>
<pre><code><span class="hljs-keyword">Shader </span><span class="hljs-string">"CustomURP/LitSimple"</span>
{
 Properties
 { 
 [MainColor] _BaseColor(<span class="hljs-string">"Base Color"</span>, Color) = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
 [MainTexture] _BaseMap(<span class="hljs-string">"Base Map"</span>, <span class="hljs-number">2</span>D) = <span class="hljs-string">"white"</span> {}
 }
 <span class="hljs-keyword">SubShader
</span> {
 Tags { <span class="hljs-string">"RenderType"</span> = <span class="hljs-string">"Opaque"</span> <span class="hljs-string">"RenderPipeline"</span> = <span class="hljs-string">"UniversalPipeline"</span> }
 Pass
 {
 HLSLPROGRAM
 <span class="hljs-comment">#pragma vertex vert</span>
 <span class="hljs-comment">#pragma fragment frag</span>
 <span class="hljs-comment">#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"</span>
 <span class="hljs-comment">#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"</span>
 struct Attributes
 {
 float4 positionOS : POSITION<span class="hljs-comment">;</span>
 float2 uv : TEXCOORD0<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 struct Varyings
 {
 float4 positionHCS : SV_POSITION<span class="hljs-comment">;</span>
 float2 uv : TEXCOORD0<span class="hljs-comment">;</span>
 half3 lightAmount : TEXCOORD2<span class="hljs-comment">;</span>
 }<span class="hljs-comment">;</span>
 TEXTURE2D(_BaseMap)<span class="hljs-comment">;</span>
 SAMPLER(sampler_BaseMap)<span class="hljs-comment">;</span>
 CBUFFER_START(UnityPerMaterial)
 half4 _BaseColor<span class="hljs-comment">;</span>
 float4 _BaseMap_ST<span class="hljs-comment">;</span>
 CBUFFER_END
 Varyings vert(Attributes IN)
 {
 Varyings OUT<span class="hljs-comment">;</span>
 OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz)<span class="hljs-comment">;</span>
 OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap)<span class="hljs-comment">;</span>
 VertexNormalInputs positions =
 GetVertexNormalInputs(IN.positionOS)<span class="hljs-comment">;</span>
 Light light = GetMainLight()<span class="hljs-comment">;</span>
</code></pre><p><span id="page-101-0"></span><img src="_page_101_Picture_0.jpeg" alt=""></p>
<p> } }</p>
<pre><code> <span class="hljs-keyword">OUT</span>.lightAmount = LightingLambert(light.color, light.direction, positions.normalWS.xyz);
 <span class="hljs-keyword">return</span> <span class="hljs-keyword">OUT</span>;
 }
 half4 frag(Varyings <span class="hljs-keyword">IN</span>) : <span class="hljs-type">SV_Target</span>
 {
 half4 color = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, <span class="hljs-keyword">IN</span>.uv) * half4(<span class="hljs-keyword">IN</span>.lightAmount, <span class="hljs-number">1</span>);
 <span class="hljs-keyword">return</span> color;
 }
 ENDHLSL
 }
</code></pre><h4 id="-shadows-"><strong>Shadows</strong></h4>
<ul>
<li>To control the strength of the shadow add a property _ShadowStrength, which is called <strong>Shadow Strength</strong> in the Inspector. It is a Float value initialized to 0.5. Add this value to the CBUFFER block.<ul>
<li>To use shadows you need the pragma, multi_compile, adding: _MAIN_LIGHT_ SHADOWS</li>
<li>MAIN_LIGHT_SHADOWS_CASCADE</li>
<li>_MAIN_LIGHT_SHADOWS_SCREEN</li>
</ul>
</li>
<li>The Varyings struct has a float4 value shadowCoords using the semantic TEXCOORD3.</li>
<li>In the vert function you use the function GetVertexPositionInputs, to convert object space to world space. Now you can convert the vertex position to a position on the shadow map using the function GetShadowCoord. Save this as the Varyings value, shadowCoords.</li>
<li>In the frag function the shadowAmount uses the function MainLightRealtimeShadow passing the interpolated shadowCoord. Strength, is set to one minus _ ShadowStrength. The color value is the _BaseColor modulated by the maximum of strength and shadowAmount.</li>
</ul>
<pre><code>Shader <span class="hljs-string">"CustomURP/SimpleShadows"</span>
{
 Properties
 { 
 [MainColor] _BaseColor(<span class="hljs-string">"Base Color"</span>, Color) = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
 _ShadowStrength(<span class="hljs-string">"Shadow Strength"</span>, Float) = <span class="hljs-number">0.5</span>
 }
 SubShader
 {
 Tags { <span class="hljs-string">"RenderType"</span> = <span class="hljs-string">"AlphaTest"</span> <span class="hljs-string">"RenderPipeline"</span> = <span class="hljs-string">"UniversalPipeline"</span> }
 Pass
 {
 HLSLPROGRAM
 #<span class="hljs-keyword">pragma</span> vertex vert
 #<span class="hljs-keyword">pragma</span> fragment frag
 #<span class="hljs-keyword">pragma</span> multi_compile _ _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_
 SHADOWS_CASCADE _MAIN_LIGHT_SHADOWS_SCREEN
 #include <span class="hljs-string">"Packages/com.unity.render-pipelines.universal/
 ShaderLibrary/Lighting.hlsl"</span>
 struct Attributes
 {
 float4 positionOS : <span class="hljs-type">POSITION</span>;
 };
 struct Varyings
 {
 float4 positionCS : <span class="hljs-type">SV_POSITION</span>;
 float4 shadowCoords : <span class="hljs-type">TEXCOORD3</span>;
 };
 CBUFFER_START(UnityPerMaterial)
 half4 _BaseColor;
 float _ShadowStrength;
 CBUFFER_END
 Varyings vert(Attributes <span class="hljs-keyword">IN</span>)
 {
 Varyings <span class="hljs-keyword">OUT</span>;
 <span class="hljs-keyword">OUT</span>.positionCS = TransformObjectToHClip(<span class="hljs-keyword">IN</span>.positionOS.xyz);
 VertexPositionInputs positions =
 GetVertexPositionInputs(<span class="hljs-keyword">IN</span>.positionOS.xyz);
 // Convert the vertex position to a position on the shadow map
 float4 shadowCoordinates = GetShadowCoord(positions);
 <span class="hljs-keyword">OUT</span>.shadowCoords = shadowCoordinates;
 <span class="hljs-keyword">return</span> <span class="hljs-keyword">OUT</span>;
 }
 half4 frag(Varyings <span class="hljs-keyword">IN</span>) : <span class="hljs-type">SV_Target</span>
 {
</code></pre><p><img src="_page_103_Picture_0.jpeg" alt=""></p>
<p> } }</p>
<p> // Get the value from the shadow map at the shadow coordinates half shadowAmount = MainLightRealtimeShadow(IN.shadowCoords); half strength = 1.0 - _ShadowStrength; half4 color = _BaseColor * max(strength, shadowAmount); return color; } ENDHLSL }</p>
<blockquote>
<p><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/writing-custom-shaders-urp.html">Custom shaders</a> require some work when upgrading to URP. These tables of functions will be helpful.</p>
</blockquote>
<ul>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/use-built-in-shader-methods-transformations.html">Transform positions in a custom URP shader</a></li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/use-built-in-shader-methods-camera.html">Use the camera in a custom URP shader</a></li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/use-built-in-shader-methods-lighting.html">Use lighting in a custom URP shader</a></li>
<li><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/use-built-in-shader-methods-shadows.html">Use shadows in a custom URP shader</a></li>
</ul>
<p><img src="_page_103_Picture_8.jpeg" alt=""></p>
<p>See this step-by-step video tutorial that uses a Unity project to show how to convert a custom unlit Built-In shader to URP.</p>
<h4 id="-see-the-tutorial-https-youtu-be-db1ed8zmy3u-"><a href="https://youtu.be/db1ed8ZMy3U">See the tutorial</a></h4>
<p><strong>Note:</strong> A great resource for users planning to write shaders for URP is <a href="https://www.cyanilux.com/tutorials/urp-shader-code/">this tutorial</a> by Cyanilux.</p>
<h2 id="-span-id-page-104-0-span-pipeline-callbacks"><span id="page-104-0"></span>Pipeline callbacks</h2>
<p>A great feature of SRPs is that you can add code at just about any stage of the rendering process using a C# script. Scripts can be injected at stages such as:</p>
<ul>
<li>Rendering shadows</li>
<li>Rendering prepasses</li>
<li>Rendering G-buffer</li>
<li>Rendering deferred lights</li>
<li>Rendering opaques</li>
<li>Rendering Skybox</li>
<li>Rendering transparents</li>
<li>Rendering post-processing</li>
</ul>
<p>You can inject scripts in the rendering process via the <strong>Add Renderer Feature</strong> option in the Inspector for the <strong>Universal Renderer Data Asset</strong>. Remember, when using URP, there is a Universal Renderer Data object and a URP Asset. The URP Asset has a Renderer List with at least one Universal Renderer Data object assigned. It is the asset you assign in <strong>Project Settings &gt; Graphics &gt; Scriptable Render Pipeline Settings</strong>.</p>
<p>If you are experimenting with multiple setting assets for different scenes, then attaching the following script to your Main Camera can be useful. Set the <strong>Pipeline Asset</strong> in the Inspector. Then it will switch the asset when the new scene is loaded.</p>
<p><span id="page-105-0"></span><img src="_page_105_Picture_0.jpeg" alt=""></p>
<p><img src="_page_105_Figure_1.jpeg" alt=""></p>
<p>Script to switch Universal Render Pipeline Asset on scene load</p>
<p>The next section covers two different types of Renderer Features, one for artists and the other for experienced programmers.</p>
<h2 id="render-objects">Render Objects</h2>
<p>A common problem in games is losing sight of the player character as they disappear behind environment objects. You could attempt to move the Camera so that the character is always in view, or adjust the environment to be as open as possible. But such options are not always available. A good trick is to show a silhouette of the character when an environment model appears between the character and the Camera, as shown in the image below.</p>
<p><img src="_page_105_Picture_6.jpeg" alt=""></p>
<p>Showing a silhouette when an environment model masks the character</p>
<p><img src="_page_106_Picture_0.jpeg" alt=""></p>
<p>Here&#39;s how you can you create this silhouette:</p>
<ul>
<li><ol>
<li>First, you need a material to use when the character is masked. Create a material and set the shader to <strong>Universal Render Pipeline &gt; Lit or Unlit</strong> (the previous image shows the Lit option). Set the <strong>Surface Inputs &gt; Base Map</strong> color. In this example, the material is called Character.</li>
</ol>
</li>
<li><ol>
<li>To avoid rendering the character more times than necessary, let&#39;s place it on a special layer. Select the character, add a <strong>SeeBehind</strong> layer to the Layers list and select it for the character.</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>@ Inspector @ Lighting</th>
<th></th>
<th>Navigation</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>v fred</td>
<td></td>
<td></td>
<td></td>
<td>Static</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Tag Untagged</td>
<td></td>
<td></td>
<td>Layer SeeBehind</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Prefab @ fred</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>O</td>
</tr>
<tr>
<td></td>
<td>Overides</td>
<td>D</td>
<td>Select</td>
<td></td>
<td>Open</td>
</tr>
</tbody>
</table>
<ol>
<li>Select the <strong>Renderer Data</strong> object used by the URP Asset. Go to the <strong>Opaque Layer Mask</strong> and exclude the SeeBehind layer. The character will then disappear.</li>
</ol>
<table>
<thead>
<tr>
<th>Filtering<br>Opaque Layer Mask</th>
<th>Mixed</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Transparent Layer Mask</td>
<td>Nothing</td>
<td></td>
</tr>
<tr>
<td>Rendering</td>
<td>Everything</td>
<td></td>
</tr>
<tr>
<td>Rendering Path</td>
<td>Default<br>1</td>
<td></td>
</tr>
<tr>
<td>Depth Priming Mode<br>Depth Texture Mode</td>
<td>TransparentFX<br>1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ignore Raycast<br>1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>1<br>Water</td>
<td></td>
</tr>
<tr>
<td>RenderPass</td>
<td>1<br>UI</td>
<td></td>
</tr>
<tr>
<td>Native RenderPass</td>
<td>SeeBehind</td>
<td></td>
</tr>
<tr>
<td>Shadows</td>
<td>Overlay</td>
<td></td>
</tr>
<tr>
<td>Transparent Receive Sh</td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>Click <strong>Add Renderer Feature</strong> and select <strong><a href="https://docs.unity3d.com/6000.0/Documentation/Manual/urp/renderer-features/how-to-custom-effect-render-objects.html">Render Objects</a></strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>Native F</th>
<th>a</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Shadows</td>
<td>Renderer Features</td>
<td></td>
</tr>
<tr>
<td>Transpa</td>
<td>Screen Space Shadows</td>
<td></td>
</tr>
<tr>
<td>Post-proc</td>
<td>Full Screen Pass Renderer Feature</td>
<td></td>
</tr>
<tr>
<td>Enabled</td>
<td>Render Objects</td>
<td></td>
</tr>
<tr>
<td>Data</td>
<td>Decal</td>
<td>ess Da O</td>
</tr>
<tr>
<td></td>
<td>Dither Effect Feature</td>
<td></td>
</tr>
<tr>
<td>Overrides</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Stencil</td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="_page_107_Picture_0.jpeg" alt=""></p>
<ol>
<li>Fill out the settings for this Render Object&#39;s <strong>Pass</strong>. Give it a name and choose when the render should be triggered. In this example, it&#39;s called AfterRenderingOpaques.</li>
</ol>
<p>Set the <strong>Layer Mask</strong> to the <strong>SeeBehind</strong> layer, which was the layer chosen for the character. Expand the <strong>Overrides</strong> and set the <strong>Override Mode</strong> to <strong>Material</strong>. Select the material created in step 1. You&#39;ll want to use <strong>Depth</strong> when rendering, without having to update the depth buffer by writing to it. Set the <strong>Depth Test</strong> to <strong>Greater</strong> so that this Pass only renders when the distance to the rendered pixel is further from the Camera than the distance currently stored in the depth buffer.</p>
<table>
<thead>
<tr>
<th>V Draw Character Behind (Render Objects)</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>Draw Character Behind</td>
<td></td>
</tr>
<tr>
<td>Event</td>
<td>AfterRenderingOpaques</td>
<td>A</td>
</tr>
<tr>
<td>Filters</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Queue</td>
<td>Opaque</td>
<td>P</td>
</tr>
<tr>
<td>Layer Mask</td>
<td>SeeBehind</td>
<td>C</td>
</tr>
<tr>
<td>LightMode Tags</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>List is Empty</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Overrides<br>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td>Character</td>
<td>O</td>
</tr>
<tr>
<td>Pass Index</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Depth</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Write Depth</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Depth Test</td>
<td>Greater</td>
<td>œ</td>
</tr>
<tr>
<td>Stencil</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Camera</td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>At this stage, you only see the silhouette of the character when it&#39;s behind another object. You don&#39;t see the character at all when it&#39;s in full view. To fix this, add another <strong>Render Objects</strong> feature. This time you don&#39;t need to update the Overrides panel. This Pass will draw the character when not masked by another object.</li>
</ol>
<table>
<thead>
<tr>
<th>V &gt; Draw Character Front (Render Objects)</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>Draw Character Front</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Event</td>
<td>AfterRenderingOpaques</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Filters</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Queue</td>
<td>Opaque</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Layer Mask</td>
<td>SeeBehind</td>
<td></td>
<td></td>
</tr>
<tr>
<td>LightMode Tags</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>List is Empty</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The silhouette trick is a good example of the benefits of using the SRP workflow to facilitate easy injection in the render pipeline.</p>
<h2 id="-span-id-page-108-0-span-the-render-graph-system"><span id="page-108-0"></span>The render graph system</h2>
<p>The <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/render-graph-introduction.html">render graph system</a> allows you to author a custom SRP in a maintainable and modular way. You can use the RenderGraph API to create a render graph, a high-level representation of the custom SRP&#39;s render passes, which explicitly states how the render pipeline uses its resources across render passes. It is not a graphical system.</p>
<p>Describing render passes in this way has two benefits: It simplifies render pipeline configuration, and it allows the render graph system to efficiently manage parts of the render pipeline, which can improve runtime performance.</p>
<p>To use the render graph system, you need to write your code in a different way to that required for a regular custom SRP.</p>
<h4 id="-main-principles-"><strong>Main principles</strong></h4>
<p>Before you write render passes with the <strong>RenderGraph</strong> API, know the following foundational principles:</p>
<ul>
<li>You no longer handle resources directly; instead, you use render graph system-specific handles. All <strong>RenderGraph</strong> APIs use these handles to manipulate resources. The resource types a render graph manages are <strong>RTHandles, ComputeBuffers</strong>, and <strong>RendererLists</strong>.</li>
<li>Actual resource references are only accessible within the execution code of a render pass.</li>
<li>The framework requires an explicit declaration of render passes. Each render pass must state which resources it reads from and/or writes to.</li>
<li>There is no persistence between each execution of a render graph. This means that the resources you create inside one execution of the render graph don&#39;t carry over to the next execution.</li>
<li>For resources that need persistence (e.g., from one frame to another), you can create them outside of a render graph, like regular resources, and import them. They behave like any other render graph resource in terms of dependency tracking, but the graph does not handle their lifetime.</li>
<li>A render graph mostly uses RTHandles for texture resources. This has a number of implications on how to write shader code and how to set them up.</li>
</ul>
<h4 id="-resource-management-"><strong>Resource management</strong></h4>
<p>The render graph system calculates the lifetime of each resource with the high-level representation of the whole frame. This means that when you create a resource via the RenderGraph API, the render graph system does not create the resource at that time. Instead, the API returns a handle that represents the resource, which you then use with all RenderGraph APIs. The render graph only creates the resource just before the first pass that needs to write it. In this case, &quot;creating&quot; does not necessarily mean that the render</p>
<p><span id="page-109-0"></span><img src="_page_109_Picture_0.jpeg" alt=""></p>
<p>graph system allocates resources. Rather, it means that it provides the necessary memory to represent the resource so that it can use the resource during a render pass. In the same manner, it also releases the resource memory after the last pass that needs to read it. This way, the render graph system can reuse memory in the most efficient manner based on what you declare in your passes. If the render graph system does not execute a pass that requires a specific resource, then the system does not allocate the memory for the resource.</p>
<h4 id="-render-graph-execution-overview-"><strong>Render graph execution overview</strong></h4>
<p>Render graph execution is a three-step process that the render graph system completes, from scratch, every frame. This is because a graph can change dynamically from frame to frame, for example, depending on the actions of the user.</p>
<ul>
<li><strong>Setup:</strong> The first step is to set up all the render passes. This is where you declare all the render passes to execute and the resources each render pass uses.</li>
<li><strong>Compilation:</strong> The second step is to compile the graph. During this step, the render graph system culls render passes if no other render pass uses their outputs. This allows for less organized setups because you can reduce specific logic when you set up the graph. This step also calculates the lifetime of resources. This allows the render graph system to create and release resources in an efficient way as well as compute the proper synchronization points when it executes passes on the asynchronous compute pipeline.</li>
<li><strong>Execution:</strong> Finally, execute the graph. The render graph system executes all render passes that it did not cull, in declaration order. Before each render pass, the render graph system creates the proper resources and releases them after the render pass if later render passes do not use them.</li>
</ul>
<p>Let&#39;s look at a practical example. The final code for this example is <a href="https://github.com/NikLever/Unity6E-book/blob/main/Assets/Haunted_Mansion/Scenes/TintFeature.cs">here</a>.</p>
<p><span id="page-110-0"></span><img src="_page_110_Picture_1.jpeg" alt=""></p>
<p>Learn how to use the render graph system to create a Renderer Feature that is injected into the render pipeline. In this tutorial we create a performant post-processing pass using the latest methods to reduce bandwidth, making it suitable on mobile platforms.</p>
<p><a href="https://www.youtube.com/watch?v=db1ed8ZMy3U">Watch the tutorial</a> </p>
<h3 id="renderer-feature">Renderer Feature</h3>
<p>A <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/urp-renderer-feature.html?">Renderer Feature</a> can be used at any stage in URP to affect the final render. This example is of a post-processing technique using a material to process each pixel in the image, creating a tint effect.</p>
<ol>
<li>Start by finding a suitable folder in the Project Assets folder. Right-click and choose <strong>Create &gt; Rendering &gt; URP Renderer Feature</strong>. Name it <strong>TintFeature</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>Rendering<br>Material</th>
<th></th>
<th>URP Asset (with 2D Renderer)<br>URP Asset (with Universal Renderer)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Create</td>
<td></td>
<td>Lens Flare</td>
<td></td>
<td>URP Renderer Feature</td>
</tr>
<tr>
<td>Reveal in Finder</td>
<td></td>
<td>Lens Flare (SRP)</td>
<td></td>
<td>URP 2D Renderer</td>
</tr>
<tr>
<td>Open</td>
<td></td>
<td>Render Texture<br>URP Universal Renderer<br>Lightmap Parameters</td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>Double-click the default <strong>TintFeature</strong> file. This is a C# script containing boilerplate for a Renderer Feature.</li>
</ol>
<p><img src="_page_111_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>13</th>
<th>using UnityEngine;</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>using UnityEngine Rendering;</td>
</tr>
<tr>
<td>m</td>
<td>using UnityEngine.Rendering.Universal;</td>
</tr>
<tr>
<td>বা</td>
<td>using UnityEngine.Rendering.RenderGraphModule;</td>
</tr>
<tr>
<td>5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>0 references</td>
</tr>
<tr>
<td></td>
<td>6 public class TintRendererFeature : ScriptableRendererFeature</td>
</tr>
<tr>
<td>77</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>2 references</td>
</tr>
<tr>
<td>8 -</td>
<td>class CustomRenderPass : ScriptableRenderPass</td>
</tr>
<tr>
<td>a</td>
<td></td>
</tr>
<tr>
<td>18</td>
<td>// This class stores the data needed by the RenderGraph pass.</td>
</tr>
<tr>
<td>11</td>
<td>// It is passed as a parameter to the delegate function that executes the RenderGraph pass.</td>
</tr>
<tr>
<td></td>
<td>3 references</td>
</tr>
<tr>
<td>12</td>
<td>private class PassData</td>
</tr>
<tr>
<td>13</td>
<td>4</td>
</tr>
<tr>
<td>14</td>
<td>1</td>
</tr>
<tr>
<td>15</td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>// This static method is passed as the RenderFunc delegate to the RenderGraph render pass.</td>
</tr>
<tr>
<td>17</td>
<td>// It is used to execute draw commands.</td>
</tr>
<tr>
<td></td>
<td>1 reference</td>
</tr>
<tr>
<td>18</td>
<td>static void ExecutePass(PassData data, RasterGraphContext context)</td>
</tr>
<tr>
<td>19</td>
<td>4</td>
</tr>
<tr>
<td>20</td>
<td>2</td>
</tr>
<tr>
<td>21</td>
<td></td>
</tr>
<tr>
<td>22</td>
<td>// RecordRenderGraph is where the RenderCraph handle can be accessed, through which render passes can be added to th</td>
</tr>
<tr>
<td>23</td>
<td>// FrameData is a context container through which URP resources can be accessed and managed.</td>
</tr>
<tr>
<td></td>
<td>O references</td>
</tr>
<tr>
<td>24</td>
<td>public override void RecordRenderGraph renderGraph, ContextContainer frameData)</td>
</tr>
<tr>
<td>25</td>
<td></td>
</tr>
<tr>
<td>26</td>
<td>const string passName = &quot;Custom Render Pass&quot;;</td>
</tr>
<tr>
<td>27</td>
<td></td>
</tr>
<tr>
<td>28</td>
<td>// This adds a raster render pass to the graph, specifying the name and the data type that will be passed to the</td>
</tr>
<tr>
<td>29</td>
<td>using (var builder = renderGraph.AddRasterRenderPass&lt;PassName, out var passData))</td>
</tr>
<tr>
<td>38</td>
<td>4</td>
</tr>
<tr>
<td>31</td>
<td>// Use this scope to set the required inputs and outputs of the pass and to</td>
</tr>
<tr>
<td>32</td>
<td>// setup the passData with the required properties needed at pass execution time.</td>
</tr>
<tr>
<td>33</td>
<td></td>
</tr>
<tr>
<td>34</td>
<td>// Make use of frameData to access resources and camera data through the dedicated containers.</td>
</tr>
<tr>
<td>35</td>
<td>// Eg:</td>
</tr>
<tr>
<td>36</td>
<td>// UniversalCameraData = frameData = frameData.Get<UniversalCameraData>();</td>
</tr>
<tr>
<td>37</td>
<td>UniversalResourceData = frameData = frameData.Get<UniversalResourceData>();</td>
</tr>
<tr>
<td>38</td>
</tr>
</tbody>
</table>
<p>Default code for a Renderer Feature</p>
<ul>
<li><ol>
<li>Add these properties to the TintRendererFeature:<ul>
<li><strong>RenderPassEvent</strong> allows the user to set the injection point in the Inspector.</li>
<li><strong>Material</strong> is the one to use when copying.</li>
<li>Requirements are set to <strong>Color</strong>.</li>
<li>Initialize a ProfilingSampler. You&#39;ll get two ID values allowing access to _ BlitTexture and _BlitScaleBias.</li>
<li>Lastly, define a <strong>MaterialPropertyBlock</strong>.</li>
</ul>
</li>
</ol>
</li>
</ul>
<pre><code><span class="hljs-keyword">public</span> RenderPassEvent injectionPoint = RenderPassEvent.AfterRendering;
<span class="hljs-keyword">public</span> Material passMaterial;
<span class="hljs-keyword">public</span> ScriptableRenderPassInput requirements = 
 ScriptableRenderPassInput.Color;
<span class="hljs-keyword">private</span> ProfilingSampler m_Sampler;
<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">readonly</span> <span class="hljs-keyword">int</span> m_BlitScaleBiasID = 
 Shader.PropertyToID(<span class="hljs-string">"_BlitScaleBias"</span>);
<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> MaterialPropertyBlock s_SharedPropertyBlock = <span class="hljs-literal">null</span>;
</code></pre><ol>
<li>Rename <strong>CustomRenderPass</strong> to <strong>TintPass</strong> and add these properties to the <strong>TintPass</strong> class. The Material will contain the shader you apply to the current state of the rendered image. The PassData defines the data used when you declare the pass. This is where you set the data that the rendering code can access.</li>
</ol>
<pre><code><span class="hljs-keyword">private</span> Material m_Material;
<span class="hljs-keyword">private</span> <span class="hljs-keyword">string</span> m_PassName;
<span class="hljs-keyword">private</span> ProfilingSampler m_Sampler;
<span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title">PassData</span>
{
 <span class="hljs-keyword">internal</span> Material material;
 <span class="hljs-keyword">internal</span> TextureHandle source;
}
</code></pre><ol>
<li>Add a constructor to the TintPass to initialize the material, and set the position of this pass in the render pipeline.</li>
</ol>
<pre><code>public TintPass(Material mat, <span class="hljs-built_in">string</span> <span class="hljs-built_in">name</span>)
 {
 m_PassName = <span class="hljs-built_in">name</span>;
 m_Material = mat;
 m_Sampler ??= new ProfilingSampler(GetType().Name + <span class="hljs-string">"_"</span> + <span class="hljs-built_in">name</span>);
 }
</code></pre><ol>
<li>Delete the functions ExecutePass, OnCameraSetup, Execute and OnCameraCleanup.</li>
</ol>
<p><img src="_page_113_Picture_0.jpeg" alt=""></p>
<ul>
<li><ol>
<li>Add the code below to the RecordRenderGraph function:<ul>
<li>Get a resourceData instance, this is used to get a texture descriptor from the active color texture after post-processing.</li>
<li>Change the name and request a new texture. Render Graph will allocate it when needed.</li>
<li>The first blit copies the current color buffer to an intermediary texture so it can be used as an input to the next pass. A pass is created using AddRasterRenderPass. In the first pass you set the source of the passData instance to the activeColorTexture of the resourceData instance.</li>
<li>Set the builder input texture using the method UseTexture and the output using SetRenderAttachment.</li>
<li>Finally, set the render function that the builder uses. It uses a function, ExecuteCopyColorPass, which is created in the steps below.</li>
<li>The second blit uses a material when copying. It is similar to the first blit except it assigns a material to the passData instance and uses the function ExecuteMainPass in the SetRenderFunc assignment.</li>
</ul>
</li>
</ol>
</li>
</ul>
<pre><code>public override void RecordRenderGraph(RenderGraph renderGraph, ContextContainer frameData)
{
 UniversalResourceData resourceData = frameData.Get&lt;UniversalResourceData&gt;()<span class="hljs-comment">;</span>
 var colCopyDesc =
 renderGraph.GetTextureDesc(resourceData.afterPostProcessColor)<span class="hljs-comment">;</span>
 colCopyDesc.name = <span class="hljs-string">"_TempColorCopy"</span><span class="hljs-comment">;</span>
 TextureHandle copiedColorTexture = renderGraph.CreateTexture(colCopyDesc)<span class="hljs-comment">;</span>
 using (var <span class="hljs-keyword">builder </span>= renderGraph.<span class="hljs-keyword">AddRasterRenderPass&lt;PassData&gt;(m_PassName </span>+
 <span class="hljs-string">"_CopyPass"</span>, out var passData, m_Sampler))
 {
 passData.source = resourceData.activeColorTexture<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.UseTexture(resourceData.activeColorTexture, </span>AccessFlags.Read)<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.SetRenderAttachment(copiedColorTexture, </span><span class="hljs-number">0</span>, AccessFlags.Write)<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.SetRenderFunc(
</span> (PassData data, RasterGraphContext rgContext) =&gt;
 {
 ExecuteCopyColorPass(rgContext.cmd, data.source)<span class="hljs-comment">;</span>
 })<span class="hljs-comment">;</span>
 }
 using (var <span class="hljs-keyword">builder </span>= renderGraph.<span class="hljs-keyword">AddRasterRenderPass&lt;PassData&gt;(m_PassName </span>+ 
 <span class="hljs-string">"_FullScreenPass"</span>, out var passData, m_Sampler))
 {
 passData.source = resourceData.activeColorTexture<span class="hljs-comment">;</span>
</code></pre><pre><code> passData.material = m_Material<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.UseTexture(copiedColorTexture, </span>AccessFlags.Read)<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.SetRenderAttachment(resourceData.activeColorTexture, </span><span class="hljs-number">0</span>,
 AccessFlags.Write)<span class="hljs-comment">;</span>
 <span class="hljs-keyword">builder.SetRenderFunc(
</span> (PassData data, RasterGraphContext rgContext) =&gt;
 {
 ExecuteMainPass(rgContext.cmd, data.material, data.source)<span class="hljs-comment">;</span>
 })<span class="hljs-comment">;</span>
 }
}
</code></pre><ol>
<li>You&#39;ll need to provide the ExecuteCopyColorPass. It simply uses the Blitter method BlitTexture. This function is provided with a variety of parameters. This example uses <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.core@17.0/api/UnityEngine.Rendering.Blitter.html#UnityEngine_Rendering_Blitter_BlitTexture_UnityEngine_Rendering_CommandBuffer_UnityEngine_Rendering_RTHandle_UnityEngine_Vector4_System_Single_System_Boolean_">this version.</a></li>
</ol>
<p><img src="_page_114_Picture_3.jpeg" alt=""></p>
<p>This function should be placed before the RecordRenderGraph function.</p>
<p><img src="_page_114_Figure_5.jpeg" alt=""></p>
<ol>
<li>Now you define the ExecuteMainPass function. You need to set the _BlitScaleBias uniform for user material with shaders replying on core Blit.hlsl to work.</li>
</ol>
<p><img src="_page_114_Picture_7.jpeg" alt=""></p>
<p><img src="_page_115_Picture_0.jpeg" alt=""></p>
<ul>
<li><ol>
<li>Rename CustomRenderPass to TintPass, and change m_ScriptablePass to m_pass.</li>
</ol>
</li>
<li><ol>
<li>Delete the existing code in the Create method. Create a new TintPass using the custom constructor. Define the renderPassEvent and configure the input.</li>
</ol>
</li>
</ul>
<p><img src="_page_115_Figure_4.jpeg" alt=""></p>
<p>These next steps complete this example of a Renderer Feature, which is designed to work with a Shader Graph shader. It&#39;s a simple example consisting of a <strong>TintColor</strong> property, a <strong>URP Sample Buffer</strong> node using the BlitSource and a <strong>Multiply</strong> node that modulates the existing BlitSource with the TintColor. Let&#39;s look at the steps below.</p>
<p><img src="_page_115_Picture_6.jpeg" alt=""></p>
<p>Tint Shader Graph</p>
<p><img src="_page_116_Picture_0.jpeg" alt=""></p>
<ol>
<li>To see the effect in action, select the <strong>Renderer Data</strong> object and click <strong>Add Renderer Feature</strong>. TintFeature will appear in the list.</li>
</ol>
<p><img src="_page_116_Figure_3.jpeg" alt=""></p>
<ul>
<li><ol>
<li>Create a material using the Tint Shader Graph.</li>
</ol>
</li>
<li><ol>
<li>Assign the Tint material to the Renderer Feature and set the materials color.</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>V Tint Renderer Feature (Tint Renderer Feature</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>TintRendererFeature</td>
<td></td>
</tr>
<tr>
<td>Script</td>
<td>TintFeature</td>
<td>0</td>
</tr>
<tr>
<td>Injection Point</td>
<td>After Rendering Onaques</td>
<td></td>
</tr>
<tr>
<td>Pass Material</td>
<td>C Tint</td>
<td></td>
</tr>
<tr>
<td>Regullrements</td>
<td>COLOL</td>
</tr>
</tbody>
</table>
<p><img src="_page_116_Picture_7.jpeg" alt=""></p>
<p>Effect of TintFeature: Unprocessed to the left, tinted on the right</p>
<p><img src="_page_117_Figure_1.jpeg" alt=""></p>
<p>Unity 6 comes with a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/render-graph-view.html#use-the-render-graph-viewer">Render Graph Viewer</a> window that you can open via <strong>Window &gt; Analysis &gt; Render Graph Viewer.</strong> This viewer allows you to study what is happening in the pipeline.</p>
<p>The Render Graph Viewer window</p>
<p>Notice that <strong>Draw Objects Pass</strong>, <strong>TintRendererFeature_CopyPass</strong>, and <strong>TintRendererFeature_ FullScreen Pass</strong> are all separate passes. It would be better to combine them into a single pass. But separate passes are necessary because of the way textures are used. If you click on the pass name, with the Pass List expanded, you&#39;ll see details about the pass. If you click on Draw Objects Pass you&#39;ll notice the message &quot;Failed to merge&quot;; this occurs because the next pass reads data output by this pass as a regular texture. TintRendererFeature_CopyPass has the same issue. Let&#39;s fix this.</p>
<p>You&#39;ll need a new material. The project includes a material in the Resources folder called <strong>FrameBufferFetch</strong>. This uses the shader of the same name (FrameBufferFetch) which has two passes. You&#39;re interested in the second pass that samples the current active frame buffer. Using this approach you&#39;ll need to adapt the Tint Shader Graph. Instead of using the URP Sample Buffer node, you&#39;re going to use a custom function node. It uses the HLSL in the <strong>FrameBufferFetch.hlsl</strong> file. Essentially it just uses the macro LOAD_FRAMEBUFFER_X_INPUT.</p>
<table>
<thead>
<tr>
<th>FrameBuffer Fetch</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Screen Position<br>FragFrameBufferFetch (Custom Function)<br>Out(4) ● === clipPos(2)<br>000 00 12 10 10</td>
<td></td>
</tr>
<tr>
<td>V<br>Mode Default<br>V</td>
<td>Vertex</td>
</tr>
<tr>
<td></td>
<td>Spacebar to Add Node</td>
</tr>
<tr>
<td>URP Sample Buffer</td>
<td>Fragment<br>Multiply</td>
</tr>
<tr>
<td>Default . O UV(4) Output(4) O<br>Source Di BillSource .<br>· TirtColorMI ·</td>
<td>. Base Color(3)<br>. A(3) . Out(3) .<br>0 803<br>X 1 · O Alphacti<br>V</td>
</tr>
<tr>
<td>&gt;</td>
</tr>
</tbody>
</table>
<p>The Tint Shader Graph using custom node FrameBufferFetch</p>
<p>Let&#39;s go back to the TintFeature. In the TintPass you need to add a new private static property.</p>
<h4 id="private-static-material-s-_framebufferfetchmaterial-">private static Material s_FrameBufferFetchMaterial;</h4>
<p>You can assign it in the custom constructor by using the Load method.</p>
<pre><code>s_FrameBufferFetchMaterial ??= UnityEngine.Resources.
<span class="hljs-keyword">Load</span>(<span class="hljs-string">"FrameBufferFetch"</span>) <span class="hljs-keyword">as</span> Material;
</code></pre><p>In the ExecuteCopyColorPass you need to remove the Blit and use a DrawProcedural instead. Using the identity matrix again, you&#39;ll use the material s_FrameBufferFetchMaterial for the second pass. The first pass is index 0 and the second pass is index 1. You&#39;re using topology triangles again, so you&#39;ll use indexCount 3 and instanceCount 1.</p>
<pre><code><span class="hljs-selector-tag">cmd</span><span class="hljs-selector-class">.DrawProcedural</span>(<span class="hljs-selector-tag">Matrix4x4</span><span class="hljs-selector-class">.identity</span>, <span class="hljs-selector-tag">s_FrameBufferFetchMaterial</span>, 1, 
<span class="hljs-selector-tag">MeshTopology</span><span class="hljs-selector-class">.Triangles</span>, 3, 1, <span class="hljs-selector-tag">null</span>);
</code></pre><p>Next you&#39;ll use the RecordRenderGraph method. For the first pass replace UseTexture with SetInputAttachment. This method uses FrameBufferFetch to access the previous pass.</p>
<p>builder.SetInputAttachment(resourceData.activeColorTexture, 0))</p>
<p>The same steps are down for the second pass.</p>
<p>builder.SetInputAttachment( copiedColorTexture, 0))</p>
<p>Look at the Render Graph Viewer and refresh if necessary. You will see that the three passes, Draw Objects Pass and the two TintRendererFeature passes, are combined into a single pass, which improves performance. In the Viewer window, the <strong>F</strong> means the input is accessed via FrameBufferFetch.</p>
<p><img src="_page_119_Figure_2.jpeg" alt=""></p>
<p>The three passes are merged</p>
<p>FramebufferFetch support is available on mobile platforms targeting Vulkan, Metal, and DirectX 12. On other platforms the engine falls back on texture sampling. Using FrameBufferFetch reduces bandwidth usage, which can improve performance if bandwidth bound, and generally reduce battery usage.</p>
<p>For more examples of using the render graph system, download the package samples via the Package Manager. Search for Universal RP, and click the Samples tab. URP RenderGraph Samples are available to import there.</p>
<p><img src="_page_119_Picture_6.jpeg" alt=""></p>
<p>Importing the URP RenderGraph Samples via the Universal RP package and Package Manager</p>
<p><img src="_page_120_Picture_1.jpeg" alt=""></p>
<p>In <a href="https://www.youtube.com/watch?v=3CpEn_mmr3o">this video tutorial,</a> we show you three practical exercises using Renderer Features: How to create a custom post-processing effect, stencil effect, and occlude characters by their environment.</p>
<h2 id="-span-id-page-121-1-span-span-id-page-121-0-span-post-processing"><span id="page-121-1"></span><span id="page-121-0"></span>Post-processing</h2>
<p>URP uses a <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/Volumes.html?">Volume</a> framework when adding post-processing effects. Unity 6 includes a <strong><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/Volumes.html#default-volumes">Default Volume</a></strong>. It can be found at <strong>Project Settings &gt; Graphics &gt; Volume.</strong> Any settings applied here affect the entire project but can be overridden by volumes added to a scene.</p>
<p><img src="_page_121_Picture_2.jpeg" alt=""></p>
<p>The Default Volume option</p>
<p><img src="_page_122_Picture_0.jpeg" alt=""></p>
<p>Another feature that&#39;s new to Unity 6 is a volume for the active URP Asset, which can also be overridden by volumes added to a scene.</p>
<p><img src="_page_122_Picture_3.jpeg" alt=""></p>
<p>URP Asset &gt; Volumes</p>
<p>When you add volumes to a scene, you can choose which post-processing effects apply to them. A volume can be Global or Local. If Global, the volume affects the Camera everywhere in the scene. With the Mode set to Local, volumes affect the Camera if it&#39;s within the bounds of the Collider.</p>
<p><img src="_page_122_Picture_6.jpeg" alt=""></p>
<p>Applying post-processing effects: The top-left image has no effects applied, the top-right image has Bloom applied, the bottom-left has Vignette applied, and the bottom-right has Color Adjustment added.</p>
<p><span id="page-123-0"></span><img src="_page_123_Picture_0.jpeg" alt=""></p>
<h2 id="using-the-urp-post-processing-framework">Using the URP post-processing framework</h2>
<ol>
<li>The first step is to make sure your Main Camera has post-processing enabled. Select the <strong>Main Camera</strong> in the <strong>Hierarchy</strong> window, go to the <strong>Inspector</strong>, and expand the <strong>Rendering</strong> panel. Check the <strong>Post Processing</strong> option.</li>
</ol>
<table>
<thead>
<tr>
<th>Rendering</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Renderer</td>
<td>Default Renderer (MansionLightingRenc ▼</td>
</tr>
<tr>
<td>Post Processing</td>
<td>&gt;</td>
</tr>
<tr>
<td>Anti-aliasing</td>
<td>No Anti-aliasing</td>
</tr>
<tr>
<td>Stop NaNs</td>
</tr>
</tbody>
</table>
<p><span id="page-123-1"></span>2. Right-click the <strong>Hierarchy</strong> window and select <strong>Create &gt; Volume &gt; Global Volume</strong> to create a Global Volume.</p>
<table>
<thead>
<tr>
<th>Volume</th>
<th>Global Volume</th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering</td>
<td>&gt;</td>
</tr>
<tr>
<td>Cinemachine</td>
<td>Box Volume<br>&gt;</td>
</tr>
<tr>
<td>Camera</td>
<td>Sphere Volume</td>
</tr>
<tr>
<td>Visual Effects</td>
<td>Convex Mesh Volume</td>
</tr>
</tbody>
</table>
<ol>
<li>With the Global Volume selected in the Hierarchy window, find the <strong>Volume</strong> panel in the Inspector and create a new <strong>Profile</strong> by clicking on <strong>New</strong>.</li>
</ol>
<table>
<thead>
<tr>
<th>V V Volume</th>
<th></th>
<th>0 主<br></th>
</tr>
</thead>
<tbody>
<tr>
<td>Mode</td>
<td>Global</td>
<td>D</td>
</tr>
<tr>
<td>Weight</td>
<td></td>
<td>0<br>1</td>
</tr>
<tr>
<td>Priority</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Profile</td>
<td>Global Volume Profile 1 0 New Clone</td>
</tr>
</tbody>
</table>
<ol>
<li>Start adding post-processing effects. See the table further down that lists available effects. Click <strong>Add Override</strong> and select <strong>Post-processing</strong>. In this example, the Bloom effect is chosen.</li>
</ol>
<table>
<thead>
<tr>
<th>Add Override</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td></td>
</tr>
<tr>
<td>Volume Overrides<br>Post-processing</td>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p><img src="_page_124_Picture_0.jpeg" alt=""></p>
<p><img src="_page_124_Picture_2.jpeg" alt=""></p>
<p>Selecting the Bloom effect</p>
<ol>
<li>Each effect has a dedicated Settings panel. The image here shows the settings for Bloom.</li>
</ol>
<table>
<thead>
<tr>
<th>▼ √ Bloom</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>ALL NONE</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Bloom</td>
<td></td>
<td></td>
</tr>
<tr>
<td>V Threshold</td>
<td>0.91</td>
<td></td>
</tr>
<tr>
<td>1<br>Intensity</td>
<td>2.88</td>
<td></td>
</tr>
<tr>
<td>Scatter<br>V</td>
<td></td>
<td>0.481</td>
</tr>
<tr>
<td>V<br>Tint</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Clamp</td>
<td>65472</td>
<td></td>
</tr>
<tr>
<td>High Quality Filtering</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Skip Iterations</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>Lens Dirt</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Dirt Texture</td>
<td>None (Texture)</td>
<td>C</td>
</tr>
<tr>
<td>Dirt Intensity</td>
<td>0</td>
</tr>
</tbody>
</table>
<ol>
<li>You can easily add multiple effects (such as Vignette in this example) and configure each one using their Settings panel.</li>
</ol>
<table>
<thead>
<tr>
<th>Q</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>C</td>
<td>Post-processing</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Color Curves</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Color Lookup</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Depth Of Field</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Film Grain</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lens Distortion</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lift, Gamma, Gain</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Motion Blur</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Panini Projection</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shadows, Midtones, Highlights</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Split Toning</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Tonemapping</td>
<td></td>
</tr>
<tr>
<td>Vignette</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>White Balance</td>
</tr>
</tbody>
</table>
<h2 id="-span-id-page-125-0-span-adding-a-local-volume-component"><span id="page-125-0"></span>Adding a Local Volume component</h2>
<p>With the Volume framework, you can configure the scene so that as a Camera moves around it, different post-processing profiles are triggered. This is achieved by adding a Local Volume component. Let&#39;s go through the steps for setting this up.</p>
<ol>
<li>In the <strong>Hierarchy</strong> window, right-click and choose <strong>Create &gt; Volume &gt; Box Volume</strong>. Alternatively, choose <strong>Sphere Volume</strong> if this shape is more suited to your purpose, or <strong>Convex Mesh Volume</strong> for a tighter control over the shape of the Collider component that defines the volume region.</li>
</ol>
<table>
<thead>
<tr>
<th>Volume</th>
<th>A</th>
<th>Global Volume</th>
</tr>
</thead>
<tbody>
<tr>
<td>Rendering</td>
<td>&gt;</td>
<td>Box Volume</td>
</tr>
<tr>
<td>Cinemachine</td>
<td>&gt;</td>
<td>Sphere Volume</td>
</tr>
<tr>
<td>Camera</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Visual Effects</td>
<td></td>
<td>Convex Mesh Volume</td>
</tr>
</tbody>
</table>
<ul>
<li><ol>
<li>From the <strong>Volume</strong> panel in the <strong>Inspector</strong>, create a new <strong>Profile</strong> to store this volume data. The panel can also be used to set:<ul>
<li>a. <strong>Blend Distance:</strong> This is the furthest distance from the Volume&#39;s Collider that URP starts blending from, and the distance in Collider dimensions where this profile fades in. At the edge of the Collider, the post-processing effects will fade out and the Blend Distance from the edge of the Collider will fully fade in.</li>
<li>b. <strong>Weight:</strong> Weight defines the maximum strength of the post-processing effects. If Weight is set to 1, then the effect will reach full strength. A setting of 0 means there is no effect, while 0.5 sets the strength of the effect at a maximum of 50%.</li>
<li>c. <strong>Priority:</strong> Use this value to determine which Volume URP is used when multiple Volumes have an equal amount of influence on the scene. The higher the number, the higher the Priority. If you are merging Global and Local, then keep Global at the default 0 setting and set the Local Volume(s) to 1 or more.</li>
</ul>
</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>V Volume</th>
<th>8 花</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mode</td>
<td>Local<br>V</td>
</tr>
<tr>
<td>Blend Distance</td>
<td>1</td>
</tr>
<tr>
<td>Weight</td>
<td>1</td>
</tr>
<tr>
<td>Priority</td>
<td>0</td>
</tr>
<tr>
<td>Profile</td>
<td>Box Volume Profile (Vol O New Clone</td>
</tr>
</tbody>
</table>
<p>Settings for a Local Volume</p>
<p><img src="_page_126_Picture_0.jpeg" alt=""></p>
<ol>
<li>Position the <strong>Volume</strong> and control its dimensions using the <strong>Box Collider</strong> component, as shown in the image below.</li>
</ol>
<p><img src="_page_126_Picture_3.jpeg" alt=""></p>
<p>Positioning and sizing a Box Volume using the attached Box Collider component</p>
<p>Post-processing can weigh heavily on your processor, so carefully consider the effects on low-end hardware and mobile devices. If your project must use it, then test on the target hardware. Some filters are less processor intensive than others. This <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/integration-with-post-processing.html#post-proc-how-too?">document</a> outlines the mobile-friendly effects.</p>
<p>These are the available post-processing effects in URP.</p>
<table>
<thead>
<tr>
<th>Effect</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bloom</td>
<td>Adds a glow around pixels above a defined brightness level</td>
</tr>
<tr>
<td>Channel Mixer</td>
<td>Modifies the influence of each input color channel on the overall mix</td>
</tr>
<tr>
<td>Creates fringes of color along boundaries that separate dark and<br>Chromatic Aberration<br>light parts of the image</td>
</tr>
</tbody>
</table>
<p><img src="_page_127_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Color Adjustments</th>
<th>Tweaks the overall tone, brightness, and contrast of the final<br>rendered image</th>
</tr>
</thead>
<tbody>
<tr>
<td>Color Curves</td>
<td>An advanced way to adjust specific ranges in hue, saturation, or<br>luminosity</td>
</tr>
<tr>
<td>Color Lookup</td>
<td>Maps the colors of each pixel to a new value using a Lookup Texture</td>
</tr>
<tr>
<td>Depth of Field</td>
<td>Simulates the focus properties of a camera lens</td>
</tr>
<tr>
<td>Film Grain</td>
<td>Simulates the random optical texture of photographic film</td>
</tr>
<tr>
<td>Lens Distortion</td>
<td>Distorts the final rendered picture to simulate the shape of a real<br>world camera lens</td>
</tr>
<tr>
<td>Lift Gamma Gain</td>
<td>Uses different trackballs to affect different ranges within the image;<br>adjust the slider under the trackball to offset the color lightness of<br>that range</td>
</tr>
<tr>
<td>Motion Blur</td>
<td>Simulates the blur that occurs in an image when a real-world<br>camera films objects moving faster than the camera&#39;s exposure time</td>
</tr>
<tr>
<td>Panini Projection</td>
<td>Helps you render perspective views in scenes with a very large field<br>of view</td>
</tr>
<tr>
<td>Screen Space Lens<br>Flare</td>
<td>Adds a lens flare that applies to the entire scene not just a single<br>light</td>
</tr>
<tr>
<td>Shadows Midtones<br>Highlights</td>
<td>Separately controls the shadows, midtones, and highlights of the<br>render</td>
</tr>
<tr>
<td>Split Toning</td>
<td>Adds different color tones to the shadows and highlights in your<br>scene</td>
</tr>
<tr>
<td>Tonemapping</td>
<td>Remaps the HDR values of an image to a new range of values</td>
</tr>
<tr>
<td>Vignette</td>
<td>Comprises darkening toward the edges of an image compared to<br>the center</td>
</tr>
<tr>
<td>White Balance</td>
<td>Removes unrealistic color casts, so items that would appear white in<br>real life render as white in your final image</td>
</tr>
</tbody>
</table>
<p><span id="page-128-0"></span><img src="_page_128_Picture_0.jpeg" alt=""></p>
<h4 id="-motion-blur-"><strong>Motion Blur</strong></h4>
<p><img src="_page_128_Picture_3.jpeg" alt=""></p>
<p>The top image shows Motion Blur off and the bottom image shows Motion Blur on.</p>
<p>The Motion Blur post-processing effect simulates the blur that occurs in an image when a realworld camera films objects moving faster than the camera&#39;s exposure time. This is usually due to rapidly moving objects, or a long exposure time.</p>
<p><span id="page-129-0"></span><img src="_page_129_Picture_0.jpeg" alt=""></p>
<h4 id="-using-motion-blur-"><strong>Using Motion Blur</strong></h4>
<p>As with all post-processing effects using URP, Motion Blur uses the Volume system, so to enable and modify Motion Blur properties, you must add a Motion Blur override to a Volume in your scene.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Description</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Select the motion blur technique.<br>Options:</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mode</td>
<td>—<br>Camera Only: Use only the motion of the camera to blur the objects.<br>This technique does not use the motion vectors and has better<br>performance than Camera and Objects.</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>—<br>Camera and Objects: Use the motion of both the camera and the<br>GameObjects. GameObject motion vectors overwrite the camera motion<br>vectors.</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Quality</td>
<td>Set the quality of the effect. Lower presets give better performance, but at a<br>lower visual quality.</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Intensity</td>
<td>Set the strength of the motion blur filter to a value from 0 to 1. Higher values<br>give a stronger blur effect, but can cause lower performance, depending on<br>the Clamp parameter.</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Clamp</td>
<td>Set the maximum length that the velocity resulting from camera rotation can<br>have. This limits the blur at high velocity, to avoid excessive performance<br>costs. The value is measured as a fraction of the screen&#39;s full resolution. The<br>value range is 0 to 0.2. The default value is 0.05.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="-troubleshooting-performance-issues-"><strong>Troubleshooting performance issues</strong></h4>
<p>To decrease the performance impact of Motion Blur, you can:</p>
<ul>
<li><strong>Reduce the Quality</strong>: A lower quality setting gives higher performance but may exhibit more visual artifacts.</li>
<li><strong>Change the Mode property from Camera and Objects to Camera Only:</strong> This technique has better performance than Camera and Objects.</li>
<li><strong>Decrease the Clamp:</strong> Do this to reduce the maximum velocity that Unity takes into account. Lower values give higher performance.</li>
</ul>
<p><span id="page-130-0"></span><img src="_page_130_Picture_0.jpeg" alt=""></p>
<h2 id="controlling-post-processing-with-code">Controlling post-processing with code</h2>
<p>You can also dynamically adjust your post-processing profile using a C# script. The following code example shows how to adjust the intensity of the Bloom effect. If a Vignette is applied, you can control the vignetting color via code. For example, if the player character takes damage, you can temporarily tint it red.</p>
<pre><code><span class="hljs-keyword">using</span> UnityEngine;
<span class="hljs-keyword">using</span> UnityEngine.Rendering;
<span class="hljs-keyword">using</span> UnityEngine.Rendering.Universal;
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">PPController</span> : <span class="hljs-title">MonoBehaviour</span>
{
      <span class="hljs-comment">// Start is called before the first frame update</span>
      <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Start</span>(<span class="hljs-params"></span>)
      </span>{
 Volume volume = GetComponent&lt;Volume&gt;();
 Bloom bloom;
 <span class="hljs-keyword">if</span> (volume.profile.TryGet&lt;Bloom&gt;(<span class="hljs-keyword">out</span> bloom))
 {
 bloom.intensity.<span class="hljs-keyword">value</span> = <span class="hljs-number">0</span>;
 }
 }
}
</code></pre><h2 id="-span-id-page-131-0-span-camera-stacking"><span id="page-131-0"></span>Camera Stacking</h2>
<p>A common requirement in games is the ability to combine geometry viewed from different cameras in a single render. The image below shows a shelf in the foreground acting as an inventory within the game. Collected items are added to the shelf and can be selected at key points by the player. Notice that it has a different field of view, as well as different lighting and post-processing. This has been set up using the <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/camera-stacking.html?">Camera Stacking</a> feature in URP.</p>
<p><img src="_page_131_Picture_2.jpeg" alt=""></p>
<p>An example of using Camera Stacking</p>
<p><img src="_page_132_Picture_0.jpeg" alt=""></p>
<p>Let&#39;s look at how to set this feature up.</p>
<ul>
<li><ol>
<li>Create a Camera by right-clicking the <strong>Hierarchy</strong> view and choosing <strong>Camera</strong>. Remove the audio listener component.</li>
</ol>
</li>
<li><ol>
<li>Use the <strong>Inspector &gt; Camera Settings</strong> panel to set this Camera as <strong>Render Type Overlay</strong>.</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>Camera</th>
<th></th>
<th></th>
<th></th>
<th>9<br>3</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Render Type</td>
<td></td>
<td>Overlay</td>
<td></td>
<td></td>
<td>œ</td>
</tr>
<tr>
<td>Projection<br>2</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Projection</td>
<td>Perspective</td>
<td></td>
<td></td>
<td></td>
<td>D</td>
</tr>
<tr>
<td>Field of View Axis</td>
<td>Vertical</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Field of View</td>
<td></td>
<td></td>
<td></td>
<td>55.1</td>
<td></td>
</tr>
<tr>
<td>Clipping Planes</td>
<td>Near</td>
<td>0.3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Far</td>
<td>1000</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Physical Camera</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>Create a new <strong>Layer</strong> for the Camera and the GameObjects it renders.</li>
</ol>
<table>
<thead>
<tr>
<th>User Layer 6</th>
<th>Highlight</th>
</tr>
</thead>
<tbody>
<tr>
<td>User Layer 7</td>
<td>SeeBehind</td>
</tr>
<tr>
<td>User Layer 8</td>
<td>Chandelier</td>
</tr>
<tr>
<td>User Layer 9</td>
<td>Overlay</td>
</tr>
</tbody>
</table>
<ol>
<li>Update the <strong>Rendering &gt; Culling Mask</strong> for the Camera using the Inspector.</li>
</ol>
<p><img src="_page_132_Picture_9.jpeg" alt=""></p>
<ol>
<li>Move the Camera to a suitable place in the scene, then add and position <strong>GameObjects</strong>  by placing them in <strong>Layer Overlay</strong>.</li>
</ol>
<p><img src="_page_132_Picture_11.jpeg" alt=""></p>
<p><span id="page-133-0"></span><img src="_page_133_Picture_0.jpeg" alt=""></p>
<ol>
<li>Make sure the <strong>Main Camera</strong> does not render Overlay by updating its <strong>Rendering &gt; Culling Mask</strong>.</li>
</ol>
<p><img src="_page_133_Picture_3.jpeg" alt=""></p>
<ol>
<li>In the <strong>Stack</strong> panel, use the &quot;<strong>+</strong>&quot; button to add the <strong>Overlay Camera</strong>.</li>
</ol>
<h3 id="controlling-a-stack-with-code">Controlling a stack with code</h3>
<p>As with post-processing, you can control the stack from code, and add or remove cameras dynamically during runtime. See this code example:</p>
<pre><code><span class="hljs-keyword">using</span> UnityEngine;
<span class="hljs-keyword">using</span> UnityEngine.Rendering.Universal;
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">StackController</span> : <span class="hljs-title">MonoBehaviour</span>
{
     <span class="hljs-keyword">public</span> Camera overlayCamera;
     <span class="hljs-comment">// Start is called before the first frame update</span>
     <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Start</span>(<span class="hljs-params"></span>)
     </span>{
 Camera camera = GetComponent&lt;Camera&gt;();
 <span class="hljs-keyword">var</span> cameraData = camera.<span class="hljs-function">GetUniversalAdditionalCamera
 <span class="hljs-title">Data</span>(<span class="hljs-params"></span>)</span>;
 cameraData.cameraStack.Remove(overlayCamera);
     }
}
</code></pre><p>Post-processing and Camera Stacking, both easily configured using URP, are powerful tools for creating rich, atmospheric effects in your games.</p>
<h2 id="-span-id-page-134-0-span-the-submitrenderrequest-api"><span id="page-134-0"></span>The SubmitRenderRequest API</h2>
<p>Sometimes you might want to render your game to a different destination than the user&#39;s screen. The <strong>SubmitRenderRequest</strong> API is designed with this purpose in mind. Let&#39;s look at a possible use case.</p>
<h3 id="coding-a-screengrab">Coding a screengrab</h3>
<p>The script below will render the game to an off-screen <strong>RenderTexture</strong> when the user presses the onscreen GUI. The script should be attached to the Main Camera. A <strong>RenderTexture</strong> is created in the <strong>Start</strong> callback. It is 1920 x 1080 pixels with a bit depth of 24. When the user presses the &quot;Render Request&quot; button, the RenderRequest method is called.</p>
<p>In the RenderRequest method, there&#39;s a reference to the Camera component. Create a <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Rendering.RenderPipeline.StandardRequest.html">RenderPipeline.StandardRequest</a> instance, then check whether the current pipeline supports the RenderRequest framework. If it does, you set the RenderTexture that was initialized in the Start callback as the destination of this request object and initialize the render using <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Rendering.RenderPipeline.SubmitRenderRequest.html">RenderPipeline.SubmitRenderRequest</a>. This method takes a camera instance and a request object.</p>
<p>At this point, Texture2D contains a render of the current scene. To save this to a file, you first need to convert the RenderTexture to a Texture2D instance. The method <strong>ToTexture2D</strong> shows one possible route. Once you have a Texture2D you can use the <strong>EncodeToPNG</strong> method of a Texture2D instance to get a byte array. You can then use the System.IO.File method <strong>WriteAllBytes</strong> to save the byte array to a file.</p>
<p><img src="_page_135_Picture_0.jpeg" alt=""></p>
<p>If you use the script directly, the screengrab will be saved in a newly created folder called <strong>RenderOutput</strong> in the <strong>Assets</strong> folder of your game. The file name is R_ followed by a randomly chosen integer between 0 and 100,000.</p>
<pre><code><span class="hljs-keyword">using</span> System.Collections;
<span class="hljs-keyword">using</span> System.Collections.Generic;
<span class="hljs-keyword">using</span> UnityEngine;
<span class="hljs-keyword">using</span> UnityEngine.Rendering;
[RequireComponent(<span class="hljs-keyword">typeof</span>(Camera))]
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">StandardRenderRequest</span> : <span class="hljs-title">MonoBehaviour</span>
{
 [SerializeField]
 RenderTexture texture2D;
 <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Start</span>(<span class="hljs-params"></span>)
 </span>{
 texture2D = <span class="hljs-keyword">new</span> RenderTexture(<span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>, <span class="hljs-number">24</span>);
 }
 <span class="hljs-comment">// When user clicks on GUI button,</span>
 <span class="hljs-comment">// Render Requests are sent with various output textures to render </span>
 <span class="hljs-function">given frame
 <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">OnGUI</span>(<span class="hljs-params"></span>)
 </span>{
 GUILayout.BeginVertical();
 <span class="hljs-keyword">if</span> (GUILayout.Button(<span class="hljs-string">"Render Request"</span>))
 {
 RenderRequest();
 }
 GUILayout.EndVertical();
 }
 <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">RenderRequest</span>(<span class="hljs-params"></span>)
 </span>{
 Camera cam = GetComponent&lt;Camera&gt;();
 RenderPipeline.StandardRequest request = <span class="hljs-keyword">new</span> RenderPipeline.StandardRequest();
 <span class="hljs-keyword">if</span> (RenderPipeline.SupportsRenderRequest(cam, request))
 {
 <span class="hljs-comment">// 2D Texture</span>
 request.destination = texture2D;
 RenderPipeline.SubmitRenderRequest(cam, request);
 SaveTexture(ToTexture2D(texture2D));
 }
 }
 <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">SaveTexture</span>(<span class="hljs-params">Texture2D texture</span>)
 </span>{
</code></pre><pre><code> byte[] bytes = texture.EncodeToPNG();
 <span class="hljs-built_in">var</span> dirPath = Application.dataPath + <span class="hljs-string">"/RenderOutput"</span>;
 <span class="hljs-keyword">if</span> (!System.IO.Directory.Exists(dirPath))
 {
 System.IO.Directory.CreateDirectory(dirPath);
 }
 System.IO.File.WriteAllBytes(dirPath + <span class="hljs-string">"/R_"</span> + Random.Range(<span class="hljs-number">0</span>, 
 <span class="hljs-number">100000</span>) + <span class="hljs-string">".png"</span>, bytes);
 Debug.Log(bytes.Length / <span class="hljs-number">1024</span> + <span class="hljs-string">"Kb was saved as: "</span> + dirPath);
 #<span class="hljs-keyword">if</span> UNITY_EDITOR
 UnityEditor.AssetDatabase.Refresh();
 #endif
 }
 Texture2D ToTexture2D(RenderTexture rTex)
 {
 Texture2D <span class="hljs-built_in">tex</span> = <span class="hljs-built_in">new</span> Texture2D(rTex.<span class="hljs-built_in">width</span>, rTex.<span class="hljs-built_in">height</span>, 
 TextureFormat.RGB24, <span class="hljs-literal">false</span>);
 RenderTexture.active = rTex;
 <span class="hljs-built_in">tex</span>.ReadPixels(<span class="hljs-built_in">new</span> Rect(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, rTex.<span class="hljs-built_in">width</span>, rTex.<span class="hljs-built_in">height</span>), <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);
 <span class="hljs-built_in">tex</span>.Apply();
 Destroy(<span class="hljs-built_in">tex</span>);//prevents memory leak
 <span class="hljs-built_in">return</span> <span class="hljs-built_in">tex</span>;
 }
</code></pre><p>}</p>
<h2 id="-span-id-page-137-1-span-span-id-page-137-0-span-additional-tools-compatible-with-urp"><span id="page-137-1"></span><span id="page-137-0"></span>Additional tools compatible with URP</h2>
<p>Another benefit of using URP is its compatibility with Unity&#39;s authoring tools that bring complex creation tasks into the reach of technical artists. This chapter provides an introduction to Shader Graph and VFX Graph.</p>
<h2 id="shader-graph">Shader Graph</h2>
<p><a href="https://docs.unity3d.com/Packages/com.unity.shadergraph@17.0/manual/Getting-Started.html?">Shader Graph</a> brings custom shaders to an artist&#39;s workflow. The Shader Graph tool is included when you start a project using the URP template or import the URP package.</p>
<p><img src="_page_138_Picture_0.jpeg" alt=""></p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p><img src="_page_138_Picture_3.jpeg" alt=""></p>
<p>You can find the Shader Graph node examples libraries in the Shader Graph package in the Package Manager window. Read about the new Shader Graph production ready shaders in Unity 6 in <a href="https://unity.com/blog/engine-platform/new-shader-graph-production-ready-shaders-in-
unity-6">this blog post</a>.</p>
<p><img src="_page_139_Picture_0.jpeg" alt=""></p>
<p>Covering Shader Graph warrants a separate guide, but let&#39;s go over some basic yet crucial steps by creating the Light Halo shader from the <a href="#page-32-0">Lighting chapter</a>.</p>
<ol>
<li>Right-click in the <strong>Project</strong> window, find a suitable folder, and choose <strong>Create &gt; Shader Graph &gt; URP &gt; Unlit Shader Graph</strong>. For this example, choose Unlit. Name the new asset FresnelAlpha.</li>
</ol>
<p><img src="_page_139_Picture_4.jpeg" alt=""></p>
<ol>
<li>Double-click the new <strong>Shader Graph Asset</strong> to launch the Shader Graph editor.</li>
</ol>
<table>
<thead>
<tr>
<th>Graph Inspector</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Node Settings</td>
<td>Graph Settings</td>
<td>4</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Precision</td>
<td>Single</td>
<td>D</td>
<td></td>
<td>Vertex</td>
<td></td>
</tr>
<tr>
<td>Target Settings</td>
<td></td>
<td></td>
<td>Object Space · · · Position(3)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Active Targets</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Universal</td>
<td></td>
<td></td>
<td>Object Space · · O Normal(3)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>+</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Y Universal</td>
<td></td>
<td></td>
<td>Object Space · · · · Tangent (3)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Material</td>
<td>Unlit</td>
<td>D</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Allow Material<br>Override</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Surface Type</td>
<td>Opaque</td>
<td></td>
<td></td>
<td>Fragment</td>
<td>Main Preview</td>
</tr>
<tr>
<td>Render Face</td>
<td>Front</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Depth Write</td>
<td>Auto</td>
<td></td>
<td></td>
<td>· O Base Color(3)</td>
<td></td>
</tr>
<tr>
<td>Depth Test</td>
<td>LEqual</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Alpha Clipping</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cast Shadows</td>
<td>V</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Supports LOD</td>
<td></td>
<td>A</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>If you&#39;re familiar with shaders, then you&#39;ll recognize the Vertex and Fragment nodes. By default, this shader will ensure any model with a material using it that it is correctly placed in the Camera view using the Vertex node, and that each pixel is set to a grey color using the Fragment node.</p>
<ol>
<li>This shader is going to set the alpha transparency of the object. It therefore needs to apply to the Transparent queue. Change the <strong>Graph Inspector &gt; Graph Settings &gt; Surface Type</strong> to <strong>Transparent</strong>. You&#39;ll see that the Fragment node now has an Alpha input as well as Base Color.</li>
</ol>
<p><img src="_page_140_Figure_1.jpeg" alt=""></p>
<ol>
<li>Add <a href="https://docs.unity3d.com/Packages/com.unity.shadergraph@17.0/manual/Blackboard.html?">properties to the shader</a>. For instance, add Color as a Color, and Power and Strength as Float values.</li>
</ol>
<table>
<thead>
<tr>
<th>FresnelAlpha<br>Shader Graphs</th>
<th>+</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>· Color</td>
<td>Color</td>
<td>Category</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Float</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Vector 2</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Vector 3</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Vector 4</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Color</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Gradient</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Texture 2D</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Texture 2D Array</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Texture 3D</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Cubemap</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Virtual Texture</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Matrix 2</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Matrix 3</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Matrix 4</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Sampler State</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Keyword</td>
<td>&gt;</td>
</tr>
</tbody>
</table>
<p><img src="_page_141_Picture_0.jpeg" alt=""></p>
<ol>
<li>Set the default values using <strong>Graph Inspector &gt; Node Settings &gt; Default</strong>. Set Color to white, Power to 4, and Strength to 1.</li>
</ol>
<table>
<thead>
<tr>
<th>Graph Inspector</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Node Settings Graph Settings</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Property: Power</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Name</td>
<td>Power</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reference</td>
<td>_Power</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Default</td>
<td>× 1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mode</td>
<td>Default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Precision</td>
<td>Inherit</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Exposed</td>
<td>&gt;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Override Property<br>Declaration</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>Shader Graph functions by joining nodes together. A node will have one or more inputs and an output. To add a node, right-click and choose <strong>Create Node</strong> in the <strong>Search</strong> panel at the top, then enter <strong>Fre</strong>. The results will show a <strong>Fresnel Effect</strong> node.</li>
</ol>
<table>
<thead>
<tr>
<th>Create Node<br>Q - Fresnel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Math<br>V Vector</td>
</tr>
<tr>
<td>Fresnel Effect</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>A node shows a preview of its effect. Notice that the Fresnel Effect is bright toward the edge. The value is the difference between the View direction and the Normal direction – and for a sphere, this is greatest at the edge.</li>
</ol>
<p>The alpha value should be lowest at the edge. You can flip the result using a One Minus node. To do this, click <strong>Create Node</strong> and enter <strong>One</strong>. Select the <strong>One Minus</strong> node. Now drag from Out(1) on the Fresnel Effect node to In(1) on the One Minus node. The 1 means that the value type is a single float. If it was 3, then it would be a vector with three components. The nodes should be joined like this:</p>
<p><img src="_page_142_Figure_2.jpeg" alt=""></p>
<ol>
<li>Let&#39;s look at how to control the size of gradient and the overall transparency. Use a <strong>Power</strong> node for sizing the gradient. Create a Power node and connect One Minus Out(1) to Power A(1). Drag the Power property to the graph and join it to Power B(1). The graph should now look like this:</li>
</ol>
<p><img src="_page_142_Figure_4.jpeg" alt=""></p>
<ol>
<li>Control the overall transparency using a <strong>Multiply</strong> node. Create it and connect Power Out(1) to Multiply A(1). Drag the Strength property to the graph and join it to Multiply B(1). Then join the Multiply Out(1) to Fragment Alpha(1) and drag the Color(4) property to the graph and join it to Fragment Base Color(3).</li>
</ol>
<p>Notice here that the property Color comprises a four-component vector, while Base Color is a three-component vector. Shader Graph will map the first three components of Color to the Base Color vector.</p>
<p><img src="_page_143_Picture_2.jpeg" alt=""></p>
<ol>
<li>Save the asset and create a new material. Assign this shader to the new material, which is located in <strong>Shader Graphs/FresnelAlpha</strong>.</li>
</ol>
<p><img src="_page_143_Picture_4.jpeg" alt=""></p>
<ol>
<li>Now you can apply the material to an object, controlling its visibility at the edges.</li>
</ol>
<p><img src="_page_143_Picture_6.jpeg" alt=""></p>
<p>A shader is applied to a sphere-shaped Point light to provide a halo effect around it.</p>
<p><span id="page-144-0"></span><img src="_page_144_Picture_0.jpeg" alt=""></p>
<h4 id="-fullscreen-shader-graph-"><strong>Fullscreen Shader Graph</strong></h4>
<p>The Fullscreen Shader Graph allows you to create custom post-processing passes. Right-click in the Project pane and select <strong>Create &gt; Shader Graph &gt; URP &gt; Fullscreen Shader Graph</strong>.</p>
<table>
<thead>
<tr>
<th>Shader Graph</th>
<th></th>
<th>Builtin</th>
<th>&gt;</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Shader</td>
<td>&gt;</td>
<td>URP</td>
<td>&gt;</td>
<td>Lit Shader Graph</td>
</tr>
<tr>
<td>Shader Variant Collection</td>
<td></td>
<td>Blank Shader Graph</td>
<td></td>
<td>Unlit Shader Graph</td>
</tr>
<tr>
<td>Testing</td>
<td></td>
<td>Sub Graph</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Playables</td>
<td></td>
<td>VFX Shader Graph</td>
<td></td>
<td>Sprite Custom Lit Shader Graph<br>Sprite Unlit Shader Graph</td>
</tr>
<tr>
<td>Assembly Definition</td>
<td></td>
<td></td>
<td></td>
<td>Sprite Lit Shader Graph</td>
</tr>
<tr>
<td>Assembly Definition Reference</td>
<td></td>
<td>Custom Render Texture</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Text</td>
<td>&gt;</td>
<td></td>
<td></td>
<td>Decal Shader Graph</td>
</tr>
<tr>
<td>TextMeshPro</td>
<td>&gt;</td>
<td></td>
<td></td>
<td>Fullscreen Shader Graph</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Creating a Fullscreen Shader Graph</p>
<p>You can access a pixel&#39;s color for the fragment shader using a URP Sample Buffer node that itself uses the BlitSource option. The graph below shows a simple tint example. The URP Sample Buffer also gives access to world normals and motion vectors that are useful for edge detection and motion trails.</p>
<table>
<thead>
<tr>
<th></th>
<th>Vertex</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Spacebar to Add Node</td>
</tr>
<tr>
<td>URP Sample Buffer</td>
<td></td>
</tr>
<tr>
<td>Defaul = · · O UV(4) Output(4) ®<br>Multiply</td>
<td>Fragment</td>
</tr>
<tr>
<td>Source Bi BiltSource ▼<br>@ A(4)<br>V</td>
<td>Base Color (3)<br>Out(4) 4</td>
</tr>
<tr>
<td>@ B(4)<br>· Color(4) @</td>
<td>× 1<br>· O Alpha(1)<br>V</td>
</tr>
</tbody>
</table>
<p>A simple tinting example</p>
<p>To use this example, you need a way to Blit the result of the current camera render texture using a material that uses this shader.</p>
<p><img src="_page_145_Picture_0.jpeg" alt=""></p>
<p>With the active Renderer Data asset selected, use the Inspector to add a Renderer Feature. Select <strong>Full Screen Pass Renderer Feature</strong>.</p>
<p><img src="_page_145_Picture_3.jpeg" alt=""></p>
<p>Adding the Full Screen Pass Renderer Feature</p>
<p>It just remains to update the settings for this Renderer Feature. Set the material you created that uses the Fullscreen Shader Graph, then select the position in the render pipeline.</p>
<table>
<thead>
<tr>
<th></th>
<th>&gt; Full Sereen Pass Renderer Feature (Full S</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>FullScreenPassRendererFeature</td>
<td></td>
</tr>
<tr>
<td>Pass Material</td>
<td>· FullScreen</td>
<td>O</td>
</tr>
<tr>
<td>Injection Point</td>
<td>Before Rendering Post Process .</td>
<td></td>
</tr>
<tr>
<td>Requirements</td>
<td>Color</td>
<td></td>
</tr>
<tr>
<td>Pass Index</td>
<td>DrawProcedural (0)</td>
</tr>
</tbody>
</table>
<p>The Renderer Feature settings</p>
<p>The image below shows the tint effect on the left. The Fullscreen Shader Graph is a useful way to create custom post-processing effects.</p>
<p><img src="_page_145_Picture_9.jpeg" alt=""></p>
<p>The tint effect</p>
<p><span id="page-146-0"></span><img src="_page_146_Picture_0.jpeg" alt=""></p>
<h4 id="-six-way-shader-graph-"><strong>Six Way Shader Graph</strong></h4>
<p><img src="_page_146_Picture_3.jpeg" alt=""></p>
<p>Here are four versions of the same smoke effect under different lighting conditions. From the top left: Directional light and ambient; top right, ambient, probe volumes and directional light; bottom left, ambient and probes, and bottom right, spot light and probes</p>
<p>The Six Way Shader Graph is a feature in Unity 6 that lets you dynamically relight smoke effects for more realism, using six-way lightmaps that can be baked in DCC tools like Houdini, Blender, or Embergen.</p>
<table>
<thead>
<tr>
<th>&gt;</th>
<th></th>
<th>&gt;</th>
<th>Lit Shader Graph</th>
</tr>
</thead>
<tbody>
<tr>
<td>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;</td>
<td>Blank Shader Graph<br>Builtin<br>Sub Graph<br>Custom Render Texture<br>Custom Heatmap Values</td>
<td>&gt;</td>
<td>Unlit Shader Graph<br>Sprite Custom Lit Shader Graph<br>Sprite Unlit Shader Graph<br>Sprite Lit Shader Graph<br>Decal Shader Graph</td>
</tr>
<tr>
<td>V</td>
<td></td>
<td></td>
<td>Canvas Shader Graph<br>Fullscreen Shader Graph<br>Six Way Shader Graph</td>
</tr>
<tr>
<td></td>
<td></td>
<td>URP</td>
</tr>
</tbody>
</table>
<p>Create a Six Way Shader Graph</p>
<p><span id="page-147-0"></span><img src="_page_147_Picture_0.jpeg" alt=""></p>
<p>To know more about six-way lighting see the blog post <a href="https://blog.unity.com/engine-platform/realistic-smoke-with-6-way-lighting-in-vfx-graph">Realistic smoke lighting with 6-way</a>  <a href="https://blog.unity.com/engine-platform/realistic-smoke-with-6-way-lighting-in-vfx-graph">lighting in VFX Graph</a>. And see this <a href="https://blog.unity.com/technology/custom-lighting-in-shader-graph-expanding-your-graphs-in-2019">blog post</a> that goes through the Shader Graph process with an example project and some advanced suggestions.</p>
<h2 id="vfx-graph">VFX Graph</h2>
<p>Almost any kind of visual effect is possible in Unity, whether you plan on your characters shooting fireballs from their fingertips or traveling through a wormhole. Visual effects (VFX) in a game enhance the atmosphere, help tell the story, and add details that can truly captivate your players.</p>
<p>Unity is pushing the boundaries of real-time graphics with tools such as the VFX Graph. This node-based editor enables technical and VFX artists to design dynamic visual effects – from simple common particle behaviors to complex simulations involving particles, lines, ribbons, trails, meshes, and more.</p>
<table>
<thead>
<tr>
<th>32<br>Manual<br>Bounds Setting Mode</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>V V</td>
</tr>
<tr>
<td>1.5</td>
<td></td>
</tr>
<tr>
<td>Set Velocity Random (Per-component)</td>
<td>V 2</td>
</tr>
<tr>
<td>1 x -0.1<br>y 0.4</td>
<td>z -0.1</td>
</tr>
<tr>
<td></td>
<td>z 0.1</td>
</tr>
<tr>
<td></td>
<td>V V</td>
</tr>
<tr>
<td></td>
<td>C × 0.1<br>y 1</td>
</tr>
</tbody>
</table>
<p>Editing a VFX Graph</p>
<p><img src="_page_148_Picture_0.jpeg" alt=""></p>
<p>To learn more about creating VFX with URP and the VFX Graph download the e-book <em><a href="https://unity.com/resources/definitive-guide-to-creating-visual-effects?isGated=false">The</a>  <a href="https://unity.com/resources/definitive-guide-to-creating-visual-effects?isGated=false">definitive guide to creating advanced visual effects in Unity</a>.</em></p>
<p><img src="_page_148_Picture_3.jpeg" alt=""></p>
<p>A smoke effect created using the VFX Graph</p>
<p><img src="_page_148_Picture_5.jpeg" alt=""></p>
<h2 id="-span-id-page-149-0-span-2d-renderer-and-2d-lights"><span id="page-149-0"></span>2D Renderer and 2D lights</h2>
<p>There&#39;s no limit to how innovative today&#39;s 2D games can be. The evolution of hardware, graphics, and game development software makes it possible to create 2D games with real-time lights, highresolution textures, and an almost unlimited sprite count.</p>
<p>If you are working on a 2D game, you&#39;ll be pleased to know there is a dedicated URP 2D Renderer. The simplest way to get started is to use the 2D URP template from the Unity Hub. This template ensures that your project has a URP 2D Renderer assigned via Project Settings &gt; Graphics &gt; Scriptable Render Pipeline Settings. All verified and precompiled 2D packages are installed with the 2D URP template and the default settings optimized for 2D projects. This also ensures that the project loads faster than installing all the packages manually.</p>
<table>
<thead>
<tr>
<th></th>
<th>New project<br>Editor Version: 6000.0.411 = Silicen C</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>11<br>All templates</td>
<td>Q Search all templates</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Core<br>D<br>2<br>Sample</td>
<td>Universal 20<br>Core</td>
<td></td>
<td>SRP</td>
</tr>
<tr>
<td>0<br>Learning</td>
<td>Universal 3D<br>200<br>Core</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>High Definition 3D<br>Coro</td>
<td>Universal 2D</td>
<td>This is an empty project configured for 2D<br>apps. It uses Unity&#39;s Universal Render<br>Pipeline pre-configured with 2D Renderer.</td>
</tr>
<tr>
<td></td>
<td>Universal 3D sample<br>్రవర్తి<br>Sample</td>
<td>Read more<br>ার<br>0<br>PROJECT SETTINGS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>High Definition 3D sample<br>్ట్రఫర్తిన<br>Sample</td>
<td>Project name<br>My project<br>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>Cancel<br>Create project</td>
</tr>
</tbody>
</table>
<p>The 2D URP template in the Unity Hub</p>
<p>If you&#39;re upgrading an existing project, then you need to find a suitable folder in your project&#39;s Assets folder. Right-click and select Create &gt; Rendering &gt; URP Asset (with 2D Renderer). Give it a name, and select it using Project Settings &gt; Graphics &gt; Scriptable Render Pipeline Settings. In the Scene view, be sure to select the 2D button when editing.</p>
<table>
<thead>
<tr>
<th>Create<br>&gt;<br>Reveal in Finder<br>Open</th>
<th></th>
<th>1941<br>Scene<br>Scene Template From Scene<br>Scene Template</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Delete<br>Rename<br>Copy Path</td>
<td>CRC</td>
<td>Volume Profile<br>Scene Template Pipeline<br>Prefab</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Open Scene Additive</td>
<td></td>
<td>Prefab Variant</td>
<td></td>
<td></td>
</tr>
<tr>
<td>View in Package Manager</td>
<td></td>
<td>Audio Mixer</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Import New Asset<br>Import Package</td>
<td></td>
<td>Rendering<br>Material</td>
<td>&gt;</td>
<td>URP Asset (with 2D Renderer)<br>URP Asset (with Universal Renderer)</td>
</tr>
</tbody>
</table>
<p>Creating a 2D Renderer and Settings Asset</p>
<p><img src="_page_150_Picture_0.jpeg" alt=""></p>
<p>The appearance of the &quot;classic&quot; magenta color that indicates a rendering error might occur if you&#39;re switching an existing project to the URP 2D Renderer.</p>
<p><img src="_page_150_Picture_3.jpeg" alt=""></p>
<p>Updating an existing project with URP 2D Renderer can result in rendering errors in your scene.</p>
<p>Fortunately, the <strong>Window &gt; Rendering &gt; Render Pipeline Converter</strong> has got you covered. Select <strong>Built-in to 2D (URP)</strong> and click the Material and Material Reference Upgrade panel. Then click Initialize Converters, followed by Convert Assets to be able to deselect some items or Initialize And Convert to handle the process with one click. If you still see magenta-colored sprites, you might need to manually replace the shader in some of your materials. Choose one of the shaders in the following table.</p>
<table>
<thead>
<tr>
<th>Shader</th>
<th>Description</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Sprite-Lit-Default</td>
<td>Uses 2D lights when rendering</td>
<td></td>
</tr>
<tr>
<td>Sprite-Mask-Default</td>
<td>Works with the stencil buffer</td>
<td></td>
</tr>
<tr>
<td>Sprite-Unlit-Default</td>
<td>Uses only the texture colors when rendering</td>
</tr>
</tbody>
</table>
<h4 id="-2d-shaders-available-in-urp-"><strong>2D shaders available in URP</strong></h4>
<p><img src="_page_151_Picture_1.jpeg" alt=""></p>
<p>Converting a Built-In Render Pipeline 2D project to URP 2D</p>
<p>2D lights are available with the URP 2D Renderer. These offer enhanced performance and flexibility. Using the new tools, you can create a more immersive experience and save time preparing different sprite variations by using baked lights to create new gameplay possibilities. If you have migrated an existing project, then you will have no URP 2D lights in your scene. If your sprites use the Sprite-Lit-Default shader, you might be surprised to see a lit render. But with no lights, you get a default Global Light assigned to the scene for an unlit appearance.</p>
<p><img src="_page_151_Picture_4.jpeg" alt=""></p>
<p>With no lights in the scene, the render defaults to Unlit.</p>
<h2 id="-span-id-page-152-0-span-2d-game-development-resources-from-unity"><span id="page-152-0"></span>2D game development resources from Unity</h2>
<p>The e-book, <em>2D game art, animation, and lighting for artists</em> is our biggest, most comprehensive 2D development guide, created for Unity developers and artists who want to make a commercial 2D game.</p>
<p><img src="_page_152_Picture_3.jpeg" alt=""></p>
<p><a href="https://unity.com/resources/2d-game-art-animation-lighting-for-artists-ebook?isGated=false">Download the Unity e-book</a> about 2D graphics, tools, and animation</p>
<p><img src="_page_152_Picture_5.jpeg" alt=""></p>
<p><img src="_page_153_Picture_0.jpeg" alt=""></p>
<p><em>Gem Hunter Match</em> shows you how a 2D puzzle/match-3 game can stand out from the competition with eye-catching lighting and visual effects created in URP. Among other techniques, you&#39;ll learn how to prepare and light 2D sprites to add depth, apply a Sprite Custom Lit shader for shimmer, and create glare and ripple effects.</p>
<ul>
<li>Download <em><a href="https://u3d.as/3fnH">Gem Hunter Match</a></em></li>
<li><a href="https://unity.com/blog/engine-platform/2d-puzzle-match-3-sample-gem-hunter-match">Get an introduction to</a> <em><a href="https://unity.com/blog/engine-platform/2d-puzzle-match-3-sample-gem-hunter-match">Gem Hunter Match</a></em></li>
</ul>
<h4 id="-happy-harvest-"><strong>Happy Harvest</strong></h4>
<p><img src="_page_153_Picture_6.jpeg" alt=""></p>
<p><em>Happy Harvest</em> shows developers how to harness the latest capabilities for creating 2D lights, shadows, and special effects with URP. It incorporates best practices any 2D creator can use, including not baking shadows into a sprite, keeping sprites flat, moving shadow and volume information to secondary textures, advanced Tilemap features, and much more.</p>
<ul>
<li>Download <em><a href="https://assetstore.unity.com/packages/essentials/tutorial-projects/happy-harvest-2d-sample-project-259218">Happy Harvest</a></em></li>
<li><a href="https://unity.com/blog/games/happy-harvest-demo-latest-2d-techniques">Get an introduction to</a> <em>Happy Harvest</em></li>
</ul>
<p><img src="_page_154_Picture_1.jpeg" alt=""></p>
<p>This 2D sample project is a vertical slice of a side scrolling Idle RPG game that showcases how the suite of 2D tools can be combined with artwork to make your vision a reality. All of the content in this demo can be added into your own creative projects.</p>
<ul>
<li>Download <em><a href="https://assetstore.unity.com/packages/essentials/tutorial-projects/dragon-crashers-urp-2d-sample-project-190721">UI Toolkit Dragon Crashers</a></em></li>
<li>Get an introduction to <em><a href="https://unity.com/blog/engine-platform/new-ui-toolkit-demos-for-programmers-artists">UI Toolkit Dragon Crasher</a></em>s</li>
</ul>
<h2 id="-span-id-page-155-0-span-more-unity-6-features-for-urp"><span id="page-155-0"></span>More Unity 6 features for URP</h2>
<p>This section highlights key features in URP in Unity 6 that can improve performance or fidelity on a wide variety of devices.</p>
<p><img src="_page_155_Picture_2.jpeg" alt=""></p>
<h3 id="spatial-temporal-post-processing-stp-">Spatial-Temporal Post-Processing (STP)</h3>
<p>The oasis environment from the URP 3D Sample rendered in three different ways: Render scale 1 at left, Render scale 0.25 in the middle, and Render scale 0.25 with STP enabled at right</p>
<p><img src="_page_156_Picture_0.jpeg" alt=""></p>
<p>The number of competing super resolution techniques is growing, and many of them are specific to a single hardware vendor. Along with this, these solutions are not designed for mobile.</p>
<p><a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/stp/stp-upscaler.html">Spatial-Temporal Post-Processing</a> (STP), is Unity&#39;s super resolution solution which works on all devices, from mobile to console, and delivers high quality results in URP while keeping overhead low. As you can see from the blended image above the results are high-quality. The left third shows the image with no STP and Render Scale 1. The middle third shows no STP and Render Scale 0.25, resulting in a blurry, low-fidelity image. The right third enables STP while keeping the Render Scale at 0.25, rendering 1/16 of the pixels yet with STP up scaling appearing sharp.</p>
<p>STP is a spatio-temporal anti-aliasing upscaling solution that should work on any device that supports shader model 5.0. It is designed with mobile in mind, aiming at delivering visual quality that&#39;s comparable to DLSS2, FSR2, or XeSS, with a lower performance cost.</p>
<p>Enable STP via the active URP Asset using <strong>Quality &gt; Upscaling Filter</strong>. Then set the Render Scale.</p>
<p><img src="_page_156_Picture_6.jpeg" alt=""></p>
<p>Enabling Spatial-Temporal Post-Processing</p>
<h3 id="-span-id-page-157-0-span-high-dynamic-range-display-output-for-pc-and-consoles"><span id="page-157-0"></span>High Dynamic Range display output for PC and consoles</h3>
<p><img src="_page_157_Picture_2.jpeg" alt=""></p>
<p>Rendering Debugger &gt; Lighting &gt; HDR Debug Mode &gt; Gamut View</p>
<p>High Dynamic Range (HDR) displays are display devices capable of reproducing images in the higher range of difference in luminance closer to natural lighting conditions. <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@17.0/manual/post-processing/hdr-output.html">HDR Output</a> allows for better preservation of the contrast and quality of the linear lighting renders and HDR images displayed on these devices.</p>
<p>You enable HDR in two places:</p>
<ol>
<li>The URP Asset</li>
</ol>
<table>
<thead>
<tr>
<th>Quality</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>HDR</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>HDR Precision 32 Bits</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>The Camera Inspector: Set <strong>Output &gt; HDR Rendering</strong> to <strong>Use settings from Render Pipeline Asset</strong>.</li>
</ol>
<p><span id="page-158-0"></span><img src="_page_158_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Output</th>
<th></th>
<th></th>
<th>(2)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Output Texture</td>
<td>None (Render Texture)</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Target Display</td>
<td>Display 1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Target Eye</td>
<td>Both</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Viewport Rect</td>
<td>X 0</td>
<td>Y<br>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>W1</td>
<td>H 1</td>
<td></td>
</tr>
<tr>
<td>HDR Rendering</td>
<td>Use settings from Render Pipeli .</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MSAA</td>
<td>Use settings from Render Pipell ▼</td>
<td></td>
</tr>
</tbody>
</table>
<p>With HDR you can turn on the option to take advantage of better quality image render outputs from URP on HDR displays. As a result, you can present final images with colors and contrasts that mimic natural lighting conditions better on these devices.</p>
<p>In addition to the existing desktop and console support that became available in Unity 2022, mobile support is introduced in Unity 6 for the following platforms:</p>
<ul>
<li>iOS players (iOS 16+, iPadOS 16+)</li>
<li>Android players using Vulkan and GLES (Android 9+, depending on device capabilities)</li>
</ul>
<p>Some common mobile devices that provide HDR display support include iPhone X and newer, Samsung Galaxy S10 and newer, Galaxy Note 10 and newer, and Galaxy Tab S6 and newer.</p>
<h3 id="using-a-pipeline-state-object">Using a Pipeline State Object</h3>
<p>Unity 6 introduces a new and powerful <a href="https://discussions.unity.com/t/graphicsstatecollection-tracing-and-warmup-in-unity-6/951031">Pipeline State Object (PSO)</a> tracing and precooking workflow, unlocking a smoother and stutter-less player experience, when targeting modern platforms.</p>
<p>This set of APIs provides a significant upgrade from the &quot;shader warmup&quot; API, previously introduced in older Unity versions. While traditional shader warmup is sufficient for older graphics APIs (e.g. OpenGL, DirectX11), the new PSO workflow allows developers to better utilize modern graphics APIs, such as Vulkan, DirectX12 and Metal.</p>
<h4 id="-pso-creation-and-caching-"><strong>PSO creation and caching</strong></h4>
<p>When targeting modern graphics APIs, the GPU vendor&#39;s graphics drivers will perform runtime shader compilation (and other rendering state translation) as part of the PSO creation process. As a result, PSO creation is a lengthy process, which may lead to noticeable stutters in the runtime application. This overhead can be exacerbated for more complex projects, which require the application to compile a large amount of PSOs on the fly.</p>
<p>You can identify PSO creation stutters in the Unity Profiler, using the GraphicsPipelineImpl markers:</p>
<p><img src="_page_159_Figure_0.jpeg" alt=""></p>
<p>Profiling PSO creation</p>
<p>| <a href="#page-137-0">Additional tools compatible with URP</a> | <a href="#page-155-0">More Unity 6 features for URP</a> | <a href="#page-162-0">Performance</a> |</p>
<p>In many cases, the GPU vendor&#39;s graphics drivers will automatically cache any compiled PSO to disk, in order to accelerate PSO creation for subsequent application runs. However, the application may still need to compile PSOs for newly encountered shader variants and materials. Furthermore, OS and driver updates will often invalidate the driver-managed PSO cache.</p>
<p>The ideal way to warm PSOs may vary depending on your application and use case. For example, you may choose to synchronously precook PSOs during level transitions and scene loading. This can be done progressively (time-sliced) in order to increase application responsiveness, creating a fixed amount of PSOs per frame.</p>
<p>Alternatively, you can choose to asynchronously precook PSOs in the application&#39;s background. This will not block the application, but may temporarily regress CPU performance for the duration of the warm up.</p>
<p><span id="page-160-0"></span><img src="_page_160_Picture_0.jpeg" alt=""></p>
<h4 id="-tracing-a-new-pso-collection-"><strong>Tracing a new PSO collection</strong></h4>
<p>You should begin by tracing the PSOs created by the application during rendering:</p>
<ul>
<li><ol>
<li>In a C# script, create a new <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.html">GraphicsStateCollection.</a> This collection corresponds to your application&#39;s or scene&#39;s PSOs.</li>
</ol>
</li>
<li><ol>
<li>To begin tracing PSOs into your collection, call the <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.BeginTrace.html">GraphicsStateCollection.BeginTrace</a> method. Any new graphics pipelines created by the application will be added to the collection. In most cases, you should begin tracing during scene or application start up.</li>
</ol>
</li>
<li><ol>
<li>To finalize the tracing process, call the <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.EndTrace.html">GraphicsStateCollection.EndTrace</a> method. In most cases, you should end tracing during scene or application end.</li>
</ol>
</li>
</ul>
<p>Once tracing is complete, you can save the PSO collection to disk, using <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.SaveToFile.html">GraphicsStateCollection.SaveToFile</a>.</p>
<p>For additional control, you can inspect the recorded PSOs and variant data, and modify the collection as needed. <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.GetVariants.html">GraphicsStateCollection.GetVariants</a> can be used to retrieve all shader variants recorded in a PSO collection. You can then read the graphics states used by each variant via <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.GetGraphicsStatesForVariant.html">GraphicsStateCollection.GetGraphicsStatesForVariant</a>. Lastly, you can modify the graphics states associated with each variant using <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.AddGraphicsStateForVariant.html">AddGraphicsStateForVariant</a> / <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.RemoveGraphicsStatesForVariant.html">RemoveGraphicsStatesForVariant</a>.</p>
<h4 id="-note-"><strong>Note:</strong></h4>
<p>GPU representation of the PSO may vary across platforms. It is highly recommended to perform tracing in the Player, targeting the relevant graphics API, and to maintain separate collections per target.</p>
<p>When tracing on a target device using Player Connection, you can send the PSO collection to the Editor and save to disk, via <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.SendToEditor.html">GraphicsStateCollection.SendToEditor.</a> You can also query the platform used when tracing the PSO collection via <a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection-runtimePlatform.html">GraphicsStateCollection.runtimePlatform</a>.</p>
<h4 id="-precooking-a-pso-collection-"><strong>Precooking a PSO collection</strong></h4>
<p>Once tracing is completed, you can request Unity to precook PSO collection, ideally well ahead of drawing time. In most cases, the ideal time to perform warmup is during application or scene loading sequences.</p>
<p>You can perform PSO precooking using two warm up methods:</p>
<ul>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.WarmUp.html">GraphicsStateCollection.WarmUp</a> will schedule the creation of all PSOs in the collection.</li>
<li><a href="https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Experimental.Rendering.GraphicsStateCollection.WarmUpProgressively.html">GraphicsStateCollection.WarmUpProgressively</a> will schedule the creation of a set number of PSOs in the collection.</li>
</ul>
<p><span id="page-161-0"></span><img src="_page_161_Picture_0.jpeg" alt=""></p>
<p>Both methods will return a job handle, which can be used to determine whether PSO Warmup is performed synchronously or asynchronously.</p>
<p>Once the PSOs are created, the drivers will often cache those to disk. Next time the PSOs are precooked, they could be loaded directly from cache.</p>
<h4 id="-platform-support-"><strong>Platform support</strong></h4>
<p>The new PSO workflow is available as of Unity 6, for Players targeting Metal, Vulkan, and Direct3D 12. In coming versions, we will also provide compatibility for older graphics APIs such as OpenGLES and Direct3D 11, in the form of an implicit shader-warmup fallback.</p>
<h2 id="-span-id-page-162-0-span-performance"><span id="page-162-0"></span>Performance</h2>
<p><img src="_page_162_Picture_3.jpeg" alt=""></p>
<p>Get tips for using Unity&#39;s profiling tools, programming and code architecture, project configuration and assets, and more. Learn how to enhance your mobile game&#39;s performance. <a href="https://unity.com/resources/mobile-xr-web-game-performance-optimization-unity-6">Download</a></p>
<p><img src="_page_162_Picture_7.jpeg" alt=""></p>
<p>Pick up great tips for extensive profiling of your console and PC projects, programming code and architecture, optimizing assets and graphics, UI, physics, and animation optimizations. <a href="https://unity.com/resources/console-pc-game-performance-optimization-unity-6">Download</a></p>
<p><img src="_page_163_Picture_0.jpeg" alt=""></p>
<p>Performance is highly dependent on the project you&#39;re working on. Always <a href="https://docs.unity3d.com/Manual/Profiler.html?">profile</a> and test your game throughout the development cycle. Open the Profiler via <strong>Window &gt; Analysis &gt; Profiler</strong>, and follow the suggestions in this chapter.</p>
<p><img src="_page_163_Figure_2.jpeg" alt=""></p>
<p>The Profiler window</p>
<p>This section looks at seven ways to improve the performance of your games:</p>
<ul>
<li>Managing your lighting</li>
<li>Light probes</li>
<li>Reflection probes</li>
<li>Camera settings</li>
<li>Pipeline settings</li>
<li>Frame Debugger</li>
<li>Profiler</li>
</ul>
<p>These optimizations are also covered in this <a href="https://youtu.be/NFBr21V0zvU">tutorial</a>.</p>
<p>And see the following video tutorials for profiling tips:</p>
<p><img src="_page_163_Picture_14.jpeg" alt=""></p>
<h2 id="-span-id-page-164-0-span-optimizing-lighting-and-rendering-in-urp"><span id="page-164-0"></span>Optimizing lighting and rendering in URP</h2>
<p>URP is built with optimized real-time lighting in mind. The URP Forward Renderer supports up to eight real-time lights per object and up to 256 real-time lights per camera for desktop games, plus 32 real-time lights per camera for mobile and untethered hardware. URP also allows for configurable per-object Light settings inside the Pipeline Asset for refined control over lighting.</p>
<p>As explained in th<a href="#page-32-0">e Lighting chapter,</a> baked lighting is one of the best ways to improve the performance of your scene. Real-time lighting can be expensive, whereas baking lights can help you gain back performance, assuming the lights in your scene are static. The baked lighting textures are batched into a single draw call, without needing to be continuously calculated. This is especially useful if your scene uses multiple lights. Another great reason to bake your lighting is that it allows you to render bounced or indirect lighting in your scene and improve the visual quality of the render.</p>
<p>Global Illumination is similarly covered in the Lighting section. This process simulates rays of light bouncing around the environment and illuminating other nearby objects with the bounced light. The figure below shows three lighting setups for the same scene: with no baked light data, with baked lighting, and with post-processing applied.</p>
<p><img src="_page_165_Picture_1.jpeg" alt=""></p>
<p>From left to right: no lighting data, baked lighting, post-processing added</p>
<p>When baked, areas of shadow in a scene receive the bounced light and are illuminated. It can be subtle, but this technique spreads the light around a scene more realistically and improves its overall appearance.</p>
<p>In the previous image, you can see that the specular highlights on the ground are lost when baking. Baked lights only contain diffuse lighting. Whenever possible, compute the direct lighting contribution from real-time, and have Global Illumination come from Image Based Lighting (IBL)/shadow maps/Probes.</p>
<p><img src="_page_165_Picture_5.jpeg" alt=""></p>
<p>The effect of light baking on shadows: before baking on the left, and after baking on the right</p>
<p>Use the lowest possible <strong>Lightmap Resolution</strong> and <strong>Lightmap Size</strong> when baking your lights; Go to <strong>Window &gt; Rendering &gt; Lighting &gt; Scene</strong>. This helps to lower the texture memory requirement.</p>
<table>
<thead>
<tr>
<th>Lightmap Resolution</th>
<th>10</th>
<th>texels per unit</th>
</tr>
</thead>
<tbody>
<tr>
<td>Lightmap Padding</td>
<td>2</td>
<td>texels</td>
</tr>
<tr>
<td>Max Lightmap Size</td>
<td>512</td>
</tr>
</tbody>
</table>
<p>Setting the Lightmap Resolution and Max Lightmap Size</p>
<p><span id="page-166-0"></span><img src="_page_166_Picture_0.jpeg" alt=""></p>
<h2 id="light-probes">Light probes</h2>
<p>As explained in the <a href="#page-32-0">Lighting section,</a> light probes sample the lighting data in the scene during baking and allow the bounced light information to be used by dynamic objects as they move or change. This helps them blend into and feel more natural in the baked lighting environment. (The Unity engine now has an alternative to Light Probes, see the <a href="#page-61-0">APV section</a>).</p>
<p>Light probes add naturalism to a render without increasing the processing time for a rendered frame. This makes them suitable for all hardware, even low-end mobile devices.</p>
<p><img src="_page_166_Picture_5.jpeg" alt=""></p>
<p>The effect of using light probes when rendering a dynamic object: with light probe on the left, and without on the right</p>
<h3 id="reflection-probes">Reflection probes</h3>
<p>You can also use reflection probes to optimize your scene. Reflection probes project parts of the environment onto nearby geometry to create more realistic reflections. By default, Unity uses the Skybox as the reflection map. But by using one or more reflection probes, the reflections will match their surroundings more closely.</p>
<p><img src="_page_166_Picture_9.jpeg" alt=""></p>
<p>The effect of using reflection probes on smooth surfaces: with reflection probes on the left and without on the right</p>
<p>The size of the cubemap generated when baking the reflection probes depends on how close the camera gets to a reflective object. Always make sure to use the smallest map size that suits your needs to optimize your scene.</p>
<p><span id="page-167-0"></span></p>
<table>
<thead>
<tr>
<th>Box Size</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Box Offset</td>
<td>16</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cubemap Capture Setting</td>
<td>32</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Resolution</td>
<td>64</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDR</td>
<td>V 128</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadow Distance</td>
<td></td>
<td>266</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Clear Flags</td>
<td></td>
<td>512</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Background</td>
<td></td>
<td>1024</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Culling Mask</td>
<td></td>
<td>2048</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Use Occlusion Culling</td>
<td>V</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Clipping Planes</td>
<td>Near</td>
<td>03</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Far</td>
<td>1000</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Adjusting the size of the reflection probe cubemap</p>
<h3 id="camera-settings">Camera settings</h3>
<p>The URP enables you to disable unwanted renderer processes on your cameras for performance optimization. This is useful if you&#39;re targeting both high- and low-end devices in your project. Disabling expensive processes, such as post-processing, shadow rendering, or depth texture can reduce visual fidelity but improve performance on low-end devices.</p>
<h2 id="occlusion-culling">Occlusion culling</h2>
<p>Another great way to optimize your Camera is with <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/OcclusionCulling.html?">occlusion culling.</a> By default, the Camera in Unity will always draw everything in the Camera&#39;s frustum, including geometry that might be hidden behind walls or other objects. There&#39;s no point in drawing geometry that the player can&#39;t see, and that takes up precious milliseconds. This is where occlusion culling comes in.</p>
<p>Occlusion culling is best suited to a scene where significant numbers of objects might be masked when another item appears between them and the Camera. A cellular corridor mazetype game is an ideal candidate for using occlusion culling, as seen in the images below.</p>
<p><img src="_page_167_Picture_8.jpeg" alt=""></p>
<p>Frustum culling in the image on left, and occlusion culling in the image on right</p>
<p>By baking occlusion data, Unity ignores the parts of your scene that are blocked. Reducing the geometry being drawn per frame provides a significant performance boost.</p>
<p>To enable occlusion culling in your scene, mark any geometry as either <strong>Occluder Static</strong> or <strong>Occludee Static</strong>. Occluders are medium to large objects that can occlude objects marked as Occludees. To be an Occulder, an object must be opaque, have a Terrain or Mesh Renderer component, and not move at runtime. Occludees can be any object with a Renderer component, including small and transparent objects that similarly do not move at runtime.</p>
<p><img src="_page_168_Picture_3.jpeg" alt=""></p>
<p>You set the static properties using the usual drop-down.</p>
<p>Settings for an object included in occlusion data</p>
<p>Open <strong>Window &gt; Rendering &gt; Occlusion Culling</strong>, and select the <strong>Bake</strong> tab. In the bottom-right corner of the <strong>Inspector</strong>, press <strong>Bake</strong>. Unity generates occlusion data, saving the data as an asset in your project and linking the asset to the current scene.</p>
<table>
<thead>
<tr>
<th></th>
<th>Object</th>
<th>Bake</th>
<th>Visualization</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Set default parameters</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>The default parameters guarantee that any given scene computes fast and the<br>occlusion culling results are good. As the parameters are always scene specific,<br>better results will be achieved when fine tuning the parameters on a scene to scene<br>basis. All the parameters are dependent on the unit scale of the scene and it is<br>imperative that the unit scale parameter is set correctly before setting the default<br>values.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Smallest Occluder</td>
<td>5</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Smallest Hole</td>
<td></td>
<td>0.25</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Backface Threshold</td>
<td></td>
<td></td>
<td>100</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Occlusion culling Bake tab</p>
<p>You can see occlusion culling in action using the <strong>Visualization</strong> tab. Select the <strong>Camera</strong> in the scene and use the <strong>Occlusion Culling</strong> pop-up window in the <strong>Scene</strong> view to configure the visualization. The pop-up might be hidden behind the small Camera view window. Right-click the double-line icon and choose <strong>Collapse</strong> if this is the case. Move the pop-up, then restore the Camera view using right-click expand.</p>
<p><span id="page-169-0"></span><img src="_page_169_Picture_1.jpeg" alt=""></p>
<p>Visualization tab and Occlusion Culling pop-up</p>
<p><img src="_page_169_Figure_3.jpeg" alt=""></p>
<p>As you move the Camera, you should see objects popping on and off.</p>
<p>The effect of occlusion culling off in the left image, and on in the right image</p>
<p>If you are using <a href="#page-30-0">GPU Resident Drawer</a> in Unity 6, then you can use GPU Occlusion Culling.</p>
<h2 id="pipeline-settings">Pipeline settings</h2>
<p>While the effects of changing the settings for the URP Asset and using different Quality tiers were <a href="#page-21-0">previously covered</a>, here are some additional tips for experimenting with Quality tiers to get the best results for your project:</p>
<ul>
<li>Reduce Shadow Resolution and distance for performance gains.</li>
<li>Disable features that your project does not require, such as depth texture and opaque texture.</li>
<li>Enable the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/SRPBatcher.html?">SRP Batcher</a> to use the new batching method. The SRP Batcher will automatically batch together meshes that use the same shader variant, thereby reducing draw calls. If you have numerous dynamic objects in your scene, this can be a useful way to gain performance. If the SRP Batcher checkbox is not visible, then click the three vertical dots icon (<strong>⁝</strong>) and select <strong>Show Additional Properties</strong>.</li>
</ul>
<p><span id="page-170-0"></span><img src="_page_170_Picture_0.jpeg" alt=""></p>
<p><img src="_page_170_Picture_2.jpeg" alt=""></p>
<p>Enabling additional properties for the URP Asset Inspector</p>
<h2 id="frame-debugger">Frame Debugger</h2>
<p>Use the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/FrameDebugger.html">Frame Debugger</a> to gain a better understanding of what&#39;s happening during rendering. To view additional information in the Frame Debugger window, adjust the <strong>Debug Level</strong> using the <strong>URP Asset</strong>. As with the SRP Batcher checkbox, this is only visible in the Inspector with <strong>Show Additional Properties</strong> enabled.</p>
<p><img src="_page_170_Picture_6.jpeg" alt=""></p>
<p>Setting the Debug Level</p>
<p>Adjusting the Debug Level can affect performance. Always turn it off when the Frame Debugger is not in use.</p>
<p>The Frame Debugger shows a list of all the draw calls made before rendering the final image and can help you pinpoint why certain frames are taking a long time to render. It can also identify why your scene&#39;s draw call count is so high.</p>
<p>Open the Frame Debugger by going to <strong>Window &gt; Analysis &gt; Frame Debugger</strong>. When your game is playing, select the <strong>Enable</strong> button. This will pause the game and let you examine the draw calls.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th>Console</th>
<th>Frame Debug</th>
<th></th>
<th>Profiler</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Disable</td>
<td></td>
<td></td>
<td>Editor</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MeshSkinning.GPUSkinning<br>V MeshSkinning.SkinOnGPU<br>ComputeSkinningDispatch<br>UniversalRenderPipeline.RenderSingleCame 42<br>&quot; ScriptableRenderer.Execute: MansionLigh 42<br>Clear (color+Z+stencil)<br>T MainLightShadow<br>Shadows DrawSRPBatcher<br>Clear (color+Z+stencil)<br>V Depth Normal Prepass<br>RenderLoop.DrawSRPBatcher<br>ColorGradingLUT<br>Draw Dynamic<br>T SSAO<br>Draw Mesh<br>Draw Mesh<br>Draw Mesh<br>Draw Mash<br>Clear (color+Z+stencil)<br>V DrawOpaqueObjects<br>RenderLoop.DrawSRPBatcher<br>SRP Batch<br>SRP Batch<br>SRP Batch<br>· DrawTransparentObjects</td>
<td></td>
<td>8<br>6<br>6<br>3<br>3<br>3<br>3<br>4</td>
<td>A<br>RenderTarget<br>RT 0<br>Channels All<br>2854x1340 B8G8R8A8_SRGB ()<br>Event #61: Draw Dynamic<br>Shader<br>Pass<br>Blend<br>ZClip<br>ZTest<br>ZWrite<br>Cull<br>Conservative</td>
<td></td>
<td><No name><br>ਜਿ<br>B<br>G<br>Levels @<br>A<br>Hidden/Universal Render Pipeline/Blit, SubShader #0<br>Bill<br>One Zero<br>True<br>Always<br>Off<br>Off<br>False</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>3<br>3</td>
<td>Preview<br>Textures<br>SourceTex<br>Matrices<br>unity_MatrixVP</td>
<td>ShaderProperties</td>
<td></td>
<td></td>
<td>C</td>
<td>3<br>2<br>0<br>0<br>0</td>
<td>0<br>2<br>0<br>0</td>
<td>CameraColorAttachmentB<br>0<br>0<br>0.0099<br>0</td>
<td>-1<br>0.99<br>1</td>
</tr>
</tbody>
</table>
<p>Frame Debugger detail</p>
<p><span id="page-171-0"></span><img src="_page_171_Picture_1.jpeg" alt=""></p>
<p>Clicking a stage in the render pipeline (left pane) will show a preview of this stage in <strong>Game</strong> view.</p>
<p>The Frame Debugger shows every step of the rendering process in the Game View – in this case, the SSAO generation step.</p>
<h2 id="unity-profiler">Unity Profiler</h2>
<p>Like the Frame Debugger, the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/Profiler.html">Profiler</a> is a great way to determine how long it takes to complete a frame cycle in your project. It provides an overview of rendering, memory, and scripting. You can identify scripts that take a long time to complete, helping you to pinpoint potential bottlenecks in your code.</p>
<p>Open the Profiler via <strong>Window &gt; Analysis &gt; Profiler</strong>. When in <strong>Play Mode</strong>, the window provides an overview of the overall performance of your game. You can also pause the live view and use the <strong>Hierarchy Mode</strong> to get a breakdown of the time taken to complete a single frame. The Profiler will show you each call Unity has made during the frame.</p>
<p>For an even more detailed analysis, use the <a href="https://docs.unity3d.com/6000.0/Documentation/Manual/LowLevelNativePluginProfiler.html?">low-level native plug-in Profiler API</a>. You can use this Profiler API to extend the Profiler, and profile the performance of native plug-in code, or to prepare profiling data to send to third-party profiling tools such as Razor for Sony Playstation, PIX for Microsoft (Windows and Xbox), as well as Chrome Tracing, ETW, ITT, VTune, or Telemetry.</p>
<p><img src="_page_172_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Project Console</th>
<th>Frame Debug @ Profiler</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Profiler Modules</td>
<td>· Play Mode · ( ) 14 ) Frame: 4471 / 4471 / 4471 Clear</td>
<td></td>
<td></td>
<td>Clear on Play Deep Profile Call Stacks ▼</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Chinese them<br>· Animation<br>GarbageCollector<br>VSync<br>· Global Illumination<br>UI<br>Others</td>
<td>1ms (1000FPS)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Timeline</td>
<td>· Live</td>
<td>0.0ms</td>
<td></td>
<td></td>
<td></td>
<td>CPU:65.26ms GPU .- ms</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>1.Orga</td>
<td>(1,5cps)</td>
<td>12.0ms</td>
<td>12.5ms</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Render Thread</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>ン</td>
</tr>
<tr>
<td>r Job</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Worker 0</td>
<td>1de (1.30mt)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Worker 1</td>
<td>100 (1.31mm)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>104 (1,31mm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>W</td>
</tr>
<tr>
<td>Worker 2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Loading</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The Profiler window using the low-level native plug-in Profiler API</p>
<p>Here&#39;s an example of using the low-level native plug-in Profiler API:</p>
<pre><code><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;IUnityInterface.h&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;IUnityProfiler.h&gt;</span></span>
<span class="hljs-keyword">static</span> IUnityProfiler* s_UnityProfiler = <span class="hljs-literal">NULL</span>;
<span class="hljs-keyword">static</span> <span class="hljs-keyword">const</span> UnityProfilerMarkerDesc* s_MyPluginMarker = <span class="hljs-literal">NULL</span>;
<span class="hljs-keyword">static</span> <span class="hljs-keyword">bool</span> s_IsDevelopmentBuild = <span class="hljs-literal">false</span>;
<span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">MyPluginWorkMethod</span><span class="hljs-params">()</span>
</span>{
      <span class="hljs-keyword">if</span> (s_IsDevelopmentBuild)
 s_UnityProfiler-&gt;BeginSample(s_MyPluginMarker);
      <span class="hljs-comment">// Code I want to see in Unity Profiler as "MyPluginMethod".</span>
      <span class="hljs-comment">// ...</span>
      <span class="hljs-keyword">if</span> (s_IsDevelopmentBuild)
 s_UnityProfiler-&gt;EndSample(s_MyPluginMarker);
}
<span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-keyword">void</span> UNITY_INTERFACE_EXPORT UNITY_INTERFACE_API <span class="hljs-title">UnityPluginLoad</span><span class="hljs-params">(IUnityInterfaces* 
unityInterfaces)</span>
</span>{
      s_UnityProfiler = unityInterfaces-&gt;Get&lt;IUnityProfiler&gt;();
      <span class="hljs-keyword">if</span> (s_UnityProfiler == <span class="hljs-literal">NULL</span>)
 <span class="hljs-keyword">return</span>;
</code></pre><pre><code>s_IsDevelopmentBuild = s_UnityProfiler-&gt;IsAvailable() != <span class="hljs-number">0</span>;
</code></pre><p><img src="_page_173_Picture_0.jpeg" alt=""></p>
<p>s_UnityProfiler-&gt;CreateMarker(&amp;s_MyPluginMarker, &quot;MyPluginMethod&quot;, kUnityProfilerCategoryOther, kUnityProfilerMarkerFlagDefault, 0); } extern &quot;C&quot; void UNITY_INTERFACE_EXPORT UNITY_INTERFACE_API UnityPluginUnload() { s_UnityProfiler = NULL; }</p>
<h4 id="-additional-resources-"><strong>Additional resources</strong></h4>
<p>If you&#39;re interested in building advanced profiling skills in Unity, start by downloading the free e-book <em><a href="https://unity.com/resources/ultimate-guide-to-profiling-unity-games?isGated=false">Ultimate guide to profiling Unity games</a>.</em> This guide brings together advanced advice and knowledge on how to profile an application in Unity, manage its memory, and optimize its power consumption from start to finish.</p>
<p>A couple of other useful resources include <a href="https://catlikecoding.com/unity/tutorials/basics/measuring-performance/">Measuring Performance</a> by Catlike Coding, and <a href="https://thegamedev.guru/unity-performance/draw-call-optimization/">Unity Draw Call Batching</a> by The Gamedev Guru.</p>
<h2 id="-span-id-page-174-0-span-the-urp-3d-sample"><span id="page-174-0"></span>The URP 3D sample</h2>
<p>The URP 3D sample is available in the Unity Hub and features four environments, each with its own art style, rendering path, and scene complexity, to represent the variety of 3D projects built with URP.</p>
<p>The <a href="https://unity.com/demos/urp-3d-sample">URP 3D sample</a> replaces the construction scene that will be familiar to many developers who have been using URP for a few years. The new sample project contains several miniscenes that illustrate the capabilities of URP.</p>
<p>Let&#39;s go through each scene.</p>
<h2 id="-span-id-page-175-0-span-the-garden"><span id="page-175-0"></span>The garden</h2>
<p>This scene illustrates how you can efficiently scale your content with URP to suit multiple platforms, from mobile and console to high-end gaming desktops. It features stylized PBR rendering, customizable vegetation, and rendering numerous lights with the new Forward+ renderer that surpasses previous light count limits.</p>
<p><img src="_page_175_Picture_4.jpeg" alt=""></p>
<h2 id="the-oasis">The oasis</h2>
<p>This is a photorealistic scene with highly detailed textures, VFX Graph effects, SpeedTree, and a custom water solution. It targets devices that support compute shaders.</p>
<p><img src="_page_175_Picture_7.jpeg" alt=""></p>
<p><span id="page-176-0"></span><img src="_page_176_Picture_0.jpeg" alt=""></p>
<h2 id="the-cockpit">The cockpit</h2>
<p><img src="_page_176_Picture_2.jpeg" alt=""></p>
<p>This scene uses custom lighting code with Shader Graph. It&#39;s designed for untethered VR devices such as Meta Quest 2.</p>
<h2 id="the-terminal">The terminal</h2>
<p><img src="_page_176_Picture_5.jpeg" alt=""></p>
<p>This scene is the link between the other sample scenes, providing a transition effect to move from one scene to the next.</p>
<p><span id="page-177-0"></span><img src="_page_177_Picture_0.jpeg" alt=""></p>
<h2 id="moving-between-the-scenes">Moving between the scenes</h2>
<p><img src="_page_177_Picture_2.jpeg" alt=""></p>
<p>The sample project uses a transition effect to move between scenes. The transition effect uses an off-screen render target to render the incoming scene before the transition is complete. The incoming scene is then rendered to large monitors placed in the outgoing scene using a custom shader created with Shader Graph, and the full-screen swap is handled using a stencil via a Render Objects Renderer Feature.</p>
<table>
<thead>
<tr>
<th>T &gt; Screen Stencil (Render Objects)</th>
<th></th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>ScreenStencil</td>
<td></td>
</tr>
<tr>
<td>Event</td>
<td>AfterRenderingOpaques</td>
<td>D</td>
</tr>
<tr>
<td>V Filters</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Queue</td>
<td>Opaque</td>
<td>D</td>
</tr>
<tr>
<td>Layer Mask</td>
<td>Screen, Occluder</td>
<td>A</td>
</tr>
<tr>
<td>LightMode Tags<br>4</td>
<td></td>
<td>0</td>
</tr>
<tr>
<td>V Overrides</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Override Mode</td>
<td>Material</td>
<td>œ</td>
</tr>
<tr>
<td>Material</td>
<td>StencillOnly</td>
<td>0</td>
</tr>
<tr>
<td>Pass Index</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Depth</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Stencil</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Value</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>Compare Function</td>
<td>Always</td>
<td>A</td>
</tr>
<tr>
<td>Pass</td>
<td>Replace</td>
<td>A</td>
</tr>
<tr>
<td>Fall</td>
<td>Кеер</td>
<td>D</td>
</tr>
<tr>
<td>Z Fail</td>
<td>Keep</td>
<td>A</td>
</tr>
<tr>
<td>Camera</td>
<td>( ( ( ( ( ( ( ) ( ( ( ( ) ( ( ( ) ( ( ( ( ) ( ( ( ) ( ( ( ) ( ( ( ) ( ( ( ) ( ( ( ) ( ( ( ) ( ( ( ( ) ( ( ( ( ) ( ( ( ) ( ( ( ( ) ( ( ( ( ) ( ( ( ) ( ( ( ( ) ( ( ( ) ( ( ( (</td>
</tr>
</tbody>
</table>
<p>Screen Stencil Renderer Feature</p>
<p><img src="_page_178_Picture_0.jpeg" alt=""></p>
<p>To see the effect in action, walk toward the pedestal until the Unity logo is displayed, then keep the logo in the center of the screen. This will trigger the transition.</p>
<p>All scene assets are loaded at load time, but only a single scene is enabled. The cameras used at runtime, when starting from The Terminal scene, are the same as those found in the FPS_ Controller GameObject. <strong>MainCamera</strong> renders the active scene, and <strong>ScreenCamera</strong> the scene displayed on the monitors.</p>
<p><img src="_page_178_Picture_3.jpeg" alt=""></p>
<p>FPS_Controller for The Terminal Scene</p>
<p>During a transition, the incoming scene camera is rendered to the render target. This creates a potential problem since URP only supports one main directional light. A script called <strong>Scripts &gt; SceneManagement &gt; SceneTransitionManager.cs</strong> runs before rendering, enabling the active scene&#39;s main light and disabling the other to keep to this restriction.</p>
<p>Take a look at the script below. In the <strong>OnBeginCameraRendering</strong> method, we first check whether we&#39;re rendering the main camera. If <strong>isMainCamera</strong> is true, then the <strong>ToggleMainLight</strong> calls activate the main directional light for the <strong>currentScene</strong> and disable the main directional light for the <strong>screenScene</strong>, the incoming scene. However, if <strong>isMainCamera</strong> is false, then the reverse will be the case.</p>
<p>The same script handles switching the fog, reflection, and skybox to suit the scene being rendered by adjusting the settings of the RenderSettings object.</p>
<p><img src="_page_179_Figure_1.jpeg" alt=""></p>
<p>The transition between the incoming and outgoing scenes is handled using a <strong>Render Objects Renderer Feature</strong>. By writing a value to the stencil buffer, this can be checked in a subsequent pass. If the pixel being rendered has a certain stencil value, then you keep what is already in the color buffer; otherwise, you can freely overwrite it. <strong>Renderer Features</strong> are a highly flexible way to build a final render using combinations of passes.</p>
<p><img src="_page_180_Picture_0.jpeg" alt=""></p>
<table>
<thead>
<tr>
<th>Renderer Features</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>V Decal<br>&gt;</td>
<td></td>
<td>0</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Technique</td>
<td>Automatic</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Max Draw Distance</td>
<td>1000</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Use Rendering Layers</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>V Global Volume Feature (Global Volume Feature)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Name</td>
<td>Global Volume Feature</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Base Profile</td>
<td>LowQualityVolumeProfile (Volume Profile)</td>
<td></td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>T &gt; Screen Stencil (Render Objects)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Name</td>
<td>ScreenStencil</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Event</td>
<td>AfterRenderingOpaques</td>
<td></td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>▼ Filters</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Queue</td>
<td>Opaque</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Layer Mask</td>
<td>Screen, Occluder</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LightMode Tags</td>
<td></td>
<td>0</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Overides</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>T / Temp Post (Render Objects)</td>
<td></td>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Name</td>
<td>TempPost</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Event</td>
<td>AfterRenderingTransparents</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Filters</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Queue</td>
<td>Opaque</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Layer Mask</td>
<td>Temp_Post</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LightMode Tags</td>
<td></td>
<td>0</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Overides</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Renderer Features for the Mobile Foward+ Renderer</p>
<p>To match camera positions during a transition, the project has a <strong>SceneMetaData</strong> script for each scene that stores an offset Transform, while a <strong>SceneTransitionManager</strong> script handles the incoming and outgoing scenes during the transition. The <strong>Update</strong> method tracks the progress of the transition. When <strong>ElapsedTimeInTransition</strong> is greater than <strong>m_TransitionTime</strong>, then <strong>TriggerTeleport</strong> is called, which in turn calls the <strong>Teleport</strong> method. This repositions and orientates the player to create a seamless switch from the outgoing scene to the incoming scene.</p>
<p><span id="page-181-0"></span><img src="_page_181_Picture_1.jpeg" alt=""></p>
<p>ScreenTransitionManager.cs Update method</p>
<h2 id="scalability">Scalability</h2>
<p>URP supports a wide range of hardware, and there are several ways the new sample scenes illustrate how to work with different devices. You&#39;ll notice the different options in <strong>Project Settings &gt; Quality</strong>.</p>
<table>
<thead>
<tr>
<th>Quality</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Levels</td>
<td></td>
<td>==</td>
<td></td>
</tr>
<tr>
<td>Quest2</td>
<td></td>
<td>P</td>
<td>E</td>
</tr>
<tr>
<td>Low</td>
<td></td>
<td>D</td>
<td>E</td>
</tr>
<tr>
<td>Switch</td>
<td></td>
<td>2</td>
<td>E</td>
</tr>
<tr>
<td>High</td>
<td>2</td>
<td>2</td>
<td>E</td>
</tr>
<tr>
<td>Mobile Deferre</td>
<td></td>
<td>V</td>
<td>E</td>
</tr>
<tr>
<td>Mobile Forwa</td>
<td></td>
<td>M</td>
<td>E</td>
</tr>
<tr>
<td>Default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Add Quality Level</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Quality levels</p>
<p><img src="_page_182_Picture_0.jpeg" alt=""></p>
<p>Each option uses a different <strong>Render Pipeline Asset</strong>. As explained in the <a href="#page-26-0">Quality</a> section, URP handles Quality using a combination of this panel together with the settings of the Render Pipeline Asset.</p>
<p>Standalone VR headsets present a significant challenge when displaying real-time 3D graphics. They have high-resolution screens, and each eye must be handled separately, resulting in each rendered frame requiring twice the work. Additionally, with a minimum target fps of 72, you&#39;ll need a lot of pixels per second. A workaround for this challenge is to use stylized lighting. The Cockpit scene below uses a Toon Shaded lighting model.</p>
<p><img src="_page_182_Picture_4.jpeg" alt=""></p>
<p>The cockpit environment from the URP 3D sample</p>
<p><img src="_page_183_Figure_1.jpeg" alt=""></p>
<p>The custom lighting is handled using Shader Graph, with minimal coding.</p>
<p>As usual for a Toon shader, it combines the normal vector and the Main light direction using a dot product to determine the lighting level. It then uses a ramp to set staged levels of light rather than smoothly changing values. The lighting model used in The Cockpit scene also uses Baked Global Illumination in the calculation and does some edge detection to add a subtle outline effect. Custom lighting is handled using Shader Graph.</p>
<p>See <em><a href="https://unity.com/resources/the-universal-render-pipeline-cookbook-unity-2022-lts-edition?isGated=false">The Universal Render Pipeline cookbook</a></em> for a tutorial about creating Toon Shaders.</p>
<p><span id="page-184-0"></span><img src="_page_184_Picture_0.jpeg" alt=""></p>
<h3 id="running-the-sample-project-on-a-mobile-device">Running the sample project on a mobile device</h3>
<table>
<thead>
<tr>
<th>Rendering</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Renderer List</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>0 @ Mobile Foward+ Renderer (Universal Renderer Data) O</td>
<td>Default</td>
<td>the</td>
</tr>
<tr>
<td></td>
<td>Set Default<br>1 @Forward . Screen_Renderer (Universal Renderer Dat. ©</td>
<td>13</td>
</tr>
<tr>
<td></td>
<td></td>
<td>+</td>
</tr>
<tr>
<td>Depth Texture</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td>Opaque Texture<br>Opaque Downsampling</td>
<td>2x Billinear</td>
<td></td>
</tr>
<tr>
<td>Terrain Holes</td>
<td>&gt;</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Quality<br>HDR</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>HDR Precision</td>
<td>32 Bits</td>
<td>&gt;</td>
</tr>
<tr>
<td>Anti Aliasing (MSAA)</td>
<td>Disabled</td>
<td>A</td>
</tr>
<tr>
<td>Render Scale</td>
<td></td>
<td>0.7</td>
</tr>
<tr>
<td>Upscaling Filter</td>
<td>Automatic</td>
<td>A</td>
</tr>
<tr>
<td>LOD Cross Fade</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>LOD Cross Fade Dithering Type Blue Noise</td>
<td></td>
<td>D</td>
</tr>
<tr>
<td>V Lighting</td>
<td></td>
<td><em>*</em></td>
</tr>
<tr>
<td>Main Light</td>
<td>Per Pixel</td>
<td>&gt;</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadow Resolution</td>
<td>2048</td>
<td>&gt;</td>
</tr>
<tr>
<td>Additional Lights</td>
<td>Per Pixel</td>
<td></td>
</tr>
<tr>
<td>Per Object Limit</td>
<td></td>
<td>4</td>
</tr>
<tr>
<td>Cast Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shadow Atlas Resolution</td>
<td>2048</td>
<td>2</td>
</tr>
<tr>
<td>Shadow Resolution Tiers</td>
<td>Low 256<br>Medium 512<br>High 1024</td>
<td></td>
</tr>
<tr>
<td>Cookie Atlas Resolution</td>
<td>2048</td>
<td>A</td>
</tr>
<tr>
<td>Cookie Atlas Format</td>
<td>Color High</td>
<td>A</td>
</tr>
<tr>
<td>Reflection Probes</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Probe Blending</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>Box Projection</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Mixed Lighting</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>Use Rendering Layers</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Light Cookies</td>
<td>V</td>
<td></td>
</tr>
<tr>
<td>SH Evaluation Mode</td>
<td>Auto</td>
<td>&gt;</td>
</tr>
<tr>
<td>V Shadows</td>
<td></td>
<td><em>*</em></td>
</tr>
<tr>
<td>Max Distance</td>
<td>50</td>
<td></td>
</tr>
<tr>
<td>Working Unit</td>
<td>Metric</td>
<td>&gt;</td>
</tr>
<tr>
<td>Cascade Count<br>Last Border</td>
<td></td>
<td>1<br>10</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>0<br>40.0m</td>
<td>O-&gt;Falbac</td>
</tr>
<tr>
<td></td>
<td>0</td>
<td>10.0m</td>
</tr>
<tr>
<td>Depth Bias</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>Normal Bias</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>Soft Shadows</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Conservative Enclosing Sphere ✔</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Post-processing</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Grading Mode</td>
<td>Low Dynamic Range</td>
<td>4</td>
</tr>
<tr>
<td>LUT size</td>
<td>32</td>
<td></td>
</tr>
<tr>
<td>Fast sRGB/Linear conversions</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Volume Update Mode</td>
<td>Every Frame</td>
<td>P</td>
</tr>
</tbody>
</table>
<p>A common problem for game developers is getting a game running smoothly on a mobile device. The new sample project includes a <strong>Mobile Forward+</strong> URP Asset in the <strong>Settings</strong> folder. Remember that the URP Asset is the principal way you can adjust quality settings. Forward+ relies on the CPU to do significant culling operations per frame and so is not necessarily the best option for a low-end mobile device. The best option for such devices is the Deferred renderer, which is used by a URP asset in the sample project.</p>
<p>The image to the left shows the settings for the Mobile Forward+ asset.</p>
<p>The Mobile Forward+ URP Asset</p>
<p>The <strong>Renderer List</strong> has two Universal Renderer Data assets: one for the active scene, <strong>Mobile Forward+_Renderer</strong>, and the other for rendering the screen scene, <strong>Forward+_Screen_ Renderer</strong>. The Depth Texture is enabled. Note that Additional Lights do not cast shadows. This is a very expensive option and for mobile devices can often be mimicked using light cookies. The Garden scene in particular has lots of lights, and many use cookies to give a suggestion of shadows. Notice the lighting on the rocks in the bottom left of the image below with and without cookies.</p>
<p><img src="_page_185_Picture_2.jpeg" alt=""></p>
<p>Garden environment point light with and without cookies</p>
<p>Here are three top tips when targeting mobile platforms.</p>
<ul>
<li>Reduce the number of pixels rendered. Most modern mobiles have a high DPI or dotsper-inch count. For most games, a DPI of 96 is sufficient. If Screen.DPI is 300, for example, then a render scale of 96/300 on a 2400 x 1200 screen would mean rendering 768 x 384 pixels, almost a tenth of the pixels, which is a massive performance boost. You can set the render scale in the URP Asset or adjust the value at runtime.</li>
<li>Notice that the Mobile Forward+_Renderer asset has a Decal renderer feature with its Technique option set to Automatic. This will switch to Screen Space on GPUs with hidden surface removal. This provides a performance boost by avoiding a depth prepass, which is a waste of resources on these devices.</li>
<li>Use Deferred rendering on devices where the CPU overhead of Forward+ is too expensive.</li>
<li>To enable more aggressive render pass merging by the Render Graph system, consider the following:<ul>
<li>If not needed in your project, disable the Depth Texture and Opaque Texture setting in the URP Asset settings.</li>
<li>If using Opaque Texture, set Opaque Downsampling to &quot;None&quot;. Downsampling the opaque texture will introduce a resolution change in the URP intermediate textures, preventing pass merging.</li>
</ul>
</li>
</ul>
<p><img src="_page_186_Picture_0.jpeg" alt=""></p>
<p>— If using Depth Texture, set Depth Texture Mode to &quot;After Transparents&quot;. Doing so will avoid injecting a CopyDepth pass between the main render passes (Opaque, Sky, Transparents), and allow Render Graph to successfully merge those passes.</p>
<p>A careful study of these four scenes alongside their URP Asset settings and documentation will help you learn how to use the techniques on display in your own projects.</p>
<h2 id="-span-id-page-187-0-span-conclusion"><span id="page-187-0"></span>Conclusion</h2>
<p>For developers and artists looking to switch to URP, be sure to check out the full <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@14.0/manual/index.html?">Unity</a>  <a href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@14.0/manual/index.html?">Documentation</a>, as well as <a href="https://learn.unity.com/search?k=%5B%22q%3AURP%22%2C%22t%3Aall%22%5D?">Unity Learn</a>, the <a href="https://blog.unity.com/?">Unity Blog,</a> and <a href="https://discussions.unity.com/lists/graphics">Discussions</a>.</p>
<p>The <a href="https://portal.productboard.com/unity/1-unity-platform-rendering-visual-effects/tabs/3-universal-pipeline">Unity Product Board</a> provides an overview of current URP features being developed, in addition to what&#39;s coming up next. You can even add your own feature requests.</p>
<p>Good luck with your game development.</p>
<p><img src="_page_188_Picture_0.jpeg" alt=""></p>
<p><a href="https://unity.com/">unity.com</a></p>
</body></html>